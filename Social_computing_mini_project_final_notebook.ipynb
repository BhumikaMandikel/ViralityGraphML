{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount the drive and reduce the size of the dataset."
      ],
      "metadata": {
        "id": "vtORdJ91XcTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVuwot3PYqs-",
        "outputId": "82ac3c41-bd0b-4ac6-d382-79a408a7c271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "AHAoWGeaZeTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install transformers\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K1AFqnPZkdA",
        "outputId": "f3637fde-4433-4121-a277-bd523ec57503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-1*** : Extracting llm embeddings and then using it along with the additional features for predicting the virality score through GCN"
      ],
      "metadata": {
        "id": "NOcZ0vQkZlhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Convert embeddings to torch tensor\n",
        "text_embeddings = torch.tensor(text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['score'].values, dtype=torch.float)  # Replace 'score' with your actual target column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    \"\"\"Function to create KNN-based edges.\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15  # Number of nearest neighbors for KNN\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500,hidden_dim3=200,hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Fully connected layer for the final output (virality score)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GNN model\n",
        "input_dim = X.shape[1]  # Combined dimension of DistilBERT embeddings and additional features\n",
        "model = GNNModel(input_dim=input_dim)\n",
        "\n",
        "# Move the model to device (GPU/CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Assuming the virality score is a continuous integer value\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass for the entire training set\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "\n",
        "    # Backpropagation and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Optionally, you can evaluate the model on the test set here.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Create edge index for the test set (optional, if you need to evaluate on edges)\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "\n",
        "    # Forward pass on the test set\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "\n",
        "    # Compute the test loss if you have the corresponding test labels\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4rIbjNdae8C",
        "outputId": "0d0ffd0e-fd68-4bc8-8409-a2f2ebf316f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 1535.1337\n",
            "Epoch 2/500, Loss: 1684.0232\n",
            "Epoch 3/500, Loss: 1533.3690\n",
            "Epoch 4/500, Loss: 1534.5195\n",
            "Epoch 5/500, Loss: 1533.8191\n",
            "Epoch 6/500, Loss: 1530.7555\n",
            "Epoch 7/500, Loss: 1524.0878\n",
            "Epoch 8/500, Loss: 1511.9929\n",
            "Epoch 9/500, Loss: 1496.0482\n",
            "Epoch 10/500, Loss: 1493.9531\n",
            "Epoch 11/500, Loss: 1503.9839\n",
            "Epoch 12/500, Loss: 1492.7831\n",
            "Epoch 13/500, Loss: 1487.9139\n",
            "Epoch 14/500, Loss: 1490.0503\n",
            "Epoch 15/500, Loss: 1492.4976\n",
            "Epoch 16/500, Loss: 1492.8041\n",
            "Epoch 17/500, Loss: 1490.8375\n",
            "Epoch 18/500, Loss: 1487.3854\n",
            "Epoch 19/500, Loss: 1484.1494\n",
            "Epoch 20/500, Loss: 1483.4850\n",
            "Epoch 21/500, Loss: 1485.5557\n",
            "Epoch 22/500, Loss: 1485.9188\n",
            "Epoch 23/500, Loss: 1483.1696\n",
            "Epoch 24/500, Loss: 1480.9966\n",
            "Epoch 25/500, Loss: 1480.9067\n",
            "Epoch 26/500, Loss: 1481.6305\n",
            "Epoch 27/500, Loss: 1481.8239\n",
            "Epoch 28/500, Loss: 1481.0491\n",
            "Epoch 29/500, Loss: 1479.6622\n",
            "Epoch 30/500, Loss: 1478.5330\n",
            "Epoch 31/500, Loss: 1478.4357\n",
            "Epoch 32/500, Loss: 1479.0248\n",
            "Epoch 33/500, Loss: 1478.9915\n",
            "Epoch 34/500, Loss: 1478.1449\n",
            "Epoch 35/500, Loss: 1477.5166\n",
            "Epoch 36/500, Loss: 1477.5502\n",
            "Epoch 37/500, Loss: 1477.8352\n",
            "Epoch 38/500, Loss: 1477.8887\n",
            "Epoch 39/500, Loss: 1477.5725\n",
            "Epoch 40/500, Loss: 1477.1121\n",
            "Epoch 41/500, Loss: 1476.8621\n",
            "Epoch 42/500, Loss: 1476.9307\n",
            "Epoch 43/500, Loss: 1477.0105\n",
            "Epoch 44/500, Loss: 1476.7916\n",
            "Epoch 45/500, Loss: 1476.4216\n",
            "Epoch 46/500, Loss: 1476.2155\n",
            "Epoch 47/500, Loss: 1476.1963\n",
            "Epoch 48/500, Loss: 1476.1682\n",
            "Epoch 49/500, Loss: 1475.9835\n",
            "Epoch 50/500, Loss: 1475.6979\n",
            "Epoch 51/500, Loss: 1475.4753\n",
            "Epoch 52/500, Loss: 1475.3842\n",
            "Epoch 53/500, Loss: 1475.3047\n",
            "Epoch 54/500, Loss: 1475.1061\n",
            "Epoch 55/500, Loss: 1474.8486\n",
            "Epoch 56/500, Loss: 1474.6624\n",
            "Epoch 57/500, Loss: 1474.5482\n",
            "Epoch 58/500, Loss: 1474.4127\n",
            "Epoch 59/500, Loss: 1474.2052\n",
            "Epoch 60/500, Loss: 1473.9777\n",
            "Epoch 61/500, Loss: 1473.8038\n",
            "Epoch 62/500, Loss: 1473.6656\n",
            "Epoch 63/500, Loss: 1473.4856\n",
            "Epoch 64/500, Loss: 1473.2552\n",
            "Epoch 65/500, Loss: 1473.0437\n",
            "Epoch 66/500, Loss: 1472.8745\n",
            "Epoch 67/500, Loss: 1472.6960\n",
            "Epoch 68/500, Loss: 1472.4778\n",
            "Epoch 69/500, Loss: 1472.2490\n",
            "Epoch 70/500, Loss: 1472.0483\n",
            "Epoch 71/500, Loss: 1471.8540\n",
            "Epoch 72/500, Loss: 1471.6273\n",
            "Epoch 73/500, Loss: 1471.3895\n",
            "Epoch 74/500, Loss: 1471.1766\n",
            "Epoch 75/500, Loss: 1470.9678\n",
            "Epoch 76/500, Loss: 1470.7322\n",
            "Epoch 77/500, Loss: 1470.4830\n",
            "Epoch 78/500, Loss: 1470.2480\n",
            "Epoch 79/500, Loss: 1470.0173\n",
            "Epoch 80/500, Loss: 1469.7615\n",
            "Epoch 81/500, Loss: 1469.4958\n",
            "Epoch 82/500, Loss: 1469.2371\n",
            "Epoch 83/500, Loss: 1468.9506\n",
            "Epoch 84/500, Loss: 1468.6478\n",
            "Epoch 85/500, Loss: 1468.3607\n",
            "Epoch 86/500, Loss: 1468.0634\n",
            "Epoch 87/500, Loss: 1467.7427\n",
            "Epoch 88/500, Loss: 1467.4181\n",
            "Epoch 89/500, Loss: 1467.0747\n",
            "Epoch 90/500, Loss: 1466.7195\n",
            "Epoch 91/500, Loss: 1466.3816\n",
            "Epoch 92/500, Loss: 1466.0142\n",
            "Epoch 93/500, Loss: 1465.6292\n",
            "Epoch 94/500, Loss: 1465.2471\n",
            "Epoch 95/500, Loss: 1464.8428\n",
            "Epoch 96/500, Loss: 1464.4310\n",
            "Epoch 97/500, Loss: 1464.0024\n",
            "Epoch 98/500, Loss: 1463.5581\n",
            "Epoch 99/500, Loss: 1463.0928\n",
            "Epoch 100/500, Loss: 1462.5486\n",
            "Epoch 101/500, Loss: 1461.9363\n",
            "Epoch 102/500, Loss: 1461.2100\n",
            "Epoch 103/500, Loss: 1460.4153\n",
            "Epoch 104/500, Loss: 1459.5555\n",
            "Epoch 105/500, Loss: 1458.6453\n",
            "Epoch 106/500, Loss: 1457.7029\n",
            "Epoch 107/500, Loss: 1456.6899\n",
            "Epoch 108/500, Loss: 1455.5742\n",
            "Epoch 109/500, Loss: 1454.5361\n",
            "Epoch 110/500, Loss: 1455.7683\n",
            "Epoch 111/500, Loss: 1459.6378\n",
            "Epoch 112/500, Loss: 1458.6556\n",
            "Epoch 113/500, Loss: 1458.2704\n",
            "Epoch 114/500, Loss: 1450.3055\n",
            "Epoch 115/500, Loss: 1457.2710\n",
            "Epoch 116/500, Loss: 1450.9690\n",
            "Epoch 117/500, Loss: 1456.3264\n",
            "Epoch 118/500, Loss: 1448.5675\n",
            "Epoch 119/500, Loss: 1450.2305\n",
            "Epoch 120/500, Loss: 1446.8044\n",
            "Epoch 121/500, Loss: 1445.6207\n",
            "Epoch 122/500, Loss: 1447.5338\n",
            "Epoch 123/500, Loss: 1442.0951\n",
            "Epoch 124/500, Loss: 1444.3269\n",
            "Epoch 125/500, Loss: 1439.4753\n",
            "Epoch 126/500, Loss: 1440.0902\n",
            "Epoch 127/500, Loss: 1438.5059\n",
            "Epoch 128/500, Loss: 1436.4457\n",
            "Epoch 129/500, Loss: 1434.7566\n",
            "Epoch 130/500, Loss: 1434.8948\n",
            "Epoch 131/500, Loss: 1432.5146\n",
            "Epoch 132/500, Loss: 1433.1870\n",
            "Epoch 133/500, Loss: 1430.0582\n",
            "Epoch 134/500, Loss: 1429.2897\n",
            "Epoch 135/500, Loss: 1427.7992\n",
            "Epoch 136/500, Loss: 1425.1917\n",
            "Epoch 137/500, Loss: 1424.7368\n",
            "Epoch 138/500, Loss: 1422.9318\n",
            "Epoch 139/500, Loss: 1421.3657\n",
            "Epoch 140/500, Loss: 1420.4351\n",
            "Epoch 141/500, Loss: 1419.3383\n",
            "Epoch 142/500, Loss: 1418.6360\n",
            "Epoch 143/500, Loss: 1416.5958\n",
            "Epoch 144/500, Loss: 1414.6742\n",
            "Epoch 145/500, Loss: 1413.2917\n",
            "Epoch 146/500, Loss: 1413.2578\n",
            "Epoch 147/500, Loss: 1418.7872\n",
            "Epoch 148/500, Loss: 1410.3420\n",
            "Epoch 149/500, Loss: 1428.0193\n",
            "Epoch 150/500, Loss: 1429.9950\n",
            "Epoch 151/500, Loss: 1444.0966\n",
            "Epoch 152/500, Loss: 1432.0466\n",
            "Epoch 153/500, Loss: 1413.4344\n",
            "Epoch 154/500, Loss: 1452.7379\n",
            "Epoch 155/500, Loss: 1413.0314\n",
            "Epoch 156/500, Loss: 1430.4508\n",
            "Epoch 157/500, Loss: 1436.7096\n",
            "Epoch 158/500, Loss: 1428.2826\n",
            "Epoch 159/500, Loss: 1407.5385\n",
            "Epoch 160/500, Loss: 1427.6334\n",
            "Epoch 161/500, Loss: 1402.1356\n",
            "Epoch 162/500, Loss: 1409.2664\n",
            "Epoch 163/500, Loss: 1412.2720\n",
            "Epoch 164/500, Loss: 1403.8466\n",
            "Epoch 165/500, Loss: 1398.5179\n",
            "Epoch 166/500, Loss: 1408.4028\n",
            "Epoch 167/500, Loss: 1395.6105\n",
            "Epoch 168/500, Loss: 1400.6989\n",
            "Epoch 169/500, Loss: 1401.0297\n",
            "Epoch 170/500, Loss: 1393.3938\n",
            "Epoch 171/500, Loss: 1397.0176\n",
            "Epoch 172/500, Loss: 1393.2139\n",
            "Epoch 173/500, Loss: 1391.0228\n",
            "Epoch 174/500, Loss: 1393.4174\n",
            "Epoch 175/500, Loss: 1388.2345\n",
            "Epoch 176/500, Loss: 1387.9945\n",
            "Epoch 177/500, Loss: 1386.6499\n",
            "Epoch 178/500, Loss: 1383.5626\n",
            "Epoch 179/500, Loss: 1384.3862\n",
            "Epoch 180/500, Loss: 1380.0709\n",
            "Epoch 181/500, Loss: 1380.3060\n",
            "Epoch 182/500, Loss: 1377.3843\n",
            "Epoch 183/500, Loss: 1375.9285\n",
            "Epoch 184/500, Loss: 1375.0146\n",
            "Epoch 185/500, Loss: 1371.5435\n",
            "Epoch 186/500, Loss: 1371.6855\n",
            "Epoch 187/500, Loss: 1367.7446\n",
            "Epoch 188/500, Loss: 1367.3142\n",
            "Epoch 189/500, Loss: 1363.7153\n",
            "Epoch 190/500, Loss: 1362.9441\n",
            "Epoch 191/500, Loss: 1359.2809\n",
            "Epoch 192/500, Loss: 1358.3472\n",
            "Epoch 193/500, Loss: 1354.7766\n",
            "Epoch 194/500, Loss: 1353.2855\n",
            "Epoch 195/500, Loss: 1350.7964\n",
            "Epoch 196/500, Loss: 1347.0566\n",
            "Epoch 197/500, Loss: 1346.3291\n",
            "Epoch 198/500, Loss: 1344.1240\n",
            "Epoch 199/500, Loss: 1337.7910\n",
            "Epoch 200/500, Loss: 1339.2295\n",
            "Epoch 201/500, Loss: 1349.0222\n",
            "Epoch 202/500, Loss: 1327.8923\n",
            "Epoch 203/500, Loss: 1335.6404\n",
            "Epoch 204/500, Loss: 1379.6941\n",
            "Epoch 205/500, Loss: 1338.2471\n",
            "Epoch 206/500, Loss: 1529.2961\n",
            "Epoch 207/500, Loss: 1463.0364\n",
            "Epoch 208/500, Loss: 1487.8301\n",
            "Epoch 209/500, Loss: 1484.8877\n",
            "Epoch 210/500, Loss: 1483.3268\n",
            "Epoch 211/500, Loss: 1483.2125\n",
            "Epoch 212/500, Loss: 1483.2412\n",
            "Epoch 213/500, Loss: 1483.3290\n",
            "Epoch 214/500, Loss: 1483.3354\n",
            "Epoch 215/500, Loss: 1483.2524\n",
            "Epoch 216/500, Loss: 1483.1738\n",
            "Epoch 217/500, Loss: 1483.1693\n",
            "Epoch 218/500, Loss: 1483.2172\n",
            "Epoch 219/500, Loss: 1483.2469\n",
            "Epoch 220/500, Loss: 1483.2234\n",
            "Epoch 221/500, Loss: 1483.1721\n",
            "Epoch 222/500, Loss: 1483.1437\n",
            "Epoch 223/500, Loss: 1483.1567\n",
            "Epoch 224/500, Loss: 1483.1836\n",
            "Epoch 225/500, Loss: 1483.1852\n",
            "Epoch 226/500, Loss: 1483.1578\n",
            "Epoch 227/500, Loss: 1483.1304\n",
            "Epoch 228/500, Loss: 1483.1245\n",
            "Epoch 229/500, Loss: 1483.1364\n",
            "Epoch 230/500, Loss: 1483.1442\n",
            "Epoch 231/500, Loss: 1483.1346\n",
            "Epoch 232/500, Loss: 1483.1152\n",
            "Epoch 233/500, Loss: 1483.1023\n",
            "Epoch 234/500, Loss: 1483.1029\n",
            "Epoch 235/500, Loss: 1483.1082\n",
            "Epoch 236/500, Loss: 1483.1063\n",
            "Epoch 237/500, Loss: 1483.0951\n",
            "Epoch 238/500, Loss: 1483.0829\n",
            "Epoch 239/500, Loss: 1483.0778\n",
            "Epoch 240/500, Loss: 1483.0786\n",
            "Epoch 241/500, Loss: 1483.0785\n",
            "Epoch 242/500, Loss: 1483.0726\n",
            "Epoch 243/500, Loss: 1483.0635\n",
            "Epoch 244/500, Loss: 1483.0562\n",
            "Epoch 245/500, Loss: 1483.0537\n",
            "Epoch 246/500, Loss: 1483.0526\n",
            "Epoch 247/500, Loss: 1483.0490\n",
            "Epoch 248/500, Loss: 1483.0425\n",
            "Epoch 249/500, Loss: 1483.0359\n",
            "Epoch 250/500, Loss: 1483.0317\n",
            "Epoch 251/500, Loss: 1483.0293\n",
            "Epoch 252/500, Loss: 1483.0264\n",
            "Epoch 253/500, Loss: 1483.0216\n",
            "Epoch 254/500, Loss: 1483.0160\n",
            "Epoch 255/500, Loss: 1483.0112\n",
            "Epoch 256/500, Loss: 1483.0079\n",
            "Epoch 257/500, Loss: 1483.0050\n",
            "Epoch 258/500, Loss: 1483.0011\n",
            "Epoch 259/500, Loss: 1482.9962\n",
            "Epoch 260/500, Loss: 1482.9917\n",
            "Epoch 261/500, Loss: 1482.9879\n",
            "Epoch 262/500, Loss: 1482.9847\n",
            "Epoch 263/500, Loss: 1482.9812\n",
            "Epoch 264/500, Loss: 1482.9773\n",
            "Epoch 265/500, Loss: 1482.9730\n",
            "Epoch 266/500, Loss: 1482.9691\n",
            "Epoch 267/500, Loss: 1482.9657\n",
            "Epoch 268/500, Loss: 1482.9622\n",
            "Epoch 269/500, Loss: 1482.9585\n",
            "Epoch 270/500, Loss: 1482.9547\n",
            "Epoch 271/500, Loss: 1482.9510\n",
            "Epoch 272/500, Loss: 1482.9475\n",
            "Epoch 273/500, Loss: 1482.9441\n",
            "Epoch 274/500, Loss: 1482.9407\n",
            "Epoch 275/500, Loss: 1482.9370\n",
            "Epoch 276/500, Loss: 1482.9337\n",
            "Epoch 277/500, Loss: 1482.9303\n",
            "Epoch 278/500, Loss: 1482.9271\n",
            "Epoch 279/500, Loss: 1482.9238\n",
            "Epoch 280/500, Loss: 1482.9204\n",
            "Epoch 281/500, Loss: 1482.9167\n",
            "Epoch 282/500, Loss: 1482.9137\n",
            "Epoch 283/500, Loss: 1482.9108\n",
            "Epoch 284/500, Loss: 1482.9075\n",
            "Epoch 285/500, Loss: 1482.9045\n",
            "Epoch 286/500, Loss: 1482.9011\n",
            "Epoch 287/500, Loss: 1482.8979\n",
            "Epoch 288/500, Loss: 1482.8950\n",
            "Epoch 289/500, Loss: 1482.8918\n",
            "Epoch 290/500, Loss: 1482.8894\n",
            "Epoch 291/500, Loss: 1482.8861\n",
            "Epoch 292/500, Loss: 1482.8832\n",
            "Epoch 293/500, Loss: 1482.8802\n",
            "Epoch 294/500, Loss: 1482.8774\n",
            "Epoch 295/500, Loss: 1482.8744\n",
            "Epoch 296/500, Loss: 1482.8718\n",
            "Epoch 297/500, Loss: 1482.8691\n",
            "Epoch 298/500, Loss: 1482.8665\n",
            "Epoch 299/500, Loss: 1482.8636\n",
            "Epoch 300/500, Loss: 1482.8608\n",
            "Epoch 301/500, Loss: 1482.8583\n",
            "Epoch 302/500, Loss: 1482.8560\n",
            "Epoch 303/500, Loss: 1482.8530\n",
            "Epoch 304/500, Loss: 1482.8508\n",
            "Epoch 305/500, Loss: 1482.8479\n",
            "Epoch 306/500, Loss: 1482.8458\n",
            "Epoch 307/500, Loss: 1482.8431\n",
            "Epoch 308/500, Loss: 1482.8407\n",
            "Epoch 309/500, Loss: 1482.8385\n",
            "Epoch 310/500, Loss: 1482.8361\n",
            "Epoch 311/500, Loss: 1482.8336\n",
            "Epoch 312/500, Loss: 1482.8317\n",
            "Epoch 313/500, Loss: 1482.8292\n",
            "Epoch 314/500, Loss: 1482.8270\n",
            "Epoch 315/500, Loss: 1482.8250\n",
            "Epoch 316/500, Loss: 1482.8229\n",
            "Epoch 317/500, Loss: 1482.8208\n",
            "Epoch 318/500, Loss: 1482.8184\n",
            "Epoch 319/500, Loss: 1482.8165\n",
            "Epoch 320/500, Loss: 1482.8146\n",
            "Epoch 321/500, Loss: 1482.8125\n",
            "Epoch 322/500, Loss: 1482.8105\n",
            "Epoch 323/500, Loss: 1482.8086\n",
            "Epoch 324/500, Loss: 1482.8066\n",
            "Epoch 325/500, Loss: 1482.8047\n",
            "Epoch 326/500, Loss: 1482.8030\n",
            "Epoch 327/500, Loss: 1482.8013\n",
            "Epoch 328/500, Loss: 1482.7993\n",
            "Epoch 329/500, Loss: 1482.7979\n",
            "Epoch 330/500, Loss: 1482.7958\n",
            "Epoch 331/500, Loss: 1482.7941\n",
            "Epoch 332/500, Loss: 1482.7925\n",
            "Epoch 333/500, Loss: 1482.7909\n",
            "Epoch 334/500, Loss: 1482.7893\n",
            "Epoch 335/500, Loss: 1482.7876\n",
            "Epoch 336/500, Loss: 1482.7858\n",
            "Epoch 337/500, Loss: 1482.7845\n",
            "Epoch 338/500, Loss: 1482.7832\n",
            "Epoch 339/500, Loss: 1482.7817\n",
            "Epoch 340/500, Loss: 1482.7803\n",
            "Epoch 341/500, Loss: 1482.7788\n",
            "Epoch 342/500, Loss: 1482.7772\n",
            "Epoch 343/500, Loss: 1482.7761\n",
            "Epoch 344/500, Loss: 1482.7747\n",
            "Epoch 345/500, Loss: 1482.7736\n",
            "Epoch 346/500, Loss: 1482.7721\n",
            "Epoch 347/500, Loss: 1482.7709\n",
            "Epoch 348/500, Loss: 1482.7694\n",
            "Epoch 349/500, Loss: 1482.7684\n",
            "Epoch 350/500, Loss: 1482.7671\n",
            "Epoch 351/500, Loss: 1482.7661\n",
            "Epoch 352/500, Loss: 1482.7648\n",
            "Epoch 353/500, Loss: 1482.7637\n",
            "Epoch 354/500, Loss: 1482.7625\n",
            "Epoch 355/500, Loss: 1482.7616\n",
            "Epoch 356/500, Loss: 1482.7603\n",
            "Epoch 357/500, Loss: 1482.7592\n",
            "Epoch 358/500, Loss: 1482.7582\n",
            "Epoch 359/500, Loss: 1482.7577\n",
            "Epoch 360/500, Loss: 1482.7567\n",
            "Epoch 361/500, Loss: 1482.7555\n",
            "Epoch 362/500, Loss: 1482.7545\n",
            "Epoch 363/500, Loss: 1482.7538\n",
            "Epoch 364/500, Loss: 1482.7529\n",
            "Epoch 365/500, Loss: 1482.7520\n",
            "Epoch 366/500, Loss: 1482.7510\n",
            "Epoch 367/500, Loss: 1482.7502\n",
            "Epoch 368/500, Loss: 1482.7495\n",
            "Epoch 369/500, Loss: 1482.7487\n",
            "Epoch 370/500, Loss: 1482.7477\n",
            "Epoch 371/500, Loss: 1482.7471\n",
            "Epoch 372/500, Loss: 1482.7465\n",
            "Epoch 373/500, Loss: 1482.7456\n",
            "Epoch 374/500, Loss: 1482.7449\n",
            "Epoch 375/500, Loss: 1482.7443\n",
            "Epoch 376/500, Loss: 1482.7435\n",
            "Epoch 377/500, Loss: 1482.7429\n",
            "Epoch 378/500, Loss: 1482.7424\n",
            "Epoch 379/500, Loss: 1482.7417\n",
            "Epoch 380/500, Loss: 1482.7411\n",
            "Epoch 381/500, Loss: 1482.7404\n",
            "Epoch 382/500, Loss: 1482.7399\n",
            "Epoch 383/500, Loss: 1482.7391\n",
            "Epoch 384/500, Loss: 1482.7388\n",
            "Epoch 385/500, Loss: 1482.7383\n",
            "Epoch 386/500, Loss: 1482.7379\n",
            "Epoch 387/500, Loss: 1482.7373\n",
            "Epoch 388/500, Loss: 1482.7369\n",
            "Epoch 389/500, Loss: 1482.7363\n",
            "Epoch 390/500, Loss: 1482.7357\n",
            "Epoch 391/500, Loss: 1482.7354\n",
            "Epoch 392/500, Loss: 1482.7347\n",
            "Epoch 393/500, Loss: 1482.7340\n",
            "Epoch 394/500, Loss: 1482.7336\n",
            "Epoch 395/500, Loss: 1482.7332\n",
            "Epoch 396/500, Loss: 1482.7335\n",
            "Epoch 397/500, Loss: 1482.7324\n",
            "Epoch 398/500, Loss: 1482.7321\n",
            "Epoch 399/500, Loss: 1482.7318\n",
            "Epoch 400/500, Loss: 1482.7314\n",
            "Epoch 401/500, Loss: 1482.7312\n",
            "Epoch 402/500, Loss: 1482.7306\n",
            "Epoch 403/500, Loss: 1482.7303\n",
            "Epoch 404/500, Loss: 1482.7300\n",
            "Epoch 405/500, Loss: 1482.7297\n",
            "Epoch 406/500, Loss: 1482.7294\n",
            "Epoch 407/500, Loss: 1482.7291\n",
            "Epoch 408/500, Loss: 1482.7288\n",
            "Epoch 409/500, Loss: 1482.7288\n",
            "Epoch 410/500, Loss: 1482.7280\n",
            "Epoch 411/500, Loss: 1482.7279\n",
            "Epoch 412/500, Loss: 1482.7274\n",
            "Epoch 413/500, Loss: 1482.7274\n",
            "Epoch 414/500, Loss: 1482.7271\n",
            "Epoch 415/500, Loss: 1482.7269\n",
            "Epoch 416/500, Loss: 1482.7266\n",
            "Epoch 417/500, Loss: 1482.7261\n",
            "Epoch 418/500, Loss: 1482.7260\n",
            "Epoch 419/500, Loss: 1482.7257\n",
            "Epoch 420/500, Loss: 1482.7255\n",
            "Epoch 421/500, Loss: 1482.7252\n",
            "Epoch 422/500, Loss: 1482.7251\n",
            "Epoch 423/500, Loss: 1482.7250\n",
            "Epoch 424/500, Loss: 1482.7249\n",
            "Epoch 425/500, Loss: 1482.7242\n",
            "Epoch 426/500, Loss: 1482.7239\n",
            "Epoch 427/500, Loss: 1482.7239\n",
            "Epoch 428/500, Loss: 1482.7239\n",
            "Epoch 429/500, Loss: 1482.7234\n",
            "Epoch 430/500, Loss: 1482.7233\n",
            "Epoch 431/500, Loss: 1482.7231\n",
            "Epoch 432/500, Loss: 1482.7229\n",
            "Epoch 433/500, Loss: 1482.7228\n",
            "Epoch 434/500, Loss: 1482.7225\n",
            "Epoch 435/500, Loss: 1482.7223\n",
            "Epoch 436/500, Loss: 1482.7222\n",
            "Epoch 437/500, Loss: 1482.7218\n",
            "Epoch 438/500, Loss: 1482.7220\n",
            "Epoch 439/500, Loss: 1482.7219\n",
            "Epoch 440/500, Loss: 1482.7216\n",
            "Epoch 441/500, Loss: 1482.7213\n",
            "Epoch 442/500, Loss: 1482.7213\n",
            "Epoch 443/500, Loss: 1482.7211\n",
            "Epoch 444/500, Loss: 1482.7211\n",
            "Epoch 445/500, Loss: 1482.7208\n",
            "Epoch 446/500, Loss: 1482.7206\n",
            "Epoch 447/500, Loss: 1482.7206\n",
            "Epoch 448/500, Loss: 1482.7202\n",
            "Epoch 449/500, Loss: 1482.7202\n",
            "Epoch 450/500, Loss: 1482.7198\n",
            "Epoch 451/500, Loss: 1482.7200\n",
            "Epoch 452/500, Loss: 1482.7197\n",
            "Epoch 453/500, Loss: 1482.7196\n",
            "Epoch 454/500, Loss: 1482.7194\n",
            "Epoch 455/500, Loss: 1482.7194\n",
            "Epoch 456/500, Loss: 1482.7190\n",
            "Epoch 457/500, Loss: 1482.7189\n",
            "Epoch 458/500, Loss: 1482.7186\n",
            "Epoch 459/500, Loss: 1482.7186\n",
            "Epoch 460/500, Loss: 1482.7184\n",
            "Epoch 461/500, Loss: 1482.7183\n",
            "Epoch 462/500, Loss: 1482.7181\n",
            "Epoch 463/500, Loss: 1482.7179\n",
            "Epoch 464/500, Loss: 1482.7178\n",
            "Epoch 465/500, Loss: 1482.7180\n",
            "Epoch 466/500, Loss: 1482.7177\n",
            "Epoch 467/500, Loss: 1482.7177\n",
            "Epoch 468/500, Loss: 1482.7175\n",
            "Epoch 469/500, Loss: 1482.7174\n",
            "Epoch 470/500, Loss: 1482.7173\n",
            "Epoch 471/500, Loss: 1482.7173\n",
            "Epoch 472/500, Loss: 1482.7168\n",
            "Epoch 473/500, Loss: 1482.7168\n",
            "Epoch 474/500, Loss: 1482.7168\n",
            "Epoch 475/500, Loss: 1482.7167\n",
            "Epoch 476/500, Loss: 1482.7163\n",
            "Epoch 477/500, Loss: 1482.7162\n",
            "Epoch 478/500, Loss: 1482.7161\n",
            "Epoch 479/500, Loss: 1482.7161\n",
            "Epoch 480/500, Loss: 1482.7157\n",
            "Epoch 481/500, Loss: 1482.7157\n",
            "Epoch 482/500, Loss: 1482.7155\n",
            "Epoch 483/500, Loss: 1482.7155\n",
            "Epoch 484/500, Loss: 1482.7151\n",
            "Epoch 485/500, Loss: 1482.7151\n",
            "Epoch 486/500, Loss: 1482.7150\n",
            "Epoch 487/500, Loss: 1482.7150\n",
            "Epoch 488/500, Loss: 1482.7148\n",
            "Epoch 489/500, Loss: 1482.7147\n",
            "Epoch 490/500, Loss: 1482.7147\n",
            "Epoch 491/500, Loss: 1482.7144\n",
            "Epoch 492/500, Loss: 1482.7144\n",
            "Epoch 493/500, Loss: 1482.7142\n",
            "Epoch 494/500, Loss: 1482.7140\n",
            "Epoch 495/500, Loss: 1482.7137\n",
            "Epoch 496/500, Loss: 1482.7137\n",
            "Epoch 497/500, Loss: 1482.7137\n",
            "Epoch 498/500, Loss: 1482.7134\n",
            "Epoch 499/500, Loss: 1482.7134\n",
            "Epoch 500/500, Loss: 1482.7131\n",
            "Training complete.\n",
            "Test Loss: 3272.6758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-1 P-2*** : Extracting llm embeddings and then using it along with the additional features for predicting the virality score through GAT"
      ],
      "metadata": {
        "id": "VYnQM9C9ehP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GATConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "text_embeddings = torch.tensor(text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Select additional features\n",
        "additional_features = torch.tensor(df_one_hot.values, dtype=torch.float)\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['score'].values, dtype=torch.float)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to create edge index using KNN\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    _, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GAT model\n",
        "class GATModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1, heads=4):\n",
        "        super(GATModel, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim1, heads=heads)\n",
        "        self.conv2 = GATConv(hidden_dim1 * heads, hidden_dim2, heads=heads)\n",
        "        self.conv3 = GATConv(hidden_dim2 * heads, hidden_dim3, heads=heads)\n",
        "        self.conv4 = GATConv(hidden_dim3 * heads, hidden_dim4, heads=heads)\n",
        "        self.fc = nn.Linear(hidden_dim4 * heads, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize GAT model\n",
        "input_dim = X.shape[1]\n",
        "model = GATModel(input_dim=input_dim)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training data to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UiM6Rk9eik1",
        "outputId": "d1507fb6-8fe1-4961-9b0d-5c2d4158cb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 1534.3809\n",
            "Epoch 2/500, Loss: 2048347.0000\n",
            "Epoch 3/500, Loss: 1486.3187\n",
            "Epoch 4/500, Loss: 1584.0054\n",
            "Epoch 5/500, Loss: 1541.5175\n",
            "Epoch 6/500, Loss: 1501.3237\n",
            "Epoch 7/500, Loss: 1569.5597\n",
            "Epoch 8/500, Loss: 1497.3683\n",
            "Epoch 9/500, Loss: 1523.7749\n",
            "Epoch 10/500, Loss: 1518.7014\n",
            "Epoch 11/500, Loss: 1493.0240\n",
            "Epoch 12/500, Loss: 1497.0538\n",
            "Epoch 13/500, Loss: 1486.2109\n",
            "Epoch 14/500, Loss: 1492.2892\n",
            "Epoch 15/500, Loss: 1486.8528\n",
            "Epoch 16/500, Loss: 1480.8640\n",
            "Epoch 17/500, Loss: 1483.2509\n",
            "Epoch 18/500, Loss: 1479.4443\n",
            "Epoch 19/500, Loss: 1473.2670\n",
            "Epoch 20/500, Loss: 1475.8508\n",
            "Epoch 21/500, Loss: 1483.4203\n",
            "Epoch 22/500, Loss: 1473.6963\n",
            "Epoch 23/500, Loss: 1460.6692\n",
            "Epoch 24/500, Loss: 1468.1377\n",
            "Epoch 25/500, Loss: 1486.2356\n",
            "Epoch 26/500, Loss: 1458.2960\n",
            "Epoch 27/500, Loss: 1464.9655\n",
            "Epoch 28/500, Loss: 1446.5037\n",
            "Epoch 29/500, Loss: 1439.0510\n",
            "Epoch 30/500, Loss: 1455.3193\n",
            "Epoch 31/500, Loss: 1411.9213\n",
            "Epoch 32/500, Loss: 1401.9559\n",
            "Epoch 33/500, Loss: 1415.2075\n",
            "Epoch 34/500, Loss: 1475.6481\n",
            "Epoch 35/500, Loss: 1341.2823\n",
            "Epoch 36/500, Loss: 1295.3099\n",
            "Epoch 37/500, Loss: 1395.4836\n",
            "Epoch 38/500, Loss: 1264.5037\n",
            "Epoch 39/500, Loss: 1360.6072\n",
            "Epoch 40/500, Loss: 1470.9836\n",
            "Epoch 41/500, Loss: 1382.9945\n",
            "Epoch 42/500, Loss: 1215.9471\n",
            "Epoch 43/500, Loss: 1093.9745\n",
            "Epoch 44/500, Loss: 1066.1616\n",
            "Epoch 45/500, Loss: 1494.5245\n",
            "Epoch 46/500, Loss: 1514.3063\n",
            "Epoch 47/500, Loss: 1462.1140\n",
            "Epoch 48/500, Loss: 1091.8508\n",
            "Epoch 49/500, Loss: 996.1167\n",
            "Epoch 50/500, Loss: 1169.4500\n",
            "Epoch 51/500, Loss: 1340.8043\n",
            "Epoch 52/500, Loss: 1585.1102\n",
            "Epoch 53/500, Loss: 1541.8000\n",
            "Epoch 54/500, Loss: 1500.0995\n",
            "Epoch 55/500, Loss: 1483.8304\n",
            "Epoch 56/500, Loss: 1486.7482\n",
            "Epoch 57/500, Loss: 1475.8915\n",
            "Epoch 58/500, Loss: 1469.6530\n",
            "Epoch 59/500, Loss: 1486.2114\n",
            "Epoch 60/500, Loss: 1631.9719\n",
            "Epoch 61/500, Loss: 1452.8661\n",
            "Epoch 62/500, Loss: 1454.0016\n",
            "Epoch 63/500, Loss: 1483.0032\n",
            "Epoch 64/500, Loss: 1505.4244\n",
            "Epoch 65/500, Loss: 1495.0573\n",
            "Epoch 66/500, Loss: 1482.9043\n",
            "Epoch 67/500, Loss: 1473.5398\n",
            "Epoch 68/500, Loss: 1486.5737\n",
            "Epoch 69/500, Loss: 1487.8622\n",
            "Epoch 70/500, Loss: 1492.5116\n",
            "Epoch 71/500, Loss: 1497.6919\n",
            "Epoch 72/500, Loss: 1482.6412\n",
            "Epoch 73/500, Loss: 1475.2053\n",
            "Epoch 74/500, Loss: 1517.7097\n",
            "Epoch 75/500, Loss: 1784.1300\n",
            "Epoch 76/500, Loss: 1635.5433\n",
            "Epoch 77/500, Loss: 1544.2301\n",
            "Epoch 78/500, Loss: 2017.9644\n",
            "Epoch 79/500, Loss: 1578.2214\n",
            "Epoch 80/500, Loss: 1491.9434\n",
            "Epoch 81/500, Loss: 2257.9202\n",
            "Epoch 82/500, Loss: 8324.4873\n",
            "Epoch 83/500, Loss: 1492.2949\n",
            "Epoch 84/500, Loss: 1593.2451\n",
            "Epoch 85/500, Loss: 1517.3431\n",
            "Epoch 86/500, Loss: 1490.5645\n",
            "Epoch 87/500, Loss: 1509.5182\n",
            "Epoch 88/500, Loss: 1543.6958\n",
            "Epoch 89/500, Loss: 1497.6520\n",
            "Epoch 90/500, Loss: 1551.6650\n",
            "Epoch 91/500, Loss: 1503.1134\n",
            "Epoch 92/500, Loss: 1533.2284\n",
            "Epoch 93/500, Loss: 1545.6975\n",
            "Epoch 94/500, Loss: 1498.4287\n",
            "Epoch 95/500, Loss: 1516.7906\n",
            "Epoch 96/500, Loss: 1519.5792\n",
            "Epoch 97/500, Loss: 1495.6368\n",
            "Epoch 98/500, Loss: 1502.4884\n",
            "Epoch 99/500, Loss: 1503.0841\n",
            "Epoch 100/500, Loss: 1488.9750\n",
            "Epoch 101/500, Loss: 1497.9130\n",
            "Epoch 102/500, Loss: 1497.5596\n",
            "Epoch 103/500, Loss: 1484.2823\n",
            "Epoch 104/500, Loss: 1489.5637\n",
            "Epoch 105/500, Loss: 1488.1100\n",
            "Epoch 106/500, Loss: 1476.4150\n",
            "Epoch 107/500, Loss: 1477.4095\n",
            "Epoch 108/500, Loss: 1499.4818\n",
            "Epoch 109/500, Loss: 1641.2120\n",
            "Epoch 110/500, Loss: 1637.0483\n",
            "Epoch 111/500, Loss: 1488.3844\n",
            "Epoch 112/500, Loss: 1550.1155\n",
            "Epoch 113/500, Loss: 1491.4647\n",
            "Epoch 114/500, Loss: 1524.6254\n",
            "Epoch 115/500, Loss: 1510.7701\n",
            "Epoch 116/500, Loss: 1489.6442\n",
            "Epoch 117/500, Loss: 1506.3265\n",
            "Epoch 118/500, Loss: 1493.9675\n",
            "Epoch 119/500, Loss: 1491.6647\n",
            "Epoch 120/500, Loss: 1490.9720\n",
            "Epoch 121/500, Loss: 1480.6836\n",
            "Epoch 122/500, Loss: 1480.9618\n",
            "Epoch 123/500, Loss: 1481.2858\n",
            "Epoch 124/500, Loss: 1478.4670\n",
            "Epoch 125/500, Loss: 1479.7698\n",
            "Epoch 126/500, Loss: 1482.8424\n",
            "Epoch 127/500, Loss: 1484.0524\n",
            "Epoch 128/500, Loss: 1487.6831\n",
            "Epoch 129/500, Loss: 1473.5392\n",
            "Epoch 130/500, Loss: 1466.7996\n",
            "Epoch 131/500, Loss: 1467.1012\n",
            "Epoch 132/500, Loss: 1467.7137\n",
            "Epoch 133/500, Loss: 1470.0640\n",
            "Epoch 134/500, Loss: 1463.1863\n",
            "Epoch 135/500, Loss: 1471.4232\n",
            "Epoch 136/500, Loss: 1474.1556\n",
            "Epoch 137/500, Loss: 1466.8823\n",
            "Epoch 138/500, Loss: 1469.9229\n",
            "Epoch 139/500, Loss: 1469.8054\n",
            "Epoch 140/500, Loss: 1473.2665\n",
            "Epoch 141/500, Loss: 1469.1498\n",
            "Epoch 142/500, Loss: 1467.5988\n",
            "Epoch 143/500, Loss: 1501.0813\n",
            "Epoch 144/500, Loss: 1490.6770\n",
            "Epoch 145/500, Loss: 1480.8793\n",
            "Epoch 146/500, Loss: 1479.7427\n",
            "Epoch 147/500, Loss: 1480.1438\n",
            "Epoch 148/500, Loss: 1478.3267\n",
            "Epoch 149/500, Loss: 1491.2836\n",
            "Epoch 150/500, Loss: 1559.4774\n",
            "Epoch 151/500, Loss: 1554.7188\n",
            "Epoch 152/500, Loss: 1489.1366\n",
            "Epoch 153/500, Loss: 1494.2709\n",
            "Epoch 154/500, Loss: 1501.7914\n",
            "Epoch 155/500, Loss: 1469.7184\n",
            "Epoch 156/500, Loss: 1489.9379\n",
            "Epoch 157/500, Loss: 1478.2443\n",
            "Epoch 158/500, Loss: 1477.4750\n",
            "Epoch 159/500, Loss: 1477.3153\n",
            "Epoch 160/500, Loss: 1470.7880\n",
            "Epoch 161/500, Loss: 1469.8959\n",
            "Epoch 162/500, Loss: 1476.4259\n",
            "Epoch 163/500, Loss: 1471.3633\n",
            "Epoch 164/500, Loss: 1472.5063\n",
            "Epoch 165/500, Loss: 1472.7367\n",
            "Epoch 166/500, Loss: 1470.7296\n",
            "Epoch 167/500, Loss: 1466.9147\n",
            "Epoch 168/500, Loss: 1468.9093\n",
            "Epoch 169/500, Loss: 1463.8103\n",
            "Epoch 170/500, Loss: 1457.9143\n",
            "Epoch 171/500, Loss: 1453.6527\n",
            "Epoch 172/500, Loss: 1454.8481\n",
            "Epoch 173/500, Loss: 1446.3773\n",
            "Epoch 174/500, Loss: 1441.2051\n",
            "Epoch 175/500, Loss: 1442.9923\n",
            "Epoch 176/500, Loss: 1444.4067\n",
            "Epoch 177/500, Loss: 1445.2914\n",
            "Epoch 178/500, Loss: 1469.9680\n",
            "Epoch 179/500, Loss: 1514.4246\n",
            "Epoch 180/500, Loss: 1527.2408\n",
            "Epoch 181/500, Loss: 1457.2344\n",
            "Epoch 182/500, Loss: 1443.0684\n",
            "Epoch 183/500, Loss: 1492.1195\n",
            "Epoch 184/500, Loss: 1464.5083\n",
            "Epoch 185/500, Loss: 1443.5770\n",
            "Epoch 186/500, Loss: 1447.0988\n",
            "Epoch 187/500, Loss: 1443.4645\n",
            "Epoch 188/500, Loss: 1436.7114\n",
            "Epoch 189/500, Loss: 1441.7435\n",
            "Epoch 190/500, Loss: 1465.8409\n",
            "Epoch 191/500, Loss: 1453.8361\n",
            "Epoch 192/500, Loss: 1440.1478\n",
            "Epoch 193/500, Loss: 1544.8164\n",
            "Epoch 194/500, Loss: 1677.3068\n",
            "Epoch 195/500, Loss: 1498.0491\n",
            "Epoch 196/500, Loss: 1575.0435\n",
            "Epoch 197/500, Loss: 1594.0441\n",
            "Epoch 198/500, Loss: 1539.7201\n",
            "Epoch 199/500, Loss: 2345.5942\n",
            "Epoch 200/500, Loss: 2602.2935\n",
            "Epoch 201/500, Loss: 1622.3756\n",
            "Epoch 202/500, Loss: 1569.9504\n",
            "Epoch 203/500, Loss: 1541.1058\n",
            "Epoch 204/500, Loss: 1550.8596\n",
            "Epoch 205/500, Loss: 1546.5034\n",
            "Epoch 206/500, Loss: 1502.5305\n",
            "Epoch 207/500, Loss: 1505.1879\n",
            "Epoch 208/500, Loss: 1497.0917\n",
            "Epoch 209/500, Loss: 1519.7566\n",
            "Epoch 210/500, Loss: 1510.8810\n",
            "Epoch 211/500, Loss: 1492.4391\n",
            "Epoch 212/500, Loss: 1484.1432\n",
            "Epoch 213/500, Loss: 1485.8254\n",
            "Epoch 214/500, Loss: 1501.9524\n",
            "Epoch 215/500, Loss: 1600.5745\n",
            "Epoch 216/500, Loss: 1708.4792\n",
            "Epoch 217/500, Loss: 1552.6792\n",
            "Epoch 218/500, Loss: 1516.0439\n",
            "Epoch 219/500, Loss: 1546.4713\n",
            "Epoch 220/500, Loss: 1499.6069\n",
            "Epoch 221/500, Loss: 1520.4613\n",
            "Epoch 222/500, Loss: 1497.3848\n",
            "Epoch 223/500, Loss: 1498.4575\n",
            "Epoch 224/500, Loss: 1482.1482\n",
            "Epoch 225/500, Loss: 1569.8578\n",
            "Epoch 226/500, Loss: 1557.3424\n",
            "Epoch 227/500, Loss: 1538.4672\n",
            "Epoch 228/500, Loss: 1488.5925\n",
            "Epoch 229/500, Loss: 1481.6960\n",
            "Epoch 230/500, Loss: 1584.1705\n",
            "Epoch 231/500, Loss: 1543.5649\n",
            "Epoch 232/500, Loss: 1536.6923\n",
            "Epoch 233/500, Loss: 1475.1478\n",
            "Epoch 234/500, Loss: 1496.2627\n",
            "Epoch 235/500, Loss: 1511.2949\n",
            "Epoch 236/500, Loss: 1490.8328\n",
            "Epoch 237/500, Loss: 1470.2727\n",
            "Epoch 238/500, Loss: 1471.1626\n",
            "Epoch 239/500, Loss: 1481.1417\n",
            "Epoch 240/500, Loss: 1476.7812\n",
            "Epoch 241/500, Loss: 1470.9247\n",
            "Epoch 242/500, Loss: 1477.5376\n",
            "Epoch 243/500, Loss: 1460.3073\n",
            "Epoch 244/500, Loss: 1469.2123\n",
            "Epoch 245/500, Loss: 1464.4247\n",
            "Epoch 246/500, Loss: 1465.9933\n",
            "Epoch 247/500, Loss: 1464.3585\n",
            "Epoch 248/500, Loss: 1461.0157\n",
            "Epoch 249/500, Loss: 1492.6981\n",
            "Epoch 250/500, Loss: 1483.5260\n",
            "Epoch 251/500, Loss: 1475.7504\n",
            "Epoch 252/500, Loss: 1474.5176\n",
            "Epoch 253/500, Loss: 1459.7107\n",
            "Epoch 254/500, Loss: 1465.5525\n",
            "Epoch 255/500, Loss: 1466.1647\n",
            "Epoch 256/500, Loss: 1491.4719\n",
            "Epoch 257/500, Loss: 1496.2839\n",
            "Epoch 258/500, Loss: 1496.3927\n",
            "Epoch 259/500, Loss: 1508.8557\n",
            "Epoch 260/500, Loss: 1986.6437\n",
            "Epoch 261/500, Loss: 2032.3184\n",
            "Epoch 262/500, Loss: 1499.9814\n",
            "Epoch 263/500, Loss: 1627.6523\n",
            "Epoch 264/500, Loss: 1533.3998\n",
            "Epoch 265/500, Loss: 1517.2960\n",
            "Epoch 266/500, Loss: 1552.3160\n",
            "Epoch 267/500, Loss: 1512.2738\n",
            "Epoch 268/500, Loss: 1532.6711\n",
            "Epoch 269/500, Loss: 1528.6235\n",
            "Epoch 270/500, Loss: 1603.5879\n",
            "Epoch 271/500, Loss: 1474.4679\n",
            "Epoch 272/500, Loss: 1507.5083\n",
            "Epoch 273/500, Loss: 1500.0796\n",
            "Epoch 274/500, Loss: 1495.2959\n",
            "Epoch 275/500, Loss: 1498.9946\n",
            "Epoch 276/500, Loss: 1479.7911\n",
            "Epoch 277/500, Loss: 1535.9678\n",
            "Epoch 278/500, Loss: 2357.8757\n",
            "Epoch 279/500, Loss: 2212.2227\n",
            "Epoch 280/500, Loss: 1957.0568\n",
            "Epoch 281/500, Loss: 11000.5273\n",
            "Epoch 282/500, Loss: 21413.6387\n",
            "Epoch 283/500, Loss: 8416.1133\n",
            "Epoch 284/500, Loss: 2127.4814\n",
            "Epoch 285/500, Loss: 1856.7418\n",
            "Epoch 286/500, Loss: 2035.1470\n",
            "Epoch 287/500, Loss: 2356.8413\n",
            "Epoch 288/500, Loss: 1681.8931\n",
            "Epoch 289/500, Loss: 2127.4653\n",
            "Epoch 290/500, Loss: 2097.5381\n",
            "Epoch 291/500, Loss: 1717.4316\n",
            "Epoch 292/500, Loss: 1537.2239\n",
            "Epoch 293/500, Loss: 2076.4841\n",
            "Epoch 294/500, Loss: 8277.3047\n",
            "Epoch 295/500, Loss: 6565.4536\n",
            "Epoch 296/500, Loss: 2884.0586\n",
            "Epoch 297/500, Loss: 4208.1641\n",
            "Epoch 298/500, Loss: 19747.7305\n",
            "Epoch 299/500, Loss: 12245.6240\n",
            "Epoch 300/500, Loss: 3542.4558\n",
            "Epoch 301/500, Loss: 6399.1890\n",
            "Epoch 302/500, Loss: 16529.1914\n",
            "Epoch 303/500, Loss: 3345.1951\n",
            "Epoch 304/500, Loss: 6578.1279\n",
            "Epoch 305/500, Loss: 6906.7227\n",
            "Epoch 306/500, Loss: 28394.3164\n",
            "Epoch 307/500, Loss: 63988.7734\n",
            "Epoch 308/500, Loss: 5029.5200\n",
            "Epoch 309/500, Loss: 14559.1318\n",
            "Epoch 310/500, Loss: 2271.2021\n",
            "Epoch 311/500, Loss: 5837.0728\n",
            "Epoch 312/500, Loss: 1627.0607\n",
            "Epoch 313/500, Loss: 2294.3374\n",
            "Epoch 314/500, Loss: 1510.4922\n",
            "Epoch 315/500, Loss: 1579.3917\n",
            "Epoch 316/500, Loss: 1496.2919\n",
            "Epoch 317/500, Loss: 1535.3898\n",
            "Epoch 318/500, Loss: 1497.0729\n",
            "Epoch 319/500, Loss: 1469.8779\n",
            "Epoch 320/500, Loss: 1473.3263\n",
            "Epoch 321/500, Loss: 1479.4576\n",
            "Epoch 322/500, Loss: 1477.4701\n",
            "Epoch 323/500, Loss: 1480.0630\n",
            "Epoch 324/500, Loss: 1501.9039\n",
            "Epoch 325/500, Loss: 1478.4409\n",
            "Epoch 326/500, Loss: 1484.9192\n",
            "Epoch 327/500, Loss: 1484.8718\n",
            "Epoch 328/500, Loss: 1475.7095\n",
            "Epoch 329/500, Loss: 1478.2028\n",
            "Epoch 330/500, Loss: 1478.2234\n",
            "Epoch 331/500, Loss: 1477.6243\n",
            "Epoch 332/500, Loss: 1471.4005\n",
            "Epoch 333/500, Loss: 1475.6921\n",
            "Epoch 334/500, Loss: 1471.2446\n",
            "Epoch 335/500, Loss: 1470.2445\n",
            "Epoch 336/500, Loss: 1471.1792\n",
            "Epoch 337/500, Loss: 1471.4879\n",
            "Epoch 338/500, Loss: 1470.1459\n",
            "Epoch 339/500, Loss: 1467.9429\n",
            "Epoch 340/500, Loss: 1468.1329\n",
            "Epoch 341/500, Loss: 1468.4948\n",
            "Epoch 342/500, Loss: 1470.7404\n",
            "Epoch 343/500, Loss: 1476.7223\n",
            "Epoch 344/500, Loss: 1468.2183\n",
            "Epoch 345/500, Loss: 1468.3158\n",
            "Epoch 346/500, Loss: 1458.2529\n",
            "Epoch 347/500, Loss: 1462.7443\n",
            "Epoch 348/500, Loss: 1458.3307\n",
            "Epoch 349/500, Loss: 1462.6394\n",
            "Epoch 350/500, Loss: 1453.7292\n",
            "Epoch 351/500, Loss: 1455.0570\n",
            "Epoch 352/500, Loss: 1446.6655\n",
            "Epoch 353/500, Loss: 1444.5104\n",
            "Epoch 354/500, Loss: 1442.8816\n",
            "Epoch 355/500, Loss: 1445.3210\n",
            "Epoch 356/500, Loss: 1443.1967\n",
            "Epoch 357/500, Loss: 1479.9219\n",
            "Epoch 358/500, Loss: 1479.7991\n",
            "Epoch 359/500, Loss: 1474.6281\n",
            "Epoch 360/500, Loss: 1482.7922\n",
            "Epoch 361/500, Loss: 1465.3784\n",
            "Epoch 362/500, Loss: 1484.5608\n",
            "Epoch 363/500, Loss: 1472.8733\n",
            "Epoch 364/500, Loss: 1469.5326\n",
            "Epoch 365/500, Loss: 1484.3011\n",
            "Epoch 366/500, Loss: 1468.6091\n",
            "Epoch 367/500, Loss: 1473.6790\n",
            "Epoch 368/500, Loss: 1483.7308\n",
            "Epoch 369/500, Loss: 1449.1558\n",
            "Epoch 370/500, Loss: 1449.9659\n",
            "Epoch 371/500, Loss: 1445.3251\n",
            "Epoch 372/500, Loss: 1495.7511\n",
            "Epoch 373/500, Loss: 1475.9468\n",
            "Epoch 374/500, Loss: 1467.6498\n",
            "Epoch 375/500, Loss: 1494.3824\n",
            "Epoch 376/500, Loss: 1503.7188\n",
            "Epoch 377/500, Loss: 1571.6466\n",
            "Epoch 378/500, Loss: 1486.2025\n",
            "Epoch 379/500, Loss: 1496.0958\n",
            "Epoch 380/500, Loss: 1491.8406\n",
            "Epoch 381/500, Loss: 1493.5602\n",
            "Epoch 382/500, Loss: 1491.0599\n",
            "Epoch 383/500, Loss: 1487.8475\n",
            "Epoch 384/500, Loss: 1485.5410\n",
            "Epoch 385/500, Loss: 1464.6831\n",
            "Epoch 386/500, Loss: 1473.5758\n",
            "Epoch 387/500, Loss: 1467.9938\n",
            "Epoch 388/500, Loss: 1459.9723\n",
            "Epoch 389/500, Loss: 1476.0510\n",
            "Epoch 390/500, Loss: 1465.4640\n",
            "Epoch 391/500, Loss: 1463.8739\n",
            "Epoch 392/500, Loss: 1465.4990\n",
            "Epoch 393/500, Loss: 1446.6100\n",
            "Epoch 394/500, Loss: 1452.2001\n",
            "Epoch 395/500, Loss: 1449.3022\n",
            "Epoch 396/500, Loss: 1442.7236\n",
            "Epoch 397/500, Loss: 1444.0173\n",
            "Epoch 398/500, Loss: 1436.6182\n",
            "Epoch 399/500, Loss: 1437.3297\n",
            "Epoch 400/500, Loss: 1432.2589\n",
            "Epoch 401/500, Loss: 1453.3579\n",
            "Epoch 402/500, Loss: 1451.3312\n",
            "Epoch 403/500, Loss: 1447.2832\n",
            "Epoch 404/500, Loss: 1447.8888\n",
            "Epoch 405/500, Loss: 1445.7091\n",
            "Epoch 406/500, Loss: 1441.3931\n",
            "Epoch 407/500, Loss: 1440.9552\n",
            "Epoch 408/500, Loss: 1448.1149\n",
            "Epoch 409/500, Loss: 1448.7045\n",
            "Epoch 410/500, Loss: 1510.2789\n",
            "Epoch 411/500, Loss: 1452.4509\n",
            "Epoch 412/500, Loss: 1449.0739\n",
            "Epoch 413/500, Loss: 1447.6447\n",
            "Epoch 414/500, Loss: 1435.1243\n",
            "Epoch 415/500, Loss: 1431.0367\n",
            "Epoch 416/500, Loss: 1447.8854\n",
            "Epoch 417/500, Loss: 1498.7057\n",
            "Epoch 418/500, Loss: 1580.5354\n",
            "Epoch 419/500, Loss: 1479.8792\n",
            "Epoch 420/500, Loss: 1486.8053\n",
            "Epoch 421/500, Loss: 1469.2412\n",
            "Epoch 422/500, Loss: 1466.5316\n",
            "Epoch 423/500, Loss: 1480.9902\n",
            "Epoch 424/500, Loss: 1481.9572\n",
            "Epoch 425/500, Loss: 1467.6506\n",
            "Epoch 426/500, Loss: 1457.2390\n",
            "Epoch 427/500, Loss: 1455.0336\n",
            "Epoch 428/500, Loss: 1481.4113\n",
            "Epoch 429/500, Loss: 1598.9716\n",
            "Epoch 430/500, Loss: 1848.7056\n",
            "Epoch 431/500, Loss: 1489.9977\n",
            "Epoch 432/500, Loss: 1595.2611\n",
            "Epoch 433/500, Loss: 8439.2412\n",
            "Epoch 434/500, Loss: 2419.1768\n",
            "Epoch 435/500, Loss: 1546.8043\n",
            "Epoch 436/500, Loss: 1584.8966\n",
            "Epoch 437/500, Loss: 1664.2023\n",
            "Epoch 438/500, Loss: 1542.0592\n",
            "Epoch 439/500, Loss: 1537.7739\n",
            "Epoch 440/500, Loss: 1559.6292\n",
            "Epoch 441/500, Loss: 1550.8221\n",
            "Epoch 442/500, Loss: 1542.7529\n",
            "Epoch 443/500, Loss: 1538.1301\n",
            "Epoch 444/500, Loss: 1535.0164\n",
            "Epoch 445/500, Loss: 1534.6818\n",
            "Epoch 446/500, Loss: 1534.6725\n",
            "Epoch 447/500, Loss: 1534.8215\n",
            "Epoch 448/500, Loss: 1535.2500\n",
            "Epoch 449/500, Loss: 1534.6360\n",
            "Epoch 450/500, Loss: 1535.9358\n",
            "Epoch 451/500, Loss: 1534.6105\n",
            "Epoch 452/500, Loss: 1534.5972\n",
            "Epoch 453/500, Loss: 1534.5836\n",
            "Epoch 454/500, Loss: 1534.5695\n",
            "Epoch 455/500, Loss: 1534.5553\n",
            "Epoch 456/500, Loss: 1534.5410\n",
            "Epoch 457/500, Loss: 1534.5264\n",
            "Epoch 458/500, Loss: 1534.5116\n",
            "Epoch 459/500, Loss: 1534.4965\n",
            "Epoch 460/500, Loss: 1534.4813\n",
            "Epoch 461/500, Loss: 1534.4659\n",
            "Epoch 462/500, Loss: 1534.4504\n",
            "Epoch 463/500, Loss: 1534.4347\n",
            "Epoch 464/500, Loss: 1534.4191\n",
            "Epoch 465/500, Loss: 1534.4033\n",
            "Epoch 466/500, Loss: 1534.3876\n",
            "Epoch 467/500, Loss: 1534.3717\n",
            "Epoch 468/500, Loss: 1534.3556\n",
            "Epoch 469/500, Loss: 1534.3394\n",
            "Epoch 470/500, Loss: 1534.3232\n",
            "Epoch 471/500, Loss: 1534.3070\n",
            "Epoch 472/500, Loss: 1534.2904\n",
            "Epoch 473/500, Loss: 1534.2743\n",
            "Epoch 474/500, Loss: 1534.2579\n",
            "Epoch 475/500, Loss: 1534.2415\n",
            "Epoch 476/500, Loss: 1534.2249\n",
            "Epoch 477/500, Loss: 1534.2083\n",
            "Epoch 478/500, Loss: 1534.1920\n",
            "Epoch 479/500, Loss: 1534.1752\n",
            "Epoch 480/500, Loss: 1534.1584\n",
            "Epoch 481/500, Loss: 1534.1417\n",
            "Epoch 482/500, Loss: 1534.1254\n",
            "Epoch 483/500, Loss: 1534.1084\n",
            "Epoch 484/500, Loss: 1534.0919\n",
            "Epoch 485/500, Loss: 1534.0751\n",
            "Epoch 486/500, Loss: 1534.0580\n",
            "Epoch 487/500, Loss: 1534.0413\n",
            "Epoch 488/500, Loss: 1534.0243\n",
            "Epoch 489/500, Loss: 1534.0073\n",
            "Epoch 490/500, Loss: 1533.9906\n",
            "Epoch 491/500, Loss: 1533.9739\n",
            "Epoch 492/500, Loss: 1533.9569\n",
            "Epoch 493/500, Loss: 1533.9397\n",
            "Epoch 494/500, Loss: 1533.9227\n",
            "Epoch 495/500, Loss: 1533.9058\n",
            "Epoch 496/500, Loss: 1533.8888\n",
            "Epoch 497/500, Loss: 1533.8717\n",
            "Epoch 498/500, Loss: 1533.8545\n",
            "Epoch 499/500, Loss: 1533.8374\n",
            "Epoch 500/500, Loss: 1533.8204\n",
            "Training complete.\n",
            "Test Loss: 3382.5105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-2*** : Extracting llm embeddings and along with additional features we use a ml model (Random forest regressor) to predict the same."
      ],
      "metadata": {
        "id": "ISAzDpk-agLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "print(f'Shape of text_embeddings: {text_embeddings.shape}')\n",
        "print(f'Shape of additional_features: {additional_features.shape}')\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable\n",
        "y = df['score'].values  # Replace 'score' with your actual target column\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print test loss (e.g., Mean Squared Error)\n",
        "mse = np.mean((test_predictions - y_test) ** 2)\n",
        "print(f'Test Mean Squared Error: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMV6ZNhxa3jg",
        "outputId": "5c2b2402-8140-49a4-8144-f821c127fc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of text_embeddings: (600, 768)\n",
            "Shape of additional_features: torch.Size([600, 6])\n",
            "Test Mean Squared Error: 3437.0377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-3*** : Using tf-idf vectoriser for the text data and then use it as feature apart from the additional features on a ml model."
      ],
      "metadata": {
        "id": "tG9pVgrYdd2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "\n",
        "# Check if the necessary columns exist in the dataset\n",
        "# Extracting text from the 'body' column and defining the target variable\n",
        "texts = df['body']\n",
        "y = df['score']  # Continuous target variable\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "\n",
        "# Fit and transform the text data to generate TF-IDF features\n",
        "X_tfidf = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R-squared: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31XYwwnyeHIL",
        "outputId": "11404427-65c0-438f-bbf8-dfe3a23cd11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 4051.6476\n",
            "R-squared: -0.2406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-4***: using Tf-idf vectorizer and gnn to do the same prediction.\n"
      ],
      "metadata": {
        "id": "PL48gBNCgb_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT (No longer needed for TF-IDF)\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "# distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function to get TF-IDF embeddings\n",
        "def get_tfidf_embeddings(texts):\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Limit to 5000 features for better performance\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
        "    return torch.tensor(tfidf_matrix.toarray(), dtype=torch.float)\n",
        "\n",
        "# Get TF-IDF embeddings for the text column\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_tfidf_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['score'].values, dtype=torch.float)  # Replace 'score' with your actual target column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    \"\"\"Function to create KNN-based edges.\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15  # Number of nearest neighbors for KNN\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        # Fully connected layer for the final output (virality score)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GNN model\n",
        "input_dim = X.shape[1]  # Combined dimension of TF-IDF embeddings and additional features\n",
        "model = GNNModel(input_dim=input_dim)\n",
        "\n",
        "# Move the model to device (GPU/CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()  # Assuming the virality score is a continuous integer value\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass for the entire training set\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "\n",
        "    # Backpropagation and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Optionally, you can evaluate the model on the test set here.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Create edge index for the test set (optional, if you need to evaluate on edges)\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "\n",
        "    # Forward pass on the test set\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "\n",
        "    # Compute the test loss if you have the corresponding test labels\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY15NdRwhE59",
        "outputId": "2ed57c7b-a1f5-4d93-f1d2-e6ef29fef4ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 1534.3875\n",
            "Epoch 2/500, Loss: 1500.0795\n",
            "Epoch 3/500, Loss: 1885.8322\n",
            "Epoch 4/500, Loss: 1490.7983\n",
            "Epoch 5/500, Loss: 1519.3062\n",
            "Epoch 6/500, Loss: 1530.7145\n",
            "Epoch 7/500, Loss: 1533.0515\n",
            "Epoch 8/500, Loss: 1533.3130\n",
            "Epoch 9/500, Loss: 1533.0995\n",
            "Epoch 10/500, Loss: 1532.7345\n",
            "Epoch 11/500, Loss: 1532.2312\n",
            "Epoch 12/500, Loss: 1531.5188\n",
            "Epoch 13/500, Loss: 1530.5568\n",
            "Epoch 14/500, Loss: 1529.2365\n",
            "Epoch 15/500, Loss: 1527.4252\n",
            "Epoch 16/500, Loss: 1524.9370\n",
            "Epoch 17/500, Loss: 1521.5386\n",
            "Epoch 18/500, Loss: 1516.9335\n",
            "Epoch 19/500, Loss: 1510.7855\n",
            "Epoch 20/500, Loss: 1502.8652\n",
            "Epoch 21/500, Loss: 1493.5225\n",
            "Epoch 22/500, Loss: 1485.1348\n",
            "Epoch 23/500, Loss: 1484.5416\n",
            "Epoch 24/500, Loss: 1494.0226\n",
            "Epoch 25/500, Loss: 1493.4806\n",
            "Epoch 26/500, Loss: 1486.1261\n",
            "Epoch 27/500, Loss: 1481.5803\n",
            "Epoch 28/500, Loss: 1481.2412\n",
            "Epoch 29/500, Loss: 1482.6445\n",
            "Epoch 30/500, Loss: 1483.8319\n",
            "Epoch 31/500, Loss: 1483.9620\n",
            "Epoch 32/500, Loss: 1482.9058\n",
            "Epoch 33/500, Loss: 1481.0594\n",
            "Epoch 34/500, Loss: 1479.3411\n",
            "Epoch 35/500, Loss: 1478.8726\n",
            "Epoch 36/500, Loss: 1479.7817\n",
            "Epoch 37/500, Loss: 1480.2324\n",
            "Epoch 38/500, Loss: 1479.2413\n",
            "Epoch 39/500, Loss: 1477.8590\n",
            "Epoch 40/500, Loss: 1477.1583\n",
            "Epoch 41/500, Loss: 1477.1350\n",
            "Epoch 42/500, Loss: 1477.2834\n",
            "Epoch 43/500, Loss: 1477.1970\n",
            "Epoch 44/500, Loss: 1476.7506\n",
            "Epoch 45/500, Loss: 1476.0906\n",
            "Epoch 46/500, Loss: 1475.5165\n",
            "Epoch 47/500, Loss: 1475.2224\n",
            "Epoch 48/500, Loss: 1475.0157\n",
            "Epoch 49/500, Loss: 1474.4861\n",
            "Epoch 50/500, Loss: 1473.6116\n",
            "Epoch 51/500, Loss: 1472.7480\n",
            "Epoch 52/500, Loss: 1472.0850\n",
            "Epoch 53/500, Loss: 1471.4955\n",
            "Epoch 54/500, Loss: 1470.7749\n",
            "Epoch 55/500, Loss: 1469.8634\n",
            "Epoch 56/500, Loss: 1468.8467\n",
            "Epoch 57/500, Loss: 1467.8043\n",
            "Epoch 58/500, Loss: 1466.6392\n",
            "Epoch 59/500, Loss: 1465.1897\n",
            "Epoch 60/500, Loss: 1463.4772\n",
            "Epoch 61/500, Loss: 1461.6666\n",
            "Epoch 62/500, Loss: 1459.6848\n",
            "Epoch 63/500, Loss: 1457.3878\n",
            "Epoch 64/500, Loss: 1454.7734\n",
            "Epoch 65/500, Loss: 1451.8406\n",
            "Epoch 66/500, Loss: 1448.5176\n",
            "Epoch 67/500, Loss: 1444.8087\n",
            "Epoch 68/500, Loss: 1440.7980\n",
            "Epoch 69/500, Loss: 1436.2433\n",
            "Epoch 70/500, Loss: 1430.9562\n",
            "Epoch 71/500, Loss: 1425.0713\n",
            "Epoch 72/500, Loss: 1418.5909\n",
            "Epoch 73/500, Loss: 1411.1987\n",
            "Epoch 74/500, Loss: 1402.8383\n",
            "Epoch 75/500, Loss: 1393.1564\n",
            "Epoch 76/500, Loss: 1382.5293\n",
            "Epoch 77/500, Loss: 1370.8966\n",
            "Epoch 78/500, Loss: 1359.0190\n",
            "Epoch 79/500, Loss: 1346.4027\n",
            "Epoch 80/500, Loss: 1333.7234\n",
            "Epoch 81/500, Loss: 1321.1083\n",
            "Epoch 82/500, Loss: 1308.3241\n",
            "Epoch 83/500, Loss: 1296.6331\n",
            "Epoch 84/500, Loss: 1286.6514\n",
            "Epoch 85/500, Loss: 1280.8179\n",
            "Epoch 86/500, Loss: 1272.6567\n",
            "Epoch 87/500, Loss: 1271.2178\n",
            "Epoch 88/500, Loss: 1271.4835\n",
            "Epoch 89/500, Loss: 1266.3079\n",
            "Epoch 90/500, Loss: 1265.3267\n",
            "Epoch 91/500, Loss: 1259.5862\n",
            "Epoch 92/500, Loss: 1259.1868\n",
            "Epoch 93/500, Loss: 1256.0304\n",
            "Epoch 94/500, Loss: 1256.7426\n",
            "Epoch 95/500, Loss: 1256.5380\n",
            "Epoch 96/500, Loss: 1254.4260\n",
            "Epoch 97/500, Loss: 1255.9944\n",
            "Epoch 98/500, Loss: 1255.0031\n",
            "Epoch 99/500, Loss: 1253.9443\n",
            "Epoch 100/500, Loss: 1256.7153\n",
            "Epoch 101/500, Loss: 1254.9630\n",
            "Epoch 102/500, Loss: 1255.2251\n",
            "Epoch 103/500, Loss: 1252.3821\n",
            "Epoch 104/500, Loss: 1254.0889\n",
            "Epoch 105/500, Loss: 1252.5466\n",
            "Epoch 106/500, Loss: 1251.1086\n",
            "Epoch 107/500, Loss: 1251.3999\n",
            "Epoch 108/500, Loss: 1249.1697\n",
            "Epoch 109/500, Loss: 1250.0864\n",
            "Epoch 110/500, Loss: 1247.4313\n",
            "Epoch 111/500, Loss: 1248.2806\n",
            "Epoch 112/500, Loss: 1246.5592\n",
            "Epoch 113/500, Loss: 1246.0240\n",
            "Epoch 114/500, Loss: 1245.8545\n",
            "Epoch 115/500, Loss: 1244.5281\n",
            "Epoch 116/500, Loss: 1244.2782\n",
            "Epoch 117/500, Loss: 1243.7351\n",
            "Epoch 118/500, Loss: 1242.5507\n",
            "Epoch 119/500, Loss: 1242.7920\n",
            "Epoch 120/500, Loss: 1241.8038\n",
            "Epoch 121/500, Loss: 1241.4058\n",
            "Epoch 122/500, Loss: 1241.0493\n",
            "Epoch 123/500, Loss: 1240.4124\n",
            "Epoch 124/500, Loss: 1239.7219\n",
            "Epoch 125/500, Loss: 1239.4265\n",
            "Epoch 126/500, Loss: 1238.8557\n",
            "Epoch 127/500, Loss: 1238.2736\n",
            "Epoch 128/500, Loss: 1237.9520\n",
            "Epoch 129/500, Loss: 1237.4888\n",
            "Epoch 130/500, Loss: 1237.0344\n",
            "Epoch 131/500, Loss: 1236.6150\n",
            "Epoch 132/500, Loss: 1235.9834\n",
            "Epoch 133/500, Loss: 1235.3823\n",
            "Epoch 134/500, Loss: 1234.8375\n",
            "Epoch 135/500, Loss: 1234.2384\n",
            "Epoch 136/500, Loss: 1233.7322\n",
            "Epoch 137/500, Loss: 1233.2864\n",
            "Epoch 138/500, Loss: 1232.6110\n",
            "Epoch 139/500, Loss: 1231.9949\n",
            "Epoch 140/500, Loss: 1231.1899\n",
            "Epoch 141/500, Loss: 1230.2740\n",
            "Epoch 142/500, Loss: 1229.4553\n",
            "Epoch 143/500, Loss: 1228.4951\n",
            "Epoch 144/500, Loss: 1227.4631\n",
            "Epoch 145/500, Loss: 1226.1503\n",
            "Epoch 146/500, Loss: 1224.6104\n",
            "Epoch 147/500, Loss: 1222.8536\n",
            "Epoch 148/500, Loss: 1220.6730\n",
            "Epoch 149/500, Loss: 1218.2836\n",
            "Epoch 150/500, Loss: 1215.5018\n",
            "Epoch 151/500, Loss: 1213.0815\n",
            "Epoch 152/500, Loss: 1214.1952\n",
            "Epoch 153/500, Loss: 1213.8221\n",
            "Epoch 154/500, Loss: 1210.8695\n",
            "Epoch 155/500, Loss: 1198.6310\n",
            "Epoch 156/500, Loss: 1212.3561\n",
            "Epoch 157/500, Loss: 1226.9768\n",
            "Epoch 158/500, Loss: 1223.6119\n",
            "Epoch 159/500, Loss: 1186.4351\n",
            "Epoch 160/500, Loss: 1227.1833\n",
            "Epoch 161/500, Loss: 1210.0575\n",
            "Epoch 162/500, Loss: 1249.9689\n",
            "Epoch 163/500, Loss: 1213.9320\n",
            "Epoch 164/500, Loss: 1172.4569\n",
            "Epoch 165/500, Loss: 1237.1069\n",
            "Epoch 166/500, Loss: 1169.2152\n",
            "Epoch 167/500, Loss: 1205.6980\n",
            "Epoch 168/500, Loss: 1203.9835\n",
            "Epoch 169/500, Loss: 1168.5161\n",
            "Epoch 170/500, Loss: 1172.4142\n",
            "Epoch 171/500, Loss: 1177.1897\n",
            "Epoch 172/500, Loss: 1147.0891\n",
            "Epoch 173/500, Loss: 1160.6113\n",
            "Epoch 174/500, Loss: 1155.6671\n",
            "Epoch 175/500, Loss: 1133.7216\n",
            "Epoch 176/500, Loss: 1142.8998\n",
            "Epoch 177/500, Loss: 1131.0376\n",
            "Epoch 178/500, Loss: 1120.8899\n",
            "Epoch 179/500, Loss: 1123.9795\n",
            "Epoch 180/500, Loss: 1107.8022\n",
            "Epoch 181/500, Loss: 1105.2201\n",
            "Epoch 182/500, Loss: 1094.6672\n",
            "Epoch 183/500, Loss: 1088.9404\n",
            "Epoch 184/500, Loss: 1077.6571\n",
            "Epoch 185/500, Loss: 1075.6158\n",
            "Epoch 186/500, Loss: 1060.4883\n",
            "Epoch 187/500, Loss: 1061.2849\n",
            "Epoch 188/500, Loss: 1046.8276\n",
            "Epoch 189/500, Loss: 1035.4071\n",
            "Epoch 190/500, Loss: 1036.8843\n",
            "Epoch 191/500, Loss: 1025.9492\n",
            "Epoch 192/500, Loss: 1035.7341\n",
            "Epoch 193/500, Loss: 1010.6701\n",
            "Epoch 194/500, Loss: 1019.4680\n",
            "Epoch 195/500, Loss: 991.6808\n",
            "Epoch 196/500, Loss: 995.8959\n",
            "Epoch 197/500, Loss: 988.6402\n",
            "Epoch 198/500, Loss: 1049.2256\n",
            "Epoch 199/500, Loss: 988.0031\n",
            "Epoch 200/500, Loss: 1074.7340\n",
            "Epoch 201/500, Loss: 1425.9391\n",
            "Epoch 202/500, Loss: 1471.1923\n",
            "Epoch 203/500, Loss: 1446.8646\n",
            "Epoch 204/500, Loss: 1366.6038\n",
            "Epoch 205/500, Loss: 1058.4951\n",
            "Epoch 206/500, Loss: 1589.4073\n",
            "Epoch 207/500, Loss: 1112.1499\n",
            "Epoch 208/500, Loss: 1356.8938\n",
            "Epoch 209/500, Loss: 1390.5477\n",
            "Epoch 210/500, Loss: 1401.4380\n",
            "Epoch 211/500, Loss: 1424.7622\n",
            "Epoch 212/500, Loss: 1422.1263\n",
            "Epoch 213/500, Loss: 1402.8336\n",
            "Epoch 214/500, Loss: 1389.5425\n",
            "Epoch 215/500, Loss: 1380.4126\n",
            "Epoch 216/500, Loss: 1360.1102\n",
            "Epoch 217/500, Loss: 1327.0309\n",
            "Epoch 218/500, Loss: 1262.9717\n",
            "Epoch 219/500, Loss: 1181.3632\n",
            "Epoch 220/500, Loss: 1122.8104\n",
            "Epoch 221/500, Loss: 1253.5292\n",
            "Epoch 222/500, Loss: 1177.5142\n",
            "Epoch 223/500, Loss: 1104.1959\n",
            "Epoch 224/500, Loss: 1157.0618\n",
            "Epoch 225/500, Loss: 1175.2249\n",
            "Epoch 226/500, Loss: 1152.1670\n",
            "Epoch 227/500, Loss: 1092.1899\n",
            "Epoch 228/500, Loss: 1039.9015\n",
            "Epoch 229/500, Loss: 1114.5815\n",
            "Epoch 230/500, Loss: 1055.5477\n",
            "Epoch 231/500, Loss: 1024.5526\n",
            "Epoch 232/500, Loss: 1055.2699\n",
            "Epoch 233/500, Loss: 1032.6904\n",
            "Epoch 234/500, Loss: 1006.4571\n",
            "Epoch 235/500, Loss: 1030.2714\n",
            "Epoch 236/500, Loss: 1018.1099\n",
            "Epoch 237/500, Loss: 990.5304\n",
            "Epoch 238/500, Loss: 997.8977\n",
            "Epoch 239/500, Loss: 999.2141\n",
            "Epoch 240/500, Loss: 982.5683\n",
            "Epoch 241/500, Loss: 980.7202\n",
            "Epoch 242/500, Loss: 983.2313\n",
            "Epoch 243/500, Loss: 964.6680\n",
            "Epoch 244/500, Loss: 960.3776\n",
            "Epoch 245/500, Loss: 964.9692\n",
            "Epoch 246/500, Loss: 951.9292\n",
            "Epoch 247/500, Loss: 946.0025\n",
            "Epoch 248/500, Loss: 945.4633\n",
            "Epoch 249/500, Loss: 931.8301\n",
            "Epoch 250/500, Loss: 929.4108\n",
            "Epoch 251/500, Loss: 923.9351\n",
            "Epoch 252/500, Loss: 912.7285\n",
            "Epoch 253/500, Loss: 909.9568\n",
            "Epoch 254/500, Loss: 896.5754\n",
            "Epoch 255/500, Loss: 894.0040\n",
            "Epoch 256/500, Loss: 882.7281\n",
            "Epoch 257/500, Loss: 876.0297\n",
            "Epoch 258/500, Loss: 865.2151\n",
            "Epoch 259/500, Loss: 856.6406\n",
            "Epoch 260/500, Loss: 845.2527\n",
            "Epoch 261/500, Loss: 837.1275\n",
            "Epoch 262/500, Loss: 823.7319\n",
            "Epoch 263/500, Loss: 816.0832\n",
            "Epoch 264/500, Loss: 803.6802\n",
            "Epoch 265/500, Loss: 789.6146\n",
            "Epoch 266/500, Loss: 776.0541\n",
            "Epoch 267/500, Loss: 762.6042\n",
            "Epoch 268/500, Loss: 750.2192\n",
            "Epoch 269/500, Loss: 747.9644\n",
            "Epoch 270/500, Loss: 866.4063\n",
            "Epoch 271/500, Loss: 1229.6212\n",
            "Epoch 272/500, Loss: 1391.8993\n",
            "Epoch 273/500, Loss: 1475.1567\n",
            "Epoch 274/500, Loss: 1465.3418\n",
            "Epoch 275/500, Loss: 1466.3778\n",
            "Epoch 276/500, Loss: 1476.6658\n",
            "Epoch 277/500, Loss: 1474.5590\n",
            "Epoch 278/500, Loss: 1463.0465\n",
            "Epoch 279/500, Loss: 1464.4772\n",
            "Epoch 280/500, Loss: 1471.8774\n",
            "Epoch 281/500, Loss: 1468.8226\n",
            "Epoch 282/500, Loss: 1462.8571\n",
            "Epoch 283/500, Loss: 1464.3646\n",
            "Epoch 284/500, Loss: 1467.2887\n",
            "Epoch 285/500, Loss: 1463.9497\n",
            "Epoch 286/500, Loss: 1460.8131\n",
            "Epoch 287/500, Loss: 1462.9792\n",
            "Epoch 288/500, Loss: 1464.2411\n",
            "Epoch 289/500, Loss: 1460.9744\n",
            "Epoch 290/500, Loss: 1458.5986\n",
            "Epoch 291/500, Loss: 1462.5970\n",
            "Epoch 292/500, Loss: 1459.4983\n",
            "Epoch 293/500, Loss: 1458.7271\n",
            "Epoch 294/500, Loss: 1460.7042\n",
            "Epoch 295/500, Loss: 1460.0739\n",
            "Epoch 296/500, Loss: 1457.8374\n",
            "Epoch 297/500, Loss: 1458.9415\n",
            "Epoch 298/500, Loss: 1458.6295\n",
            "Epoch 299/500, Loss: 1456.7778\n",
            "Epoch 300/500, Loss: 1457.5797\n",
            "Epoch 301/500, Loss: 1457.7383\n",
            "Epoch 302/500, Loss: 1456.2882\n",
            "Epoch 303/500, Loss: 1456.2487\n",
            "Epoch 304/500, Loss: 1456.9346\n",
            "Epoch 305/500, Loss: 1455.5887\n",
            "Epoch 306/500, Loss: 1455.5322\n",
            "Epoch 307/500, Loss: 1455.8870\n",
            "Epoch 308/500, Loss: 1455.0098\n",
            "Epoch 309/500, Loss: 1454.6840\n",
            "Epoch 310/500, Loss: 1454.9609\n",
            "Epoch 311/500, Loss: 1454.2814\n",
            "Epoch 312/500, Loss: 1454.1517\n",
            "Epoch 313/500, Loss: 1454.2728\n",
            "Epoch 314/500, Loss: 1453.7626\n",
            "Epoch 315/500, Loss: 1453.5935\n",
            "Epoch 316/500, Loss: 1453.7159\n",
            "Epoch 317/500, Loss: 1453.2327\n",
            "Epoch 318/500, Loss: 1453.0496\n",
            "Epoch 319/500, Loss: 1453.0836\n",
            "Epoch 320/500, Loss: 1452.7306\n",
            "Epoch 321/500, Loss: 1452.5907\n",
            "Epoch 322/500, Loss: 1452.5483\n",
            "Epoch 323/500, Loss: 1452.2484\n",
            "Epoch 324/500, Loss: 1452.1753\n",
            "Epoch 325/500, Loss: 1452.0333\n",
            "Epoch 326/500, Loss: 1451.7645\n",
            "Epoch 327/500, Loss: 1451.7096\n",
            "Epoch 328/500, Loss: 1451.5198\n",
            "Epoch 329/500, Loss: 1451.3198\n",
            "Epoch 330/500, Loss: 1451.2469\n",
            "Epoch 331/500, Loss: 1451.0449\n",
            "Epoch 332/500, Loss: 1450.8998\n",
            "Epoch 333/500, Loss: 1450.7855\n",
            "Epoch 334/500, Loss: 1450.5750\n",
            "Epoch 335/500, Loss: 1450.4695\n",
            "Epoch 336/500, Loss: 1450.3081\n",
            "Epoch 337/500, Loss: 1450.1396\n",
            "Epoch 338/500, Loss: 1450.0287\n",
            "Epoch 339/500, Loss: 1449.8564\n",
            "Epoch 340/500, Loss: 1449.7274\n",
            "Epoch 341/500, Loss: 1449.5790\n",
            "Epoch 342/500, Loss: 1449.4026\n",
            "Epoch 343/500, Loss: 1449.2313\n",
            "Epoch 344/500, Loss: 1448.9728\n",
            "Epoch 345/500, Loss: 1448.7151\n",
            "Epoch 346/500, Loss: 1448.4418\n",
            "Epoch 347/500, Loss: 1448.2896\n",
            "Epoch 348/500, Loss: 1448.1812\n",
            "Epoch 349/500, Loss: 1448.0367\n",
            "Epoch 350/500, Loss: 1447.9381\n",
            "Epoch 351/500, Loss: 1447.8384\n",
            "Epoch 352/500, Loss: 1447.7281\n",
            "Epoch 353/500, Loss: 1447.5861\n",
            "Epoch 354/500, Loss: 1447.4098\n",
            "Epoch 355/500, Loss: 1447.2269\n",
            "Epoch 356/500, Loss: 1447.0332\n",
            "Epoch 357/500, Loss: 1446.8552\n",
            "Epoch 358/500, Loss: 1446.6877\n",
            "Epoch 359/500, Loss: 1446.5275\n",
            "Epoch 360/500, Loss: 1446.3562\n",
            "Epoch 361/500, Loss: 1446.1799\n",
            "Epoch 362/500, Loss: 1445.9905\n",
            "Epoch 363/500, Loss: 1445.8096\n",
            "Epoch 364/500, Loss: 1445.6317\n",
            "Epoch 365/500, Loss: 1445.4568\n",
            "Epoch 366/500, Loss: 1445.2828\n",
            "Epoch 367/500, Loss: 1445.1130\n",
            "Epoch 368/500, Loss: 1444.9497\n",
            "Epoch 369/500, Loss: 1444.8003\n",
            "Epoch 370/500, Loss: 1444.6603\n",
            "Epoch 371/500, Loss: 1444.5244\n",
            "Epoch 372/500, Loss: 1444.3829\n",
            "Epoch 373/500, Loss: 1444.3008\n",
            "Epoch 374/500, Loss: 1444.1172\n",
            "Epoch 375/500, Loss: 1444.0002\n",
            "Epoch 376/500, Loss: 1443.8743\n",
            "Epoch 377/500, Loss: 1443.7546\n",
            "Epoch 378/500, Loss: 1443.6348\n",
            "Epoch 379/500, Loss: 1443.4976\n",
            "Epoch 380/500, Loss: 1443.3722\n",
            "Epoch 381/500, Loss: 1443.2260\n",
            "Epoch 382/500, Loss: 1443.1045\n",
            "Epoch 383/500, Loss: 1442.9568\n",
            "Epoch 384/500, Loss: 1442.8435\n",
            "Epoch 385/500, Loss: 1442.7145\n",
            "Epoch 386/500, Loss: 1442.5909\n",
            "Epoch 387/500, Loss: 1442.4615\n",
            "Epoch 388/500, Loss: 1442.3250\n",
            "Epoch 389/500, Loss: 1442.2084\n",
            "Epoch 390/500, Loss: 1442.0697\n",
            "Epoch 391/500, Loss: 1441.9458\n",
            "Epoch 392/500, Loss: 1441.8112\n",
            "Epoch 393/500, Loss: 1441.6775\n",
            "Epoch 394/500, Loss: 1441.5519\n",
            "Epoch 395/500, Loss: 1441.4176\n",
            "Epoch 396/500, Loss: 1441.2883\n",
            "Epoch 397/500, Loss: 1441.1605\n",
            "Epoch 398/500, Loss: 1441.0225\n",
            "Epoch 399/500, Loss: 1440.9700\n",
            "Epoch 400/500, Loss: 1440.8606\n",
            "Epoch 401/500, Loss: 1440.8188\n",
            "Epoch 402/500, Loss: 1440.6993\n",
            "Epoch 403/500, Loss: 1440.5831\n",
            "Epoch 404/500, Loss: 1440.4434\n",
            "Epoch 405/500, Loss: 1440.3157\n",
            "Epoch 406/500, Loss: 1440.2445\n",
            "Epoch 407/500, Loss: 1440.1335\n",
            "Epoch 408/500, Loss: 1439.9910\n",
            "Epoch 409/500, Loss: 1439.8538\n",
            "Epoch 410/500, Loss: 1439.7216\n",
            "Epoch 411/500, Loss: 1439.6250\n",
            "Epoch 412/500, Loss: 1439.5254\n",
            "Epoch 413/500, Loss: 1439.3883\n",
            "Epoch 414/500, Loss: 1439.2667\n",
            "Epoch 415/500, Loss: 1439.1426\n",
            "Epoch 416/500, Loss: 1439.0358\n",
            "Epoch 417/500, Loss: 1438.9382\n",
            "Epoch 418/500, Loss: 1438.8226\n",
            "Epoch 419/500, Loss: 1438.7001\n",
            "Epoch 420/500, Loss: 1438.5844\n",
            "Epoch 421/500, Loss: 1438.4846\n",
            "Epoch 422/500, Loss: 1438.3816\n",
            "Epoch 423/500, Loss: 1438.2820\n",
            "Epoch 424/500, Loss: 1438.1696\n",
            "Epoch 425/500, Loss: 1438.0706\n",
            "Epoch 426/500, Loss: 1438.0070\n",
            "Epoch 427/500, Loss: 1437.9896\n",
            "Epoch 428/500, Loss: 1438.0323\n",
            "Epoch 429/500, Loss: 1438.4338\n",
            "Epoch 430/500, Loss: 1439.1263\n",
            "Epoch 431/500, Loss: 1442.0515\n",
            "Epoch 432/500, Loss: 1440.9436\n",
            "Epoch 433/500, Loss: 1443.4069\n",
            "Epoch 434/500, Loss: 1437.7531\n",
            "Epoch 435/500, Loss: 1438.8818\n",
            "Epoch 436/500, Loss: 1445.4292\n",
            "Epoch 437/500, Loss: 1437.6938\n",
            "Epoch 438/500, Loss: 1439.6018\n",
            "Epoch 439/500, Loss: 1448.5477\n",
            "Epoch 440/500, Loss: 1437.0024\n",
            "Epoch 441/500, Loss: 1455.1749\n",
            "Epoch 442/500, Loss: 1471.6848\n",
            "Epoch 443/500, Loss: 1481.0004\n",
            "Epoch 444/500, Loss: 1475.9688\n",
            "Epoch 445/500, Loss: 1473.5244\n",
            "Epoch 446/500, Loss: 1471.9495\n",
            "Epoch 447/500, Loss: 1472.6331\n",
            "Epoch 448/500, Loss: 1472.7092\n",
            "Epoch 449/500, Loss: 1471.3015\n",
            "Epoch 450/500, Loss: 1470.7579\n",
            "Epoch 451/500, Loss: 1470.7688\n",
            "Epoch 452/500, Loss: 1470.0081\n",
            "Epoch 453/500, Loss: 1469.8645\n",
            "Epoch 454/500, Loss: 1469.9537\n",
            "Epoch 455/500, Loss: 1469.3992\n",
            "Epoch 456/500, Loss: 1469.3407\n",
            "Epoch 457/500, Loss: 1469.4268\n",
            "Epoch 458/500, Loss: 1468.9973\n",
            "Epoch 459/500, Loss: 1468.9586\n",
            "Epoch 460/500, Loss: 1468.9033\n",
            "Epoch 461/500, Loss: 1468.1615\n",
            "Epoch 462/500, Loss: 1464.0107\n",
            "Epoch 463/500, Loss: 1447.9746\n",
            "Epoch 464/500, Loss: 1463.1128\n",
            "Epoch 465/500, Loss: 1487.1958\n",
            "Epoch 466/500, Loss: 1472.3453\n",
            "Epoch 467/500, Loss: 1438.8531\n",
            "Epoch 468/500, Loss: 1455.9487\n",
            "Epoch 469/500, Loss: 1439.0221\n",
            "Epoch 470/500, Loss: 1462.4457\n",
            "Epoch 471/500, Loss: 1434.5654\n",
            "Epoch 472/500, Loss: 1429.9769\n",
            "Epoch 473/500, Loss: 1421.2277\n",
            "Epoch 474/500, Loss: 1417.7062\n",
            "Epoch 475/500, Loss: 1416.6671\n",
            "Epoch 476/500, Loss: 1390.6350\n",
            "Epoch 477/500, Loss: 1372.4052\n",
            "Epoch 478/500, Loss: 1372.2809\n",
            "Epoch 479/500, Loss: 1361.8204\n",
            "Epoch 480/500, Loss: 1353.6593\n",
            "Epoch 481/500, Loss: 1337.7723\n",
            "Epoch 482/500, Loss: 1335.9152\n",
            "Epoch 483/500, Loss: 1344.1589\n",
            "Epoch 484/500, Loss: 1322.9996\n",
            "Epoch 485/500, Loss: 1343.4956\n",
            "Epoch 486/500, Loss: 1337.4105\n",
            "Epoch 487/500, Loss: 1359.1068\n",
            "Epoch 488/500, Loss: 1327.6760\n",
            "Epoch 489/500, Loss: 1294.3087\n",
            "Epoch 490/500, Loss: 1346.3049\n",
            "Epoch 491/500, Loss: 1285.0288\n",
            "Epoch 492/500, Loss: 1325.6122\n",
            "Epoch 493/500, Loss: 1319.1456\n",
            "Epoch 494/500, Loss: 1268.2131\n",
            "Epoch 495/500, Loss: 1290.6815\n",
            "Epoch 496/500, Loss: 1276.3678\n",
            "Epoch 497/500, Loss: 1257.5338\n",
            "Epoch 498/500, Loss: 1278.1854\n",
            "Epoch 499/500, Loss: 1269.5281\n",
            "Epoch 500/500, Loss: 1249.4099\n",
            "Training complete.\n",
            "Test Loss: 3345.0659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Method-4 P2***: using Tf-idf vectorizer and gat to do the same prediction.\n"
      ],
      "metadata": {
        "id": "ObpK_OaxfgdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Function to get TF-IDF embeddings\n",
        "def get_tfidf_embeddings(texts):\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
        "    return torch.tensor(tfidf_matrix.toarray(), dtype=torch.float)\n",
        "\n",
        "# Get TF-IDF embeddings for the text column\n",
        "texts = df['body']\n",
        "text_embeddings = get_tfidf_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['score'].values, dtype=torch.float)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    \"\"\"Function to create KNN-based edges.\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1, heads=8):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim1, heads=heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim1 * heads, hidden_dim2, heads=heads, concat=True)\n",
        "        self.conv3 = GATConv(hidden_dim2 * heads, hidden_dim3, heads=heads, concat=True)\n",
        "        self.conv4 = GATConv(hidden_dim3 * heads, hidden_dim4, heads=1, concat=False)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GNN model\n",
        "input_dim = X.shape[1]\n",
        "model = GNNModel(input_dim=input_dim)\n",
        "\n",
        "# Move the model to device (GPU/CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YyG1pFcflTQ",
        "outputId": "24ead049-0c2b-4a0b-f40f-b48b520dd270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Loss: 1533.8457\n",
            "Epoch 2/500, Loss: 156823.9844\n",
            "Epoch 3/500, Loss: 1511.4889\n",
            "Epoch 4/500, Loss: 1517.6553\n",
            "Epoch 5/500, Loss: 2638.5330\n",
            "Epoch 6/500, Loss: 1522.4720\n",
            "Epoch 7/500, Loss: 1536.0259\n",
            "Epoch 8/500, Loss: 1535.7510\n",
            "Epoch 9/500, Loss: 1533.9941\n",
            "Epoch 10/500, Loss: 1530.6277\n",
            "Epoch 11/500, Loss: 1522.9823\n",
            "Epoch 12/500, Loss: 1509.7566\n",
            "Epoch 13/500, Loss: 1504.5629\n",
            "Epoch 14/500, Loss: 1492.9875\n",
            "Epoch 15/500, Loss: 1480.7847\n",
            "Epoch 16/500, Loss: 1473.9805\n",
            "Epoch 17/500, Loss: 1470.9552\n",
            "Epoch 18/500, Loss: 1472.9191\n",
            "Epoch 19/500, Loss: 1473.0914\n",
            "Epoch 20/500, Loss: 1469.9844\n",
            "Epoch 21/500, Loss: 1470.7295\n",
            "Epoch 22/500, Loss: 1469.3387\n",
            "Epoch 23/500, Loss: 1470.2535\n",
            "Epoch 24/500, Loss: 1469.7292\n",
            "Epoch 25/500, Loss: 1469.2524\n",
            "Epoch 26/500, Loss: 1468.8286\n",
            "Epoch 27/500, Loss: 1468.3597\n",
            "Epoch 28/500, Loss: 1468.9203\n",
            "Epoch 29/500, Loss: 1468.4806\n",
            "Epoch 30/500, Loss: 1468.6406\n",
            "Epoch 31/500, Loss: 1468.3779\n",
            "Epoch 32/500, Loss: 1467.9939\n",
            "Epoch 33/500, Loss: 1468.1226\n",
            "Epoch 34/500, Loss: 1467.8779\n",
            "Epoch 35/500, Loss: 1467.8118\n",
            "Epoch 36/500, Loss: 1467.6897\n",
            "Epoch 37/500, Loss: 1467.2894\n",
            "Epoch 38/500, Loss: 1467.1606\n",
            "Epoch 39/500, Loss: 1467.0432\n",
            "Epoch 40/500, Loss: 1466.4528\n",
            "Epoch 41/500, Loss: 1466.0225\n",
            "Epoch 42/500, Loss: 1465.5441\n",
            "Epoch 43/500, Loss: 1464.6396\n",
            "Epoch 44/500, Loss: 1463.1111\n",
            "Epoch 45/500, Loss: 1460.7866\n",
            "Epoch 46/500, Loss: 1456.3716\n",
            "Epoch 47/500, Loss: 1448.2360\n",
            "Epoch 48/500, Loss: 1435.5004\n",
            "Epoch 49/500, Loss: 1416.9958\n",
            "Epoch 50/500, Loss: 1434.2142\n",
            "Epoch 51/500, Loss: 1473.5394\n",
            "Epoch 52/500, Loss: 1433.0730\n",
            "Epoch 53/500, Loss: 1453.2985\n",
            "Epoch 54/500, Loss: 1391.7123\n",
            "Epoch 55/500, Loss: 1323.8666\n",
            "Epoch 56/500, Loss: 1282.9718\n",
            "Epoch 57/500, Loss: 1152.3984\n",
            "Epoch 58/500, Loss: 1135.0243\n",
            "Epoch 59/500, Loss: 958.4664\n",
            "Epoch 60/500, Loss: 1761.1066\n",
            "Epoch 61/500, Loss: 884.5206\n",
            "Epoch 62/500, Loss: 1335.5665\n",
            "Epoch 63/500, Loss: 1411.0385\n",
            "Epoch 64/500, Loss: 1378.4186\n",
            "Epoch 65/500, Loss: 1251.4022\n",
            "Epoch 66/500, Loss: 1110.8839\n",
            "Epoch 67/500, Loss: 942.6844\n",
            "Epoch 68/500, Loss: 748.5317\n",
            "Epoch 69/500, Loss: 421.5173\n",
            "Epoch 70/500, Loss: 264.2770\n",
            "Epoch 71/500, Loss: 409.3634\n",
            "Epoch 72/500, Loss: 569.3052\n",
            "Epoch 73/500, Loss: 357.1003\n",
            "Epoch 74/500, Loss: 267.6624\n",
            "Epoch 75/500, Loss: 322.5551\n",
            "Epoch 76/500, Loss: 600.4210\n",
            "Epoch 77/500, Loss: 331.9796\n",
            "Epoch 78/500, Loss: 302.2244\n",
            "Epoch 79/500, Loss: 285.9167\n",
            "Epoch 80/500, Loss: 382.1249\n",
            "Epoch 81/500, Loss: 245.1768\n",
            "Epoch 82/500, Loss: 275.5512\n",
            "Epoch 83/500, Loss: 296.5480\n",
            "Epoch 84/500, Loss: 262.7841\n",
            "Epoch 85/500, Loss: 258.2585\n",
            "Epoch 86/500, Loss: 255.1963\n",
            "Epoch 87/500, Loss: 235.1526\n",
            "Epoch 88/500, Loss: 276.9936\n",
            "Epoch 89/500, Loss: 251.1378\n",
            "Epoch 90/500, Loss: 239.5054\n",
            "Epoch 91/500, Loss: 242.1801\n",
            "Epoch 92/500, Loss: 229.4927\n",
            "Epoch 93/500, Loss: 231.8546\n",
            "Epoch 94/500, Loss: 225.4499\n",
            "Epoch 95/500, Loss: 221.3528\n",
            "Epoch 96/500, Loss: 215.2689\n",
            "Epoch 97/500, Loss: 213.9659\n",
            "Epoch 98/500, Loss: 209.9104\n",
            "Epoch 99/500, Loss: 214.5367\n",
            "Epoch 100/500, Loss: 210.5026\n",
            "Epoch 101/500, Loss: 215.7608\n",
            "Epoch 102/500, Loss: 198.7484\n",
            "Epoch 103/500, Loss: 195.3786\n",
            "Epoch 104/500, Loss: 200.7764\n",
            "Epoch 105/500, Loss: 203.2162\n",
            "Epoch 106/500, Loss: 221.7379\n",
            "Epoch 107/500, Loss: 214.8518\n",
            "Epoch 108/500, Loss: 190.2281\n",
            "Epoch 109/500, Loss: 205.0307\n",
            "Epoch 110/500, Loss: 186.5329\n",
            "Epoch 111/500, Loss: 196.3703\n",
            "Epoch 112/500, Loss: 179.1830\n",
            "Epoch 113/500, Loss: 188.1891\n",
            "Epoch 114/500, Loss: 175.1369\n",
            "Epoch 115/500, Loss: 177.9797\n",
            "Epoch 116/500, Loss: 177.1504\n",
            "Epoch 117/500, Loss: 175.4524\n",
            "Epoch 118/500, Loss: 171.3245\n",
            "Epoch 119/500, Loss: 171.0650\n",
            "Epoch 120/500, Loss: 167.6653\n",
            "Epoch 121/500, Loss: 166.3869\n",
            "Epoch 122/500, Loss: 163.5257\n",
            "Epoch 123/500, Loss: 165.6366\n",
            "Epoch 124/500, Loss: 168.3967\n",
            "Epoch 125/500, Loss: 172.2509\n",
            "Epoch 126/500, Loss: 175.5184\n",
            "Epoch 127/500, Loss: 175.1819\n",
            "Epoch 128/500, Loss: 174.8455\n",
            "Epoch 129/500, Loss: 174.3562\n",
            "Epoch 130/500, Loss: 168.5068\n",
            "Epoch 131/500, Loss: 169.0606\n",
            "Epoch 132/500, Loss: 166.7874\n",
            "Epoch 133/500, Loss: 166.4603\n",
            "Epoch 134/500, Loss: 166.3696\n",
            "Epoch 135/500, Loss: 164.7767\n",
            "Epoch 136/500, Loss: 166.6112\n",
            "Epoch 137/500, Loss: 167.5855\n",
            "Epoch 138/500, Loss: 166.1376\n",
            "Epoch 139/500, Loss: 164.8509\n",
            "Epoch 140/500, Loss: 164.8422\n",
            "Epoch 141/500, Loss: 165.6473\n",
            "Epoch 142/500, Loss: 170.8431\n",
            "Epoch 143/500, Loss: 165.7469\n",
            "Epoch 144/500, Loss: 158.9558\n",
            "Epoch 145/500, Loss: 160.9736\n",
            "Epoch 146/500, Loss: 160.1663\n",
            "Epoch 147/500, Loss: 160.5492\n",
            "Epoch 148/500, Loss: 157.1383\n",
            "Epoch 149/500, Loss: 154.1755\n",
            "Epoch 150/500, Loss: 156.6802\n",
            "Epoch 151/500, Loss: 157.6957\n",
            "Epoch 152/500, Loss: 170.7020\n",
            "Epoch 153/500, Loss: 165.1262\n",
            "Epoch 154/500, Loss: 171.7465\n",
            "Epoch 155/500, Loss: 175.3305\n",
            "Epoch 156/500, Loss: 204.1176\n",
            "Epoch 157/500, Loss: 232.3516\n",
            "Epoch 158/500, Loss: 178.6336\n",
            "Epoch 159/500, Loss: 179.1174\n",
            "Epoch 160/500, Loss: 182.1810\n",
            "Epoch 161/500, Loss: 163.3117\n",
            "Epoch 162/500, Loss: 170.9507\n",
            "Epoch 163/500, Loss: 169.5972\n",
            "Epoch 164/500, Loss: 158.9986\n",
            "Epoch 165/500, Loss: 160.8972\n",
            "Epoch 166/500, Loss: 158.5151\n",
            "Epoch 167/500, Loss: 157.2555\n",
            "Epoch 168/500, Loss: 151.1275\n",
            "Epoch 169/500, Loss: 151.3026\n",
            "Epoch 170/500, Loss: 151.6376\n",
            "Epoch 171/500, Loss: 147.0242\n",
            "Epoch 172/500, Loss: 144.0834\n",
            "Epoch 173/500, Loss: 145.4540\n",
            "Epoch 174/500, Loss: 143.9797\n",
            "Epoch 175/500, Loss: 140.3383\n",
            "Epoch 176/500, Loss: 139.3320\n",
            "Epoch 177/500, Loss: 141.3264\n",
            "Epoch 178/500, Loss: 138.0714\n",
            "Epoch 179/500, Loss: 137.3156\n",
            "Epoch 180/500, Loss: 141.7191\n",
            "Epoch 181/500, Loss: 165.9571\n",
            "Epoch 182/500, Loss: 164.0937\n",
            "Epoch 183/500, Loss: 160.3932\n",
            "Epoch 184/500, Loss: 163.2534\n",
            "Epoch 185/500, Loss: 160.8475\n",
            "Epoch 186/500, Loss: 159.7335\n",
            "Epoch 187/500, Loss: 163.1972\n",
            "Epoch 188/500, Loss: 157.9843\n",
            "Epoch 189/500, Loss: 172.6149\n",
            "Epoch 190/500, Loss: 168.8405\n",
            "Epoch 191/500, Loss: 169.7729\n",
            "Epoch 192/500, Loss: 152.6482\n",
            "Epoch 193/500, Loss: 164.1554\n",
            "Epoch 194/500, Loss: 169.4268\n",
            "Epoch 195/500, Loss: 158.2855\n",
            "Epoch 196/500, Loss: 165.3419\n",
            "Epoch 197/500, Loss: 164.6376\n",
            "Epoch 198/500, Loss: 177.8762\n",
            "Epoch 199/500, Loss: 175.0805\n",
            "Epoch 200/500, Loss: 183.5565\n",
            "Epoch 201/500, Loss: 186.8376\n",
            "Epoch 202/500, Loss: 189.3159\n",
            "Epoch 203/500, Loss: 205.5986\n",
            "Epoch 204/500, Loss: 178.8447\n",
            "Epoch 205/500, Loss: 160.6779\n",
            "Epoch 206/500, Loss: 174.9413\n",
            "Epoch 207/500, Loss: 154.0222\n",
            "Epoch 208/500, Loss: 162.4814\n",
            "Epoch 209/500, Loss: 151.7617\n",
            "Epoch 210/500, Loss: 151.9766\n",
            "Epoch 211/500, Loss: 147.1046\n",
            "Epoch 212/500, Loss: 141.5121\n",
            "Epoch 213/500, Loss: 142.7049\n",
            "Epoch 214/500, Loss: 147.6532\n",
            "Epoch 215/500, Loss: 149.2094\n",
            "Epoch 216/500, Loss: 143.7398\n",
            "Epoch 217/500, Loss: 130.1701\n",
            "Epoch 218/500, Loss: 133.4051\n",
            "Epoch 219/500, Loss: 128.8126\n",
            "Epoch 220/500, Loss: 122.2543\n",
            "Epoch 221/500, Loss: 122.1601\n",
            "Epoch 222/500, Loss: 119.2195\n",
            "Epoch 223/500, Loss: 113.3682\n",
            "Epoch 224/500, Loss: 111.3374\n",
            "Epoch 225/500, Loss: 109.9063\n",
            "Epoch 226/500, Loss: 104.5063\n",
            "Epoch 227/500, Loss: 112.7724\n",
            "Epoch 228/500, Loss: 111.9198\n",
            "Epoch 229/500, Loss: 109.7803\n",
            "Epoch 230/500, Loss: 114.9669\n",
            "Epoch 231/500, Loss: 121.7633\n",
            "Epoch 232/500, Loss: 116.3958\n",
            "Epoch 233/500, Loss: 109.5236\n",
            "Epoch 234/500, Loss: 112.1167\n",
            "Epoch 235/500, Loss: 115.4161\n",
            "Epoch 236/500, Loss: 109.3155\n",
            "Epoch 237/500, Loss: 107.4870\n",
            "Epoch 238/500, Loss: 108.6073\n",
            "Epoch 239/500, Loss: 106.7814\n",
            "Epoch 240/500, Loss: 114.8979\n",
            "Epoch 241/500, Loss: 114.4648\n",
            "Epoch 242/500, Loss: 117.4392\n",
            "Epoch 243/500, Loss: 109.7707\n",
            "Epoch 244/500, Loss: 107.4454\n",
            "Epoch 245/500, Loss: 102.5368\n",
            "Epoch 246/500, Loss: 99.8090\n",
            "Epoch 247/500, Loss: 100.3016\n",
            "Epoch 248/500, Loss: 101.7400\n",
            "Epoch 249/500, Loss: 117.3778\n",
            "Epoch 250/500, Loss: 124.8472\n",
            "Epoch 251/500, Loss: 126.8866\n",
            "Epoch 252/500, Loss: 101.2853\n",
            "Epoch 253/500, Loss: 101.7905\n",
            "Epoch 254/500, Loss: 112.9121\n",
            "Epoch 255/500, Loss: 98.9024\n",
            "Epoch 256/500, Loss: 99.3434\n",
            "Epoch 257/500, Loss: 104.3441\n",
            "Epoch 258/500, Loss: 95.0567\n",
            "Epoch 259/500, Loss: 99.4475\n",
            "Epoch 260/500, Loss: 102.7796\n",
            "Epoch 261/500, Loss: 101.2097\n",
            "Epoch 262/500, Loss: 114.1426\n",
            "Epoch 263/500, Loss: 98.7253\n",
            "Epoch 264/500, Loss: 94.2673\n",
            "Epoch 265/500, Loss: 97.9759\n",
            "Epoch 266/500, Loss: 92.5313\n",
            "Epoch 267/500, Loss: 98.5977\n",
            "Epoch 268/500, Loss: 90.2013\n",
            "Epoch 269/500, Loss: 90.6985\n",
            "Epoch 270/500, Loss: 91.6450\n",
            "Epoch 271/500, Loss: 92.1286\n",
            "Epoch 272/500, Loss: 89.1878\n",
            "Epoch 273/500, Loss: 90.1980\n",
            "Epoch 274/500, Loss: 117.8122\n",
            "Epoch 275/500, Loss: 414.4453\n",
            "Epoch 276/500, Loss: 313.7386\n",
            "Epoch 277/500, Loss: 656.3339\n",
            "Epoch 278/500, Loss: 416.7503\n",
            "Epoch 279/500, Loss: 484.3200\n",
            "Epoch 280/500, Loss: 287.5463\n",
            "Epoch 281/500, Loss: 393.5963\n",
            "Epoch 282/500, Loss: 254.0732\n",
            "Epoch 283/500, Loss: 531.4935\n",
            "Epoch 284/500, Loss: 384.9863\n",
            "Epoch 285/500, Loss: 293.8910\n",
            "Epoch 286/500, Loss: 321.7662\n",
            "Epoch 287/500, Loss: 304.7108\n",
            "Epoch 288/500, Loss: 270.0065\n",
            "Epoch 289/500, Loss: 292.5006\n",
            "Epoch 290/500, Loss: 414.7767\n",
            "Epoch 291/500, Loss: 297.6706\n",
            "Epoch 292/500, Loss: 294.4200\n",
            "Epoch 293/500, Loss: 351.4623\n",
            "Epoch 294/500, Loss: 476.5331\n",
            "Epoch 295/500, Loss: 442.0147\n",
            "Epoch 296/500, Loss: 383.3007\n",
            "Epoch 297/500, Loss: 356.4619\n",
            "Epoch 298/500, Loss: 289.1323\n",
            "Epoch 299/500, Loss: 365.0576\n",
            "Epoch 300/500, Loss: 471.5977\n",
            "Epoch 301/500, Loss: 280.8578\n",
            "Epoch 302/500, Loss: 278.1484\n",
            "Epoch 303/500, Loss: 301.2895\n",
            "Epoch 304/500, Loss: 259.4614\n",
            "Epoch 305/500, Loss: 241.7463\n",
            "Epoch 306/500, Loss: 246.5427\n",
            "Epoch 307/500, Loss: 236.3810\n",
            "Epoch 308/500, Loss: 238.3597\n",
            "Epoch 309/500, Loss: 246.3393\n",
            "Epoch 310/500, Loss: 229.3985\n",
            "Epoch 311/500, Loss: 232.3886\n",
            "Epoch 312/500, Loss: 240.7103\n",
            "Epoch 313/500, Loss: 229.1111\n",
            "Epoch 314/500, Loss: 229.9038\n",
            "Epoch 315/500, Loss: 234.7650\n",
            "Epoch 316/500, Loss: 224.3751\n",
            "Epoch 317/500, Loss: 227.0471\n",
            "Epoch 318/500, Loss: 221.4602\n",
            "Epoch 319/500, Loss: 222.5052\n",
            "Epoch 320/500, Loss: 217.5981\n",
            "Epoch 321/500, Loss: 218.1846\n",
            "Epoch 322/500, Loss: 217.6093\n",
            "Epoch 323/500, Loss: 214.9464\n",
            "Epoch 324/500, Loss: 214.0170\n",
            "Epoch 325/500, Loss: 213.9665\n",
            "Epoch 326/500, Loss: 215.7166\n",
            "Epoch 327/500, Loss: 214.1935\n",
            "Epoch 328/500, Loss: 211.8400\n",
            "Epoch 329/500, Loss: 215.0019\n",
            "Epoch 330/500, Loss: 221.9404\n",
            "Epoch 331/500, Loss: 233.4341\n",
            "Epoch 332/500, Loss: 226.8040\n",
            "Epoch 333/500, Loss: 209.3106\n",
            "Epoch 334/500, Loss: 222.8069\n",
            "Epoch 335/500, Loss: 323.1763\n",
            "Epoch 336/500, Loss: 277.3527\n",
            "Epoch 337/500, Loss: 292.4439\n",
            "Epoch 338/500, Loss: 293.0212\n",
            "Epoch 339/500, Loss: 270.4244\n",
            "Epoch 340/500, Loss: 688.6340\n",
            "Epoch 341/500, Loss: 574.3045\n",
            "Epoch 342/500, Loss: 464.0397\n",
            "Epoch 343/500, Loss: 299.5144\n",
            "Epoch 344/500, Loss: 363.5941\n",
            "Epoch 345/500, Loss: 248.9125\n",
            "Epoch 346/500, Loss: 295.5096\n",
            "Epoch 347/500, Loss: 293.0058\n",
            "Epoch 348/500, Loss: 261.2002\n",
            "Epoch 349/500, Loss: 253.6930\n",
            "Epoch 350/500, Loss: 268.2527\n",
            "Epoch 351/500, Loss: 237.2408\n",
            "Epoch 352/500, Loss: 240.6048\n",
            "Epoch 353/500, Loss: 253.4811\n",
            "Epoch 354/500, Loss: 231.7282\n",
            "Epoch 355/500, Loss: 256.3359\n",
            "Epoch 356/500, Loss: 239.6949\n",
            "Epoch 357/500, Loss: 246.6493\n",
            "Epoch 358/500, Loss: 239.5373\n",
            "Epoch 359/500, Loss: 230.1161\n",
            "Epoch 360/500, Loss: 230.4201\n",
            "Epoch 361/500, Loss: 226.4158\n",
            "Epoch 362/500, Loss: 232.7977\n",
            "Epoch 363/500, Loss: 228.1989\n",
            "Epoch 364/500, Loss: 228.5816\n",
            "Epoch 365/500, Loss: 227.1539\n",
            "Epoch 366/500, Loss: 222.6277\n",
            "Epoch 367/500, Loss: 223.9698\n",
            "Epoch 368/500, Loss: 221.0599\n",
            "Epoch 369/500, Loss: 219.4933\n",
            "Epoch 370/500, Loss: 223.3971\n",
            "Epoch 371/500, Loss: 222.7558\n",
            "Epoch 372/500, Loss: 224.0762\n",
            "Epoch 373/500, Loss: 222.8426\n",
            "Epoch 374/500, Loss: 220.3019\n",
            "Epoch 375/500, Loss: 218.7507\n",
            "Epoch 376/500, Loss: 220.8880\n",
            "Epoch 377/500, Loss: 223.1374\n",
            "Epoch 378/500, Loss: 221.2053\n",
            "Epoch 379/500, Loss: 225.4983\n",
            "Epoch 380/500, Loss: 223.1859\n",
            "Epoch 381/500, Loss: 224.4859\n",
            "Epoch 382/500, Loss: 221.8404\n",
            "Epoch 383/500, Loss: 223.7692\n",
            "Epoch 384/500, Loss: 225.8959\n",
            "Epoch 385/500, Loss: 221.5301\n",
            "Epoch 386/500, Loss: 220.7879\n",
            "Epoch 387/500, Loss: 222.7457\n",
            "Epoch 388/500, Loss: 220.6797\n",
            "Epoch 389/500, Loss: 221.4193\n",
            "Epoch 390/500, Loss: 222.1443\n",
            "Epoch 391/500, Loss: 221.8517\n",
            "Epoch 392/500, Loss: 222.5535\n",
            "Epoch 393/500, Loss: 220.9765\n",
            "Epoch 394/500, Loss: 220.0552\n",
            "Epoch 395/500, Loss: 222.0555\n",
            "Epoch 396/500, Loss: 221.6876\n",
            "Epoch 397/500, Loss: 220.5959\n",
            "Epoch 398/500, Loss: 219.8053\n",
            "Epoch 399/500, Loss: 221.1723\n",
            "Epoch 400/500, Loss: 223.3804\n",
            "Epoch 401/500, Loss: 221.3004\n",
            "Epoch 402/500, Loss: 220.7443\n",
            "Epoch 403/500, Loss: 221.8463\n",
            "Epoch 404/500, Loss: 225.2840\n",
            "Epoch 405/500, Loss: 222.8033\n",
            "Epoch 406/500, Loss: 221.1461\n",
            "Epoch 407/500, Loss: 220.0859\n",
            "Epoch 408/500, Loss: 220.2522\n",
            "Epoch 409/500, Loss: 217.4934\n",
            "Epoch 410/500, Loss: 217.1372\n",
            "Epoch 411/500, Loss: 216.8365\n",
            "Epoch 412/500, Loss: 213.5099\n",
            "Epoch 413/500, Loss: 213.1219\n",
            "Epoch 414/500, Loss: 210.7503\n",
            "Epoch 415/500, Loss: 208.2600\n",
            "Epoch 416/500, Loss: 207.8327\n",
            "Epoch 417/500, Loss: 208.6895\n",
            "Epoch 418/500, Loss: 209.2907\n",
            "Epoch 419/500, Loss: 206.4223\n",
            "Epoch 420/500, Loss: 212.7399\n",
            "Epoch 421/500, Loss: 220.8953\n",
            "Epoch 422/500, Loss: 216.5466\n",
            "Epoch 423/500, Loss: 214.4764\n",
            "Epoch 424/500, Loss: 218.7065\n",
            "Epoch 425/500, Loss: 222.4827\n",
            "Epoch 426/500, Loss: 232.1783\n",
            "Epoch 427/500, Loss: 231.4181\n",
            "Epoch 428/500, Loss: 218.6045\n",
            "Epoch 429/500, Loss: 224.4296\n",
            "Epoch 430/500, Loss: 231.5056\n",
            "Epoch 431/500, Loss: 225.8000\n",
            "Epoch 432/500, Loss: 215.1111\n",
            "Epoch 433/500, Loss: 218.9240\n",
            "Epoch 434/500, Loss: 213.5333\n",
            "Epoch 435/500, Loss: 214.3459\n",
            "Epoch 436/500, Loss: 220.1138\n",
            "Epoch 437/500, Loss: 225.4853\n",
            "Epoch 438/500, Loss: 270.5511\n",
            "Epoch 439/500, Loss: 231.1526\n",
            "Epoch 440/500, Loss: 238.5670\n",
            "Epoch 441/500, Loss: 228.1628\n",
            "Epoch 442/500, Loss: 232.1129\n",
            "Epoch 443/500, Loss: 222.5125\n",
            "Epoch 444/500, Loss: 228.1221\n",
            "Epoch 445/500, Loss: 225.6564\n",
            "Epoch 446/500, Loss: 222.8847\n",
            "Epoch 447/500, Loss: 216.6636\n",
            "Epoch 448/500, Loss: 220.7892\n",
            "Epoch 449/500, Loss: 217.2993\n",
            "Epoch 450/500, Loss: 217.8637\n",
            "Epoch 451/500, Loss: 209.5754\n",
            "Epoch 452/500, Loss: 207.4597\n",
            "Epoch 453/500, Loss: 205.2627\n",
            "Epoch 454/500, Loss: 202.7781\n",
            "Epoch 455/500, Loss: 206.6920\n",
            "Epoch 456/500, Loss: 202.1388\n",
            "Epoch 457/500, Loss: 203.1388\n",
            "Epoch 458/500, Loss: 196.7935\n",
            "Epoch 459/500, Loss: 201.5229\n",
            "Epoch 460/500, Loss: 194.6660\n",
            "Epoch 461/500, Loss: 189.2345\n",
            "Epoch 462/500, Loss: 185.2429\n",
            "Epoch 463/500, Loss: 216.6231\n",
            "Epoch 464/500, Loss: 226.5942\n",
            "Epoch 465/500, Loss: 244.1677\n",
            "Epoch 466/500, Loss: 266.1429\n",
            "Epoch 467/500, Loss: 213.8807\n",
            "Epoch 468/500, Loss: 233.8340\n",
            "Epoch 469/500, Loss: 243.5968\n",
            "Epoch 470/500, Loss: 238.6294\n",
            "Epoch 471/500, Loss: 237.3990\n",
            "Epoch 472/500, Loss: 236.8287\n",
            "Epoch 473/500, Loss: 235.9276\n",
            "Epoch 474/500, Loss: 306.8216\n",
            "Epoch 475/500, Loss: 248.5085\n",
            "Epoch 476/500, Loss: 242.7601\n",
            "Epoch 477/500, Loss: 236.1025\n",
            "Epoch 478/500, Loss: 235.5452\n",
            "Epoch 479/500, Loss: 235.9866\n",
            "Epoch 480/500, Loss: 235.7077\n",
            "Epoch 481/500, Loss: 235.6448\n",
            "Epoch 482/500, Loss: 488.4122\n",
            "Epoch 483/500, Loss: 632.0942\n",
            "Epoch 484/500, Loss: 413.1238\n",
            "Epoch 485/500, Loss: 463.3759\n",
            "Epoch 486/500, Loss: 367.3294\n",
            "Epoch 487/500, Loss: 339.4246\n",
            "Epoch 488/500, Loss: 341.2174\n",
            "Epoch 489/500, Loss: 282.9577\n",
            "Epoch 490/500, Loss: 295.4860\n",
            "Epoch 491/500, Loss: 312.0416\n",
            "Epoch 492/500, Loss: 298.4096\n",
            "Epoch 493/500, Loss: 276.5341\n",
            "Epoch 494/500, Loss: 277.2305\n",
            "Epoch 495/500, Loss: 275.0471\n",
            "Epoch 496/500, Loss: 279.3408\n",
            "Epoch 497/500, Loss: 273.1510\n",
            "Epoch 498/500, Loss: 269.0077\n",
            "Epoch 499/500, Loss: 261.2223\n",
            "Epoch 500/500, Loss: 261.4189\n",
            "Training complete.\n",
            "Test Loss: 3470.7388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Extracting llm embeddings and then training it on gcn Dataset-2"
      ],
      "metadata": {
        "id": "rwDP-POsjfp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "# Set CUDA settings to avoid certain issues\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset and skip problematic rows if they exist\n",
        "try:\n",
        "    df = pd.read_csv('/content/sampled_modified_reddit_data.csv', on_bad_lines='skip')\n",
        "    print(\"Columns in dataset:\", df.columns)  # Print columns to verify the column names\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Parser error encountered. Some rows were skipped due to formatting issues.\")\n",
        "\n",
        "# Check if 'tags' column exists and apply one-hot encoding if available\n",
        "if 'tags' in df.columns:\n",
        "    df_one_hot = pd.get_dummies(df['tags'], prefix='tags')\n",
        "else:\n",
        "    print(\"Column 'tags' not found in the dataset. Proceeding without one-hot encoding.\")\n",
        "    df_one_hot = pd.DataFrame()  # Create an empty DataFrame if 'tags' is missing\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use mean pooling of embeddings across tokens\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the 'body' column\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Convert embeddings to torch tensor\n",
        "text_embeddings = torch.tensor(text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df[['Score']].values, dtype=torch.float)  # Changed from 'retweet_count' to 'Score'\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['Num of Comments'].values, dtype=torch.float)  # Assuming 'Num of Comments' is the target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    \"\"\"Function to create KNN-based edges.\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15  # Number of nearest neighbors for KNN\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GNN model\n",
        "input_dim = X.shape[1]\n",
        "model = GNNModel(input_dim=input_dim)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Optionally, you can evaluate the model on the test set here.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zdq0aI5jGJw",
        "outputId": "b804d8e7-64f1-4673-ccf2-cd51b5468906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['Political Lean', 'Score', 'Subreddit', 'Num of Comments', 'body'], dtype='object')\n",
            "Column 'tags' not found in the dataset. Proceeding without one-hot encoding.\n",
            "Epoch 1/500, Loss: 5113.5093\n",
            "Epoch 2/500, Loss: 20489.5723\n",
            "Epoch 3/500, Loss: 5685.7437\n",
            "Epoch 4/500, Loss: 5277.2925\n",
            "Epoch 5/500, Loss: 4871.7109\n",
            "Epoch 6/500, Loss: 4598.0352\n",
            "Epoch 7/500, Loss: 4251.2314\n",
            "Epoch 8/500, Loss: 3961.2810\n",
            "Epoch 9/500, Loss: 4067.0007\n",
            "Epoch 10/500, Loss: 3952.9634\n",
            "Epoch 11/500, Loss: 3852.7949\n",
            "Epoch 12/500, Loss: 3890.3438\n",
            "Epoch 13/500, Loss: 3887.6804\n",
            "Epoch 14/500, Loss: 3841.9863\n",
            "Epoch 15/500, Loss: 3809.0613\n",
            "Epoch 16/500, Loss: 3824.0352\n",
            "Epoch 17/500, Loss: 3806.9871\n",
            "Epoch 18/500, Loss: 3803.8560\n",
            "Epoch 19/500, Loss: 3801.9314\n",
            "Epoch 20/500, Loss: 3783.9414\n",
            "Epoch 21/500, Loss: 3791.5579\n",
            "Epoch 22/500, Loss: 3776.3508\n",
            "Epoch 23/500, Loss: 3779.2937\n",
            "Epoch 24/500, Loss: 3775.6335\n",
            "Epoch 25/500, Loss: 3773.1875\n",
            "Epoch 26/500, Loss: 3770.7449\n",
            "Epoch 27/500, Loss: 3766.1333\n",
            "Epoch 28/500, Loss: 3766.6216\n",
            "Epoch 29/500, Loss: 3761.2493\n",
            "Epoch 30/500, Loss: 3761.8848\n",
            "Epoch 31/500, Loss: 3756.7712\n",
            "Epoch 32/500, Loss: 3757.7622\n",
            "Epoch 33/500, Loss: 3753.3606\n",
            "Epoch 34/500, Loss: 3754.1814\n",
            "Epoch 35/500, Loss: 3749.9922\n",
            "Epoch 36/500, Loss: 3748.3806\n",
            "Epoch 37/500, Loss: 3745.8696\n",
            "Epoch 38/500, Loss: 3742.5859\n",
            "Epoch 39/500, Loss: 3741.6470\n",
            "Epoch 40/500, Loss: 3737.2644\n",
            "Epoch 41/500, Loss: 3735.7000\n",
            "Epoch 42/500, Loss: 3732.8984\n",
            "Epoch 43/500, Loss: 3728.3547\n",
            "Epoch 44/500, Loss: 3726.6938\n",
            "Epoch 45/500, Loss: 3723.9414\n",
            "Epoch 46/500, Loss: 3717.8391\n",
            "Epoch 47/500, Loss: 3713.2278\n",
            "Epoch 48/500, Loss: 3710.6814\n",
            "Epoch 49/500, Loss: 3712.3970\n",
            "Epoch 50/500, Loss: 3724.2410\n",
            "Epoch 51/500, Loss: 3709.6501\n",
            "Epoch 52/500, Loss: 3690.8367\n",
            "Epoch 53/500, Loss: 3689.0742\n",
            "Epoch 54/500, Loss: 3693.5847\n",
            "Epoch 55/500, Loss: 3691.1230\n",
            "Epoch 56/500, Loss: 3671.7205\n",
            "Epoch 57/500, Loss: 3670.6179\n",
            "Epoch 58/500, Loss: 3707.2185\n",
            "Epoch 59/500, Loss: 3686.1462\n",
            "Epoch 60/500, Loss: 3663.5012\n",
            "Epoch 61/500, Loss: 3675.0168\n",
            "Epoch 62/500, Loss: 3660.6482\n",
            "Epoch 63/500, Loss: 3642.3320\n",
            "Epoch 64/500, Loss: 3648.3613\n",
            "Epoch 65/500, Loss: 3650.4587\n",
            "Epoch 66/500, Loss: 3640.9048\n",
            "Epoch 67/500, Loss: 3625.3689\n",
            "Epoch 68/500, Loss: 3628.1775\n",
            "Epoch 69/500, Loss: 3628.1750\n",
            "Epoch 70/500, Loss: 3611.3923\n",
            "Epoch 71/500, Loss: 3608.8665\n",
            "Epoch 72/500, Loss: 3607.8132\n",
            "Epoch 73/500, Loss: 3590.0852\n",
            "Epoch 74/500, Loss: 3580.4895\n",
            "Epoch 75/500, Loss: 3588.3403\n",
            "Epoch 76/500, Loss: 3576.6316\n",
            "Epoch 77/500, Loss: 3557.4673\n",
            "Epoch 78/500, Loss: 3545.7136\n",
            "Epoch 79/500, Loss: 3532.8533\n",
            "Epoch 80/500, Loss: 3519.8853\n",
            "Epoch 81/500, Loss: 3507.1130\n",
            "Epoch 82/500, Loss: 3489.3774\n",
            "Epoch 83/500, Loss: 3474.3599\n",
            "Epoch 84/500, Loss: 3462.3201\n",
            "Epoch 85/500, Loss: 3554.2332\n",
            "Epoch 86/500, Loss: 3770.7864\n",
            "Epoch 87/500, Loss: 3904.8630\n",
            "Epoch 88/500, Loss: 3916.8679\n",
            "Epoch 89/500, Loss: 3804.3279\n",
            "Epoch 90/500, Loss: 3970.2598\n",
            "Epoch 91/500, Loss: 3737.6177\n",
            "Epoch 92/500, Loss: 3834.6257\n",
            "Epoch 93/500, Loss: 3864.0891\n",
            "Epoch 94/500, Loss: 3732.8574\n",
            "Epoch 95/500, Loss: 3716.4285\n",
            "Epoch 96/500, Loss: 3721.9114\n",
            "Epoch 97/500, Loss: 3641.8347\n",
            "Epoch 98/500, Loss: 3673.1445\n",
            "Epoch 99/500, Loss: 3704.9529\n",
            "Epoch 100/500, Loss: 3671.0625\n",
            "Epoch 101/500, Loss: 3661.5994\n",
            "Epoch 102/500, Loss: 3680.1353\n",
            "Epoch 103/500, Loss: 3628.4224\n",
            "Epoch 104/500, Loss: 3624.6138\n",
            "Epoch 105/500, Loss: 3633.7986\n",
            "Epoch 106/500, Loss: 3604.1367\n",
            "Epoch 107/500, Loss: 3597.8630\n",
            "Epoch 108/500, Loss: 3614.4055\n",
            "Epoch 109/500, Loss: 3585.3782\n",
            "Epoch 110/500, Loss: 3580.7297\n",
            "Epoch 111/500, Loss: 3585.1914\n",
            "Epoch 112/500, Loss: 3570.6958\n",
            "Epoch 113/500, Loss: 3562.6118\n",
            "Epoch 114/500, Loss: 3565.8298\n",
            "Epoch 115/500, Loss: 3552.0227\n",
            "Epoch 116/500, Loss: 3543.8484\n",
            "Epoch 117/500, Loss: 3543.4285\n",
            "Epoch 118/500, Loss: 3529.2676\n",
            "Epoch 119/500, Loss: 3521.1040\n",
            "Epoch 120/500, Loss: 3517.5969\n",
            "Epoch 121/500, Loss: 3500.8110\n",
            "Epoch 122/500, Loss: 3491.5688\n",
            "Epoch 123/500, Loss: 3475.5884\n",
            "Epoch 124/500, Loss: 3462.4478\n",
            "Epoch 125/500, Loss: 3445.4243\n",
            "Epoch 126/500, Loss: 3436.5215\n",
            "Epoch 127/500, Loss: 3419.3672\n",
            "Epoch 128/500, Loss: 3401.7322\n",
            "Epoch 129/500, Loss: 3384.6384\n",
            "Epoch 130/500, Loss: 3372.9880\n",
            "Epoch 131/500, Loss: 3347.9668\n",
            "Epoch 132/500, Loss: 3319.8528\n",
            "Epoch 133/500, Loss: 3296.9836\n",
            "Epoch 134/500, Loss: 3272.2043\n",
            "Epoch 135/500, Loss: 3270.5239\n",
            "Epoch 136/500, Loss: 3425.2747\n",
            "Epoch 137/500, Loss: 3672.9731\n",
            "Epoch 138/500, Loss: 3365.1523\n",
            "Epoch 139/500, Loss: 3221.4578\n",
            "Epoch 140/500, Loss: 3391.4263\n",
            "Epoch 141/500, Loss: 3208.7422\n",
            "Epoch 142/500, Loss: 3193.4661\n",
            "Epoch 143/500, Loss: 3281.0828\n",
            "Epoch 144/500, Loss: 3119.2083\n",
            "Epoch 145/500, Loss: 3196.8789\n",
            "Epoch 146/500, Loss: 3224.4822\n",
            "Epoch 147/500, Loss: 3138.3181\n",
            "Epoch 148/500, Loss: 3059.0681\n",
            "Epoch 149/500, Loss: 3199.3865\n",
            "Epoch 150/500, Loss: 3066.0510\n",
            "Epoch 151/500, Loss: 3011.8457\n",
            "Epoch 152/500, Loss: 3056.2322\n",
            "Epoch 153/500, Loss: 3096.0652\n",
            "Epoch 154/500, Loss: 3093.8696\n",
            "Epoch 155/500, Loss: 2956.9783\n",
            "Epoch 156/500, Loss: 2932.4258\n",
            "Epoch 157/500, Loss: 3015.3560\n",
            "Epoch 158/500, Loss: 3056.2952\n",
            "Epoch 159/500, Loss: 3180.2651\n",
            "Epoch 160/500, Loss: 3220.6282\n",
            "Epoch 161/500, Loss: 3020.0183\n",
            "Epoch 162/500, Loss: 2893.2842\n",
            "Epoch 163/500, Loss: 2941.7810\n",
            "Epoch 164/500, Loss: 2964.4490\n",
            "Epoch 165/500, Loss: 2961.1775\n",
            "Epoch 166/500, Loss: 2831.4478\n",
            "Epoch 167/500, Loss: 2860.5820\n",
            "Epoch 168/500, Loss: 2888.6436\n",
            "Epoch 169/500, Loss: 2805.0535\n",
            "Epoch 170/500, Loss: 2813.0288\n",
            "Epoch 171/500, Loss: 2798.5056\n",
            "Epoch 172/500, Loss: 2819.1360\n",
            "Epoch 173/500, Loss: 2867.4712\n",
            "Epoch 174/500, Loss: 2879.5786\n",
            "Epoch 175/500, Loss: 2896.6074\n",
            "Epoch 176/500, Loss: 3015.2300\n",
            "Epoch 177/500, Loss: 3059.1594\n",
            "Epoch 178/500, Loss: 2962.6372\n",
            "Epoch 179/500, Loss: 2789.1199\n",
            "Epoch 180/500, Loss: 2745.3301\n",
            "Epoch 181/500, Loss: 2786.1355\n",
            "Epoch 182/500, Loss: 2863.1296\n",
            "Epoch 183/500, Loss: 2728.5178\n",
            "Epoch 184/500, Loss: 2729.5657\n",
            "Epoch 185/500, Loss: 2787.8450\n",
            "Epoch 186/500, Loss: 2716.5740\n",
            "Epoch 187/500, Loss: 2738.0632\n",
            "Epoch 188/500, Loss: 2714.9761\n",
            "Epoch 189/500, Loss: 2657.3713\n",
            "Epoch 190/500, Loss: 2723.8826\n",
            "Epoch 191/500, Loss: 2736.4543\n",
            "Epoch 192/500, Loss: 2708.0371\n",
            "Epoch 193/500, Loss: 2752.2800\n",
            "Epoch 194/500, Loss: 2754.4280\n",
            "Epoch 195/500, Loss: 2709.2805\n",
            "Epoch 196/500, Loss: 2743.5059\n",
            "Epoch 197/500, Loss: 2870.8113\n",
            "Epoch 198/500, Loss: 2862.7771\n",
            "Epoch 199/500, Loss: 2848.7688\n",
            "Epoch 200/500, Loss: 2973.3237\n",
            "Epoch 201/500, Loss: 2758.8506\n",
            "Epoch 202/500, Loss: 2652.3708\n",
            "Epoch 203/500, Loss: 2778.7698\n",
            "Epoch 204/500, Loss: 2657.2302\n",
            "Epoch 205/500, Loss: 2732.4534\n",
            "Epoch 206/500, Loss: 2640.9109\n",
            "Epoch 207/500, Loss: 2663.9785\n",
            "Epoch 208/500, Loss: 2675.0608\n",
            "Epoch 209/500, Loss: 2598.7969\n",
            "Epoch 210/500, Loss: 2662.8760\n",
            "Epoch 211/500, Loss: 2593.8718\n",
            "Epoch 212/500, Loss: 2618.2485\n",
            "Epoch 213/500, Loss: 2600.9009\n",
            "Epoch 214/500, Loss: 2599.1140\n",
            "Epoch 215/500, Loss: 2601.6323\n",
            "Epoch 216/500, Loss: 2548.0994\n",
            "Epoch 217/500, Loss: 2572.7400\n",
            "Epoch 218/500, Loss: 2608.9946\n",
            "Epoch 219/500, Loss: 2596.9988\n",
            "Epoch 220/500, Loss: 2629.4355\n",
            "Epoch 221/500, Loss: 2708.7429\n",
            "Epoch 222/500, Loss: 2739.4080\n",
            "Epoch 223/500, Loss: 2727.4263\n",
            "Epoch 224/500, Loss: 2730.4329\n",
            "Epoch 225/500, Loss: 2625.0850\n",
            "Epoch 226/500, Loss: 2552.8281\n",
            "Epoch 227/500, Loss: 2633.0972\n",
            "Epoch 228/500, Loss: 2610.2949\n",
            "Epoch 229/500, Loss: 2573.5310\n",
            "Epoch 230/500, Loss: 2560.7458\n",
            "Epoch 231/500, Loss: 2576.1353\n",
            "Epoch 232/500, Loss: 2611.0730\n",
            "Epoch 233/500, Loss: 2553.1672\n",
            "Epoch 234/500, Loss: 2536.6770\n",
            "Epoch 235/500, Loss: 2566.8757\n",
            "Epoch 236/500, Loss: 2573.5889\n",
            "Epoch 237/500, Loss: 2560.4692\n",
            "Epoch 238/500, Loss: 2528.9646\n",
            "Epoch 239/500, Loss: 2527.8962\n",
            "Epoch 240/500, Loss: 2554.3396\n",
            "Epoch 241/500, Loss: 2563.9404\n",
            "Epoch 242/500, Loss: 2550.6064\n",
            "Epoch 243/500, Loss: 2541.6550\n",
            "Epoch 244/500, Loss: 2526.5017\n",
            "Epoch 245/500, Loss: 2512.7224\n",
            "Epoch 246/500, Loss: 2510.7168\n",
            "Epoch 247/500, Loss: 2521.0906\n",
            "Epoch 248/500, Loss: 2533.3140\n",
            "Epoch 249/500, Loss: 2561.4507\n",
            "Epoch 250/500, Loss: 2610.5955\n",
            "Epoch 251/500, Loss: 2674.7214\n",
            "Epoch 252/500, Loss: 2710.9592\n",
            "Epoch 253/500, Loss: 2655.1309\n",
            "Epoch 254/500, Loss: 2535.0439\n",
            "Epoch 255/500, Loss: 2536.9246\n",
            "Epoch 256/500, Loss: 2585.5781\n",
            "Epoch 257/500, Loss: 2568.6995\n",
            "Epoch 258/500, Loss: 2530.6516\n",
            "Epoch 259/500, Loss: 2535.5173\n",
            "Epoch 260/500, Loss: 2558.2029\n",
            "Epoch 261/500, Loss: 2523.0334\n",
            "Epoch 262/500, Loss: 2530.6904\n",
            "Epoch 263/500, Loss: 2549.2368\n",
            "Epoch 264/500, Loss: 2539.7205\n",
            "Epoch 265/500, Loss: 2521.7888\n",
            "Epoch 266/500, Loss: 2516.2227\n",
            "Epoch 267/500, Loss: 2539.4216\n",
            "Epoch 268/500, Loss: 2536.8027\n",
            "Epoch 269/500, Loss: 2518.4250\n",
            "Epoch 270/500, Loss: 2510.3816\n",
            "Epoch 271/500, Loss: 2521.0698\n",
            "Epoch 272/500, Loss: 2534.0671\n",
            "Epoch 273/500, Loss: 2537.4688\n",
            "Epoch 274/500, Loss: 2537.9758\n",
            "Epoch 275/500, Loss: 2526.0056\n",
            "Epoch 276/500, Loss: 2516.2285\n",
            "Epoch 277/500, Loss: 2508.4666\n",
            "Epoch 278/500, Loss: 2504.7576\n",
            "Epoch 279/500, Loss: 2502.2034\n",
            "Epoch 280/500, Loss: 2499.3425\n",
            "Epoch 281/500, Loss: 2503.0400\n",
            "Epoch 282/500, Loss: 2501.3704\n",
            "Epoch 283/500, Loss: 2506.9480\n",
            "Epoch 284/500, Loss: 2517.6106\n",
            "Epoch 285/500, Loss: 2540.0916\n",
            "Epoch 286/500, Loss: 2586.2327\n",
            "Epoch 287/500, Loss: 2646.0447\n",
            "Epoch 288/500, Loss: 2731.9802\n",
            "Epoch 289/500, Loss: 2721.7354\n",
            "Epoch 290/500, Loss: 2563.3511\n",
            "Epoch 291/500, Loss: 2520.9553\n",
            "Epoch 292/500, Loss: 2598.0383\n",
            "Epoch 293/500, Loss: 2580.0117\n",
            "Epoch 294/500, Loss: 2523.0405\n",
            "Epoch 295/500, Loss: 2562.8831\n",
            "Epoch 296/500, Loss: 2567.1001\n",
            "Epoch 297/500, Loss: 2513.6130\n",
            "Epoch 298/500, Loss: 2552.0261\n",
            "Epoch 299/500, Loss: 2540.5720\n",
            "Epoch 300/500, Loss: 2511.7029\n",
            "Epoch 301/500, Loss: 2535.7300\n",
            "Epoch 302/500, Loss: 2527.7024\n",
            "Epoch 303/500, Loss: 2505.9956\n",
            "Epoch 304/500, Loss: 2515.5474\n",
            "Epoch 305/500, Loss: 2526.1765\n",
            "Epoch 306/500, Loss: 2513.6887\n",
            "Epoch 307/500, Loss: 2497.2107\n",
            "Epoch 308/500, Loss: 2506.7344\n",
            "Epoch 309/500, Loss: 2520.3435\n",
            "Epoch 310/500, Loss: 2519.1331\n",
            "Epoch 311/500, Loss: 2508.6348\n",
            "Epoch 312/500, Loss: 2499.2683\n",
            "Epoch 313/500, Loss: 2494.8337\n",
            "Epoch 314/500, Loss: 2497.2773\n",
            "Epoch 315/500, Loss: 2504.5242\n",
            "Epoch 316/500, Loss: 2512.0544\n",
            "Epoch 317/500, Loss: 2520.9023\n",
            "Epoch 318/500, Loss: 2515.5066\n",
            "Epoch 319/500, Loss: 2514.1802\n",
            "Epoch 320/500, Loss: 2508.6414\n",
            "Epoch 321/500, Loss: 2500.6624\n",
            "Epoch 322/500, Loss: 2501.5544\n",
            "Epoch 323/500, Loss: 2495.0500\n",
            "Epoch 324/500, Loss: 2494.1489\n",
            "Epoch 325/500, Loss: 2492.7634\n",
            "Epoch 326/500, Loss: 2491.8169\n",
            "Epoch 327/500, Loss: 2491.0002\n",
            "Epoch 328/500, Loss: 2490.2981\n",
            "Epoch 329/500, Loss: 2489.4653\n",
            "Epoch 330/500, Loss: 2489.2449\n",
            "Epoch 331/500, Loss: 2488.6057\n",
            "Epoch 332/500, Loss: 2488.0251\n",
            "Epoch 333/500, Loss: 2492.5850\n",
            "Epoch 334/500, Loss: 2492.1833\n",
            "Epoch 335/500, Loss: 2495.2603\n",
            "Epoch 336/500, Loss: 2498.2097\n",
            "Epoch 337/500, Loss: 2508.1990\n",
            "Epoch 338/500, Loss: 2534.9678\n",
            "Epoch 339/500, Loss: 2571.2368\n",
            "Epoch 340/500, Loss: 2655.9761\n",
            "Epoch 341/500, Loss: 2763.5408\n",
            "Epoch 342/500, Loss: 2752.3884\n",
            "Epoch 343/500, Loss: 2614.4001\n",
            "Epoch 344/500, Loss: 2530.6545\n",
            "Epoch 345/500, Loss: 2590.0630\n",
            "Epoch 346/500, Loss: 2607.8923\n",
            "Epoch 347/500, Loss: 2526.5088\n",
            "Epoch 348/500, Loss: 2578.6130\n",
            "Epoch 349/500, Loss: 2578.6045\n",
            "Epoch 350/500, Loss: 2505.0532\n",
            "Epoch 351/500, Loss: 2582.9805\n",
            "Epoch 352/500, Loss: 2553.9656\n",
            "Epoch 353/500, Loss: 2513.5732\n",
            "Epoch 354/500, Loss: 2562.7852\n",
            "Epoch 355/500, Loss: 2528.4026\n",
            "Epoch 356/500, Loss: 2512.5339\n",
            "Epoch 357/500, Loss: 2547.6299\n",
            "Epoch 358/500, Loss: 2510.2939\n",
            "Epoch 359/500, Loss: 2501.6511\n",
            "Epoch 360/500, Loss: 2535.5872\n",
            "Epoch 361/500, Loss: 2510.7439\n",
            "Epoch 362/500, Loss: 2490.1399\n",
            "Epoch 363/500, Loss: 2511.0740\n",
            "Epoch 364/500, Loss: 2514.8889\n",
            "Epoch 365/500, Loss: 2490.7561\n",
            "Epoch 366/500, Loss: 2494.3757\n",
            "Epoch 367/500, Loss: 2515.2141\n",
            "Epoch 368/500, Loss: 2502.8826\n",
            "Epoch 369/500, Loss: 2489.3123\n",
            "Epoch 370/500, Loss: 2488.8748\n",
            "Epoch 371/500, Loss: 2495.4343\n",
            "Epoch 372/500, Loss: 2498.3767\n",
            "Epoch 373/500, Loss: 2498.2878\n",
            "Epoch 374/500, Loss: 2488.3984\n",
            "Epoch 375/500, Loss: 2483.6377\n",
            "Epoch 376/500, Loss: 2485.6279\n",
            "Epoch 377/500, Loss: 2487.4109\n",
            "Epoch 378/500, Loss: 2485.4966\n",
            "Epoch 379/500, Loss: 2483.7803\n",
            "Epoch 380/500, Loss: 2486.1616\n",
            "Epoch 381/500, Loss: 2484.6746\n",
            "Epoch 382/500, Loss: 2483.9695\n",
            "Epoch 383/500, Loss: 2484.0977\n",
            "Epoch 384/500, Loss: 2482.7747\n",
            "Epoch 385/500, Loss: 2481.7715\n",
            "Epoch 386/500, Loss: 2482.4731\n",
            "Epoch 387/500, Loss: 2481.8064\n",
            "Epoch 388/500, Loss: 2480.3948\n",
            "Epoch 389/500, Loss: 2479.2852\n",
            "Epoch 390/500, Loss: 2478.7051\n",
            "Epoch 391/500, Loss: 2480.7883\n",
            "Epoch 392/500, Loss: 2479.4119\n",
            "Epoch 393/500, Loss: 2477.8015\n",
            "Epoch 394/500, Loss: 2479.0354\n",
            "Epoch 395/500, Loss: 2478.0239\n",
            "Epoch 396/500, Loss: 2476.5225\n",
            "Epoch 397/500, Loss: 2476.5713\n",
            "Epoch 398/500, Loss: 2476.5232\n",
            "Epoch 399/500, Loss: 2479.6707\n",
            "Epoch 400/500, Loss: 2479.8435\n",
            "Epoch 401/500, Loss: 2481.0107\n",
            "Epoch 402/500, Loss: 2477.7927\n",
            "Epoch 403/500, Loss: 2481.1677\n",
            "Epoch 404/500, Loss: 2486.1155\n",
            "Epoch 405/500, Loss: 2489.9458\n",
            "Epoch 406/500, Loss: 2511.6128\n",
            "Epoch 407/500, Loss: 2540.3992\n",
            "Epoch 408/500, Loss: 2576.1775\n",
            "Epoch 409/500, Loss: 2575.6726\n",
            "Epoch 410/500, Loss: 2518.4731\n",
            "Epoch 411/500, Loss: 2496.6079\n",
            "Epoch 412/500, Loss: 2495.7896\n",
            "Epoch 413/500, Loss: 2518.9883\n",
            "Epoch 414/500, Loss: 2518.3789\n",
            "Epoch 415/500, Loss: 2484.5430\n",
            "Epoch 416/500, Loss: 2488.7976\n",
            "Epoch 417/500, Loss: 2507.3931\n",
            "Epoch 418/500, Loss: 2499.1848\n",
            "Epoch 419/500, Loss: 2484.5447\n",
            "Epoch 420/500, Loss: 2484.9473\n",
            "Epoch 421/500, Loss: 2494.2761\n",
            "Epoch 422/500, Loss: 2489.4932\n",
            "Epoch 423/500, Loss: 2479.0820\n",
            "Epoch 424/500, Loss: 2481.9536\n",
            "Epoch 425/500, Loss: 2492.2019\n",
            "Epoch 426/500, Loss: 2483.7854\n",
            "Epoch 427/500, Loss: 2475.2673\n",
            "Epoch 428/500, Loss: 2478.1492\n",
            "Epoch 429/500, Loss: 2484.3918\n",
            "Epoch 430/500, Loss: 2482.6055\n",
            "Epoch 431/500, Loss: 2481.6807\n",
            "Epoch 432/500, Loss: 2482.9324\n",
            "Epoch 433/500, Loss: 2479.4597\n",
            "Epoch 434/500, Loss: 2480.1780\n",
            "Epoch 435/500, Loss: 2482.1443\n",
            "Epoch 436/500, Loss: 2473.7136\n",
            "Epoch 437/500, Loss: 2471.7883\n",
            "Epoch 438/500, Loss: 2476.4929\n",
            "Epoch 439/500, Loss: 2476.3247\n",
            "Epoch 440/500, Loss: 2475.8965\n",
            "Epoch 441/500, Loss: 2474.5779\n",
            "Epoch 442/500, Loss: 2473.7192\n",
            "Epoch 443/500, Loss: 2470.0945\n",
            "Epoch 444/500, Loss: 2472.5195\n",
            "Epoch 445/500, Loss: 2475.2109\n",
            "Epoch 446/500, Loss: 2472.7192\n",
            "Epoch 447/500, Loss: 2470.7341\n",
            "Epoch 448/500, Loss: 2472.0261\n",
            "Epoch 449/500, Loss: 2471.1355\n",
            "Epoch 450/500, Loss: 2468.2258\n",
            "Epoch 451/500, Loss: 2468.9438\n",
            "Epoch 452/500, Loss: 2474.6140\n",
            "Epoch 453/500, Loss: 2476.2446\n",
            "Epoch 454/500, Loss: 2471.3274\n",
            "Epoch 455/500, Loss: 2470.8352\n",
            "Epoch 456/500, Loss: 2477.7502\n",
            "Epoch 457/500, Loss: 2486.6084\n",
            "Epoch 458/500, Loss: 2499.4285\n",
            "Epoch 459/500, Loss: 2552.7488\n",
            "Epoch 460/500, Loss: 2645.0420\n",
            "Epoch 461/500, Loss: 2712.6785\n",
            "Epoch 462/500, Loss: 2615.0369\n",
            "Epoch 463/500, Loss: 2548.3301\n",
            "Epoch 464/500, Loss: 2558.5496\n",
            "Epoch 465/500, Loss: 2595.0728\n",
            "Epoch 466/500, Loss: 2564.9949\n",
            "Epoch 467/500, Loss: 2488.1992\n",
            "Epoch 468/500, Loss: 2561.8442\n",
            "Epoch 469/500, Loss: 2565.6880\n",
            "Epoch 470/500, Loss: 2493.5195\n",
            "Epoch 471/500, Loss: 2506.7197\n",
            "Epoch 472/500, Loss: 2518.4622\n",
            "Epoch 473/500, Loss: 2503.3008\n",
            "Epoch 474/500, Loss: 2492.5024\n",
            "Epoch 475/500, Loss: 2511.8350\n",
            "Epoch 476/500, Loss: 2498.7925\n",
            "Epoch 477/500, Loss: 2472.5896\n",
            "Epoch 478/500, Loss: 2499.5227\n",
            "Epoch 479/500, Loss: 2503.4790\n",
            "Epoch 480/500, Loss: 2486.4868\n",
            "Epoch 481/500, Loss: 2476.7029\n",
            "Epoch 482/500, Loss: 2471.4834\n",
            "Epoch 483/500, Loss: 2477.2371\n",
            "Epoch 484/500, Loss: 2490.6521\n",
            "Epoch 485/500, Loss: 2491.3027\n",
            "Epoch 486/500, Loss: 2472.4563\n",
            "Epoch 487/500, Loss: 2467.5684\n",
            "Epoch 488/500, Loss: 2476.8025\n",
            "Epoch 489/500, Loss: 2475.3984\n",
            "Epoch 490/500, Loss: 2489.0967\n",
            "Epoch 491/500, Loss: 2491.2639\n",
            "Epoch 492/500, Loss: 2483.3677\n",
            "Epoch 493/500, Loss: 2472.3618\n",
            "Epoch 494/500, Loss: 2471.2512\n",
            "Epoch 495/500, Loss: 2469.2644\n",
            "Epoch 496/500, Loss: 2468.7051\n",
            "Epoch 497/500, Loss: 2473.8845\n",
            "Epoch 498/500, Loss: 2468.3533\n",
            "Epoch 499/500, Loss: 2463.6453\n",
            "Epoch 500/500, Loss: 2468.8860\n",
            "Training complete.\n",
            "Test Loss: 3337.6970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting llm embeddings and then training it on gat Dataset-2"
      ],
      "metadata": {
        "id": "O5Wxl-mYhB_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GATConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "# Set CUDA settings to avoid certain issues\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset and skip problematic rows if they exist\n",
        "try:\n",
        "    df = pd.read_csv('/content/sampled_modified_reddit_data.csv', on_bad_lines='skip')\n",
        "    print(\"Columns in dataset:\", df.columns)  # Print columns to verify the column names\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Parser error encountered. Some rows were skipped due to formatting issues.\")\n",
        "\n",
        "# Check if 'tags' column exists and apply one-hot encoding if available\n",
        "if 'tags' in df.columns:\n",
        "    df_one_hot = pd.get_dummies(df['tags'], prefix='tags')\n",
        "else:\n",
        "    print(\"Column 'tags' not found in the dataset. Proceeding without one-hot encoding.\")\n",
        "    df_one_hot = pd.DataFrame()  # Create an empty DataFrame if 'tags' is missing\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the 'body' column\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Convert embeddings to torch tensor\n",
        "text_embeddings = torch.tensor(text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df[['Score']].values, dtype=torch.float)  # Changed from 'retweet_count' to 'Score'\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = torch.cat([text_embeddings, additional_features], dim=1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['Num of Comments'].values, dtype=torch.float)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GAT model\n",
        "class GATModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1, heads=8):\n",
        "        super(GATModel, self).__init__()\n",
        "        self.conv1 = GATConv(input_dim, hidden_dim1, heads=heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim1 * heads, hidden_dim2, heads=heads, concat=True)\n",
        "        self.conv3 = GATConv(hidden_dim2 * heads, hidden_dim3, heads=heads, concat=True)\n",
        "        self.conv4 = GATConv(hidden_dim3 * heads, hidden_dim4, heads=1, concat=False)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GAT model\n",
        "input_dim = X.shape[1]\n",
        "model = GATModel(input_dim=input_dim)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUaCzAL7hBDK",
        "outputId": "3ae898d7-9ecd-4989-9479-1ec904bb4eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['Political Lean', 'Score', 'Subreddit', 'Num of Comments', 'body'], dtype='object')\n",
            "Column 'tags' not found in the dataset. Proceeding without one-hot encoding.\n",
            "Epoch 1/500, Loss: 5126.0205\n",
            "Epoch 2/500, Loss: 571618816.0000\n",
            "Epoch 3/500, Loss: 18445.6875\n",
            "Epoch 4/500, Loss: 4004.9609\n",
            "Epoch 5/500, Loss: 11450.0684\n",
            "Epoch 6/500, Loss: 12543.1279\n",
            "Epoch 7/500, Loss: 4704.5132\n",
            "Epoch 8/500, Loss: 5147.0952\n",
            "Epoch 9/500, Loss: 5292.1968\n",
            "Epoch 10/500, Loss: 4571.4287\n",
            "Epoch 11/500, Loss: 4643.4243\n",
            "Epoch 12/500, Loss: 5691.0903\n",
            "Epoch 13/500, Loss: 3901.7617\n",
            "Epoch 14/500, Loss: 6038.1987\n",
            "Epoch 15/500, Loss: 4748.6006\n",
            "Epoch 16/500, Loss: 4061.0750\n",
            "Epoch 17/500, Loss: 5699.0405\n",
            "Epoch 18/500, Loss: 3547.1589\n",
            "Epoch 19/500, Loss: 4928.4766\n",
            "Epoch 20/500, Loss: 3821.9785\n",
            "Epoch 21/500, Loss: 4200.5366\n",
            "Epoch 22/500, Loss: 3605.9167\n",
            "Epoch 23/500, Loss: 3822.8992\n",
            "Epoch 24/500, Loss: 3275.5398\n",
            "Epoch 25/500, Loss: 3695.8035\n",
            "Epoch 26/500, Loss: 3015.8577\n",
            "Epoch 27/500, Loss: 3758.9641\n",
            "Epoch 28/500, Loss: 2976.2241\n",
            "Epoch 29/500, Loss: 3388.6790\n",
            "Epoch 30/500, Loss: 2946.6848\n",
            "Epoch 31/500, Loss: 3298.1150\n",
            "Epoch 32/500, Loss: 2838.8921\n",
            "Epoch 33/500, Loss: 2942.9238\n",
            "Epoch 34/500, Loss: 3352.7852\n",
            "Epoch 35/500, Loss: 3126.6211\n",
            "Epoch 36/500, Loss: 2862.7578\n",
            "Epoch 37/500, Loss: 3218.0303\n",
            "Epoch 38/500, Loss: 3300.9121\n",
            "Epoch 39/500, Loss: 3194.4399\n",
            "Epoch 40/500, Loss: 2725.2903\n",
            "Epoch 41/500, Loss: 2840.9883\n",
            "Epoch 42/500, Loss: 2979.9790\n",
            "Epoch 43/500, Loss: 2887.3406\n",
            "Epoch 44/500, Loss: 2707.9414\n",
            "Epoch 45/500, Loss: 2621.5825\n",
            "Epoch 46/500, Loss: 2758.0293\n",
            "Epoch 47/500, Loss: 2937.4294\n",
            "Epoch 48/500, Loss: 2699.3970\n",
            "Epoch 49/500, Loss: 2625.5066\n",
            "Epoch 50/500, Loss: 2636.9443\n",
            "Epoch 51/500, Loss: 2722.8416\n",
            "Epoch 52/500, Loss: 2933.0398\n",
            "Epoch 53/500, Loss: 3565.3267\n",
            "Epoch 54/500, Loss: 4134.6602\n",
            "Epoch 55/500, Loss: 3050.2668\n",
            "Epoch 56/500, Loss: 2742.7742\n",
            "Epoch 57/500, Loss: 3570.1094\n",
            "Epoch 58/500, Loss: 2614.9910\n",
            "Epoch 59/500, Loss: 3383.9009\n",
            "Epoch 60/500, Loss: 2849.0947\n",
            "Epoch 61/500, Loss: 3068.0898\n",
            "Epoch 62/500, Loss: 4279.7017\n",
            "Epoch 63/500, Loss: 6263.8530\n",
            "Epoch 64/500, Loss: 5181.8667\n",
            "Epoch 65/500, Loss: 4262.5718\n",
            "Epoch 66/500, Loss: 8373.4834\n",
            "Epoch 67/500, Loss: 10146.9482\n",
            "Epoch 68/500, Loss: 7400.4502\n",
            "Epoch 69/500, Loss: 3823.1921\n",
            "Epoch 70/500, Loss: 3868.5955\n",
            "Epoch 71/500, Loss: 3695.1184\n",
            "Epoch 72/500, Loss: 4073.4419\n",
            "Epoch 73/500, Loss: 3870.3826\n",
            "Epoch 74/500, Loss: 3583.0891\n",
            "Epoch 75/500, Loss: 3386.0793\n",
            "Epoch 76/500, Loss: 4398.4116\n",
            "Epoch 77/500, Loss: 15178.5068\n",
            "Epoch 78/500, Loss: 35922.1562\n",
            "Epoch 79/500, Loss: 3568.4067\n",
            "Epoch 80/500, Loss: 11230.3281\n",
            "Epoch 81/500, Loss: 7585.7617\n",
            "Epoch 82/500, Loss: 4146.9468\n",
            "Epoch 83/500, Loss: 3923.8391\n",
            "Epoch 84/500, Loss: 5528.1846\n",
            "Epoch 85/500, Loss: 4314.8940\n",
            "Epoch 86/500, Loss: 3489.9102\n",
            "Epoch 87/500, Loss: 3670.3464\n",
            "Epoch 88/500, Loss: 3386.5981\n",
            "Epoch 89/500, Loss: 3743.8579\n",
            "Epoch 90/500, Loss: 3928.9133\n",
            "Epoch 91/500, Loss: 3840.6992\n",
            "Epoch 92/500, Loss: 4727.0366\n",
            "Epoch 93/500, Loss: 3579.4929\n",
            "Epoch 94/500, Loss: 3754.6414\n",
            "Epoch 95/500, Loss: 5203.2539\n",
            "Epoch 96/500, Loss: 3663.1223\n",
            "Epoch 97/500, Loss: 3797.9824\n",
            "Epoch 98/500, Loss: 3405.0369\n",
            "Epoch 99/500, Loss: 3364.0142\n",
            "Epoch 100/500, Loss: 3303.5828\n",
            "Epoch 101/500, Loss: 3299.7981\n",
            "Epoch 102/500, Loss: 3553.6770\n",
            "Epoch 103/500, Loss: 3718.2180\n",
            "Epoch 104/500, Loss: 3800.5513\n",
            "Epoch 105/500, Loss: 3959.4016\n",
            "Epoch 106/500, Loss: 3542.0837\n",
            "Epoch 107/500, Loss: 3827.9451\n",
            "Epoch 108/500, Loss: 3816.8923\n",
            "Epoch 109/500, Loss: 3190.3250\n",
            "Epoch 110/500, Loss: 3395.1326\n",
            "Epoch 111/500, Loss: 3409.8730\n",
            "Epoch 112/500, Loss: 4867.6499\n",
            "Epoch 113/500, Loss: 8369.3252\n",
            "Epoch 114/500, Loss: 5759.2827\n",
            "Epoch 115/500, Loss: 3946.8086\n",
            "Epoch 116/500, Loss: 5532.0049\n",
            "Epoch 117/500, Loss: 3513.3611\n",
            "Epoch 118/500, Loss: 4405.4575\n",
            "Epoch 119/500, Loss: 3772.9023\n",
            "Epoch 120/500, Loss: 3562.6101\n",
            "Epoch 121/500, Loss: 4072.0349\n",
            "Epoch 122/500, Loss: 3338.6074\n",
            "Epoch 123/500, Loss: 3515.3230\n",
            "Epoch 124/500, Loss: 3720.0876\n",
            "Epoch 125/500, Loss: 3267.9905\n",
            "Epoch 126/500, Loss: 3479.6770\n",
            "Epoch 127/500, Loss: 3513.9539\n",
            "Epoch 128/500, Loss: 3253.4858\n",
            "Epoch 129/500, Loss: 3213.1365\n",
            "Epoch 130/500, Loss: 3368.1267\n",
            "Epoch 131/500, Loss: 3249.4802\n",
            "Epoch 132/500, Loss: 3171.0627\n",
            "Epoch 133/500, Loss: 3185.8308\n",
            "Epoch 134/500, Loss: 3181.8074\n",
            "Epoch 135/500, Loss: 3126.6475\n",
            "Epoch 136/500, Loss: 3079.4473\n",
            "Epoch 137/500, Loss: 3089.7786\n",
            "Epoch 138/500, Loss: 3022.9583\n",
            "Epoch 139/500, Loss: 2955.6855\n",
            "Epoch 140/500, Loss: 3003.9414\n",
            "Epoch 141/500, Loss: 2920.7466\n",
            "Epoch 142/500, Loss: 2959.5645\n",
            "Epoch 143/500, Loss: 2906.8098\n",
            "Epoch 144/500, Loss: 2926.9778\n",
            "Epoch 145/500, Loss: 2890.4421\n",
            "Epoch 146/500, Loss: 3005.7620\n",
            "Epoch 147/500, Loss: 2881.6187\n",
            "Epoch 148/500, Loss: 2982.8997\n",
            "Epoch 149/500, Loss: 2886.8914\n",
            "Epoch 150/500, Loss: 2902.3247\n",
            "Epoch 151/500, Loss: 2882.9653\n",
            "Epoch 152/500, Loss: 2768.6638\n",
            "Epoch 153/500, Loss: 2838.8235\n",
            "Epoch 154/500, Loss: 2772.8098\n",
            "Epoch 155/500, Loss: 3371.8777\n",
            "Epoch 156/500, Loss: 3520.2161\n",
            "Epoch 157/500, Loss: 3591.1997\n",
            "Epoch 158/500, Loss: 3075.9819\n",
            "Epoch 159/500, Loss: 3166.3572\n",
            "Epoch 160/500, Loss: 3177.6763\n",
            "Epoch 161/500, Loss: 3295.2410\n",
            "Epoch 162/500, Loss: 3139.8240\n",
            "Epoch 163/500, Loss: 4044.5149\n",
            "Epoch 164/500, Loss: 9212.2568\n",
            "Epoch 165/500, Loss: 4581.1016\n",
            "Epoch 166/500, Loss: 5486.6069\n",
            "Epoch 167/500, Loss: 7094.4204\n",
            "Epoch 168/500, Loss: 19274.9199\n",
            "Epoch 169/500, Loss: 7247.8774\n",
            "Epoch 170/500, Loss: 6225.5894\n",
            "Epoch 171/500, Loss: 5908.2593\n",
            "Epoch 172/500, Loss: 4576.4883\n",
            "Epoch 173/500, Loss: 5939.9312\n",
            "Epoch 174/500, Loss: 6021.9868\n",
            "Epoch 175/500, Loss: 4349.4136\n",
            "Epoch 176/500, Loss: 3858.1140\n",
            "Epoch 177/500, Loss: 5177.8003\n",
            "Epoch 178/500, Loss: 6503.7246\n",
            "Epoch 179/500, Loss: 5244.7876\n",
            "Epoch 180/500, Loss: 3390.4529\n",
            "Epoch 181/500, Loss: 4048.0859\n",
            "Epoch 182/500, Loss: 4922.6445\n",
            "Epoch 183/500, Loss: 3701.0474\n",
            "Epoch 184/500, Loss: 3146.4529\n",
            "Epoch 185/500, Loss: 4243.2964\n",
            "Epoch 186/500, Loss: 4648.3120\n",
            "Epoch 187/500, Loss: 3599.3835\n",
            "Epoch 188/500, Loss: 4217.2939\n",
            "Epoch 189/500, Loss: 15100.7109\n",
            "Epoch 190/500, Loss: 26632.3750\n",
            "Epoch 191/500, Loss: 6728.3696\n",
            "Epoch 192/500, Loss: 10479.4756\n",
            "Epoch 193/500, Loss: 5020.5640\n",
            "Epoch 194/500, Loss: 4473.6729\n",
            "Epoch 195/500, Loss: 6500.0747\n",
            "Epoch 196/500, Loss: 4743.1143\n",
            "Epoch 197/500, Loss: 8878.8545\n",
            "Epoch 198/500, Loss: 3486.8618\n",
            "Epoch 199/500, Loss: 3812.8293\n",
            "Epoch 200/500, Loss: 5620.9756\n",
            "Epoch 201/500, Loss: 4182.5503\n",
            "Epoch 202/500, Loss: 3987.9978\n",
            "Epoch 203/500, Loss: 3844.7668\n",
            "Epoch 204/500, Loss: 3736.2625\n",
            "Epoch 205/500, Loss: 3668.5261\n",
            "Epoch 206/500, Loss: 3651.4958\n",
            "Epoch 207/500, Loss: 3650.2009\n",
            "Epoch 208/500, Loss: 3705.9609\n",
            "Epoch 209/500, Loss: 3721.9556\n",
            "Epoch 210/500, Loss: 3701.8333\n",
            "Epoch 211/500, Loss: 3679.4849\n",
            "Epoch 212/500, Loss: 3596.4829\n",
            "Epoch 213/500, Loss: 3568.0828\n",
            "Epoch 214/500, Loss: 3500.8801\n",
            "Epoch 215/500, Loss: 3460.3442\n",
            "Epoch 216/500, Loss: 3441.5657\n",
            "Epoch 217/500, Loss: 3423.0664\n",
            "Epoch 218/500, Loss: 3407.9783\n",
            "Epoch 219/500, Loss: 3310.3201\n",
            "Epoch 220/500, Loss: 3262.9910\n",
            "Epoch 221/500, Loss: 3272.6628\n",
            "Epoch 222/500, Loss: 3264.6636\n",
            "Epoch 223/500, Loss: 3102.4919\n",
            "Epoch 224/500, Loss: 3064.3989\n",
            "Epoch 225/500, Loss: 2963.0129\n",
            "Epoch 226/500, Loss: 3053.5776\n",
            "Epoch 227/500, Loss: 2860.9448\n",
            "Epoch 228/500, Loss: 2922.6687\n",
            "Epoch 229/500, Loss: 2751.4573\n",
            "Epoch 230/500, Loss: 2700.9246\n",
            "Epoch 231/500, Loss: 2730.6460\n",
            "Epoch 232/500, Loss: 2882.7368\n",
            "Epoch 233/500, Loss: 2929.0535\n",
            "Epoch 234/500, Loss: 3039.8694\n",
            "Epoch 235/500, Loss: 2665.8513\n",
            "Epoch 236/500, Loss: 2880.2664\n",
            "Epoch 237/500, Loss: 3125.0234\n",
            "Epoch 238/500, Loss: 2634.7849\n",
            "Epoch 239/500, Loss: 3646.8435\n",
            "Epoch 240/500, Loss: 3182.8816\n",
            "Epoch 241/500, Loss: 3396.4851\n",
            "Epoch 242/500, Loss: 2676.9956\n",
            "Epoch 243/500, Loss: 3383.9744\n",
            "Epoch 244/500, Loss: 2701.5759\n",
            "Epoch 245/500, Loss: 3066.3987\n",
            "Epoch 246/500, Loss: 3134.2029\n",
            "Epoch 247/500, Loss: 2857.5955\n",
            "Epoch 248/500, Loss: 2807.2888\n",
            "Epoch 249/500, Loss: 2966.5046\n",
            "Epoch 250/500, Loss: 2801.0513\n",
            "Epoch 251/500, Loss: 2779.0957\n",
            "Epoch 252/500, Loss: 2897.8875\n",
            "Epoch 253/500, Loss: 2803.9070\n",
            "Epoch 254/500, Loss: 2669.6602\n",
            "Epoch 255/500, Loss: 2659.8367\n",
            "Epoch 256/500, Loss: 2645.1541\n",
            "Epoch 257/500, Loss: 2544.9399\n",
            "Epoch 258/500, Loss: 2599.2732\n",
            "Epoch 259/500, Loss: 2611.7942\n",
            "Epoch 260/500, Loss: 2529.6235\n",
            "Epoch 261/500, Loss: 2585.4331\n",
            "Epoch 262/500, Loss: 2539.0552\n",
            "Epoch 263/500, Loss: 2495.7996\n",
            "Epoch 264/500, Loss: 2998.2942\n",
            "Epoch 265/500, Loss: 2742.6492\n",
            "Epoch 266/500, Loss: 2615.7239\n",
            "Epoch 267/500, Loss: 2655.0269\n",
            "Epoch 268/500, Loss: 2583.8630\n",
            "Epoch 269/500, Loss: 2865.5251\n",
            "Epoch 270/500, Loss: 2807.0845\n",
            "Epoch 271/500, Loss: 3211.2168\n",
            "Epoch 272/500, Loss: 2891.1296\n",
            "Epoch 273/500, Loss: 2811.0049\n",
            "Epoch 274/500, Loss: 2542.2402\n",
            "Epoch 275/500, Loss: 2710.1921\n",
            "Epoch 276/500, Loss: 2729.7830\n",
            "Epoch 277/500, Loss: 2496.2136\n",
            "Epoch 278/500, Loss: 2635.7351\n",
            "Epoch 279/500, Loss: 2517.0652\n",
            "Epoch 280/500, Loss: 2554.7830\n",
            "Epoch 281/500, Loss: 2907.3535\n",
            "Epoch 282/500, Loss: 2697.2734\n",
            "Epoch 283/500, Loss: 2561.0591\n",
            "Epoch 284/500, Loss: 2597.2917\n",
            "Epoch 285/500, Loss: 2571.4397\n",
            "Epoch 286/500, Loss: 2941.5632\n",
            "Epoch 287/500, Loss: 2512.3735\n",
            "Epoch 288/500, Loss: 2618.5984\n",
            "Epoch 289/500, Loss: 2593.9692\n",
            "Epoch 290/500, Loss: 2434.8657\n",
            "Epoch 291/500, Loss: 2929.9248\n",
            "Epoch 292/500, Loss: 2760.1072\n",
            "Epoch 293/500, Loss: 2700.0708\n",
            "Epoch 294/500, Loss: 2802.0437\n",
            "Epoch 295/500, Loss: 3057.0251\n",
            "Epoch 296/500, Loss: 8201.5879\n",
            "Epoch 297/500, Loss: 42801.6367\n",
            "Epoch 298/500, Loss: 11003.9922\n",
            "Epoch 299/500, Loss: 17648.7695\n",
            "Epoch 300/500, Loss: 6779.7085\n",
            "Epoch 301/500, Loss: 12648.6689\n",
            "Epoch 302/500, Loss: 4665.0518\n",
            "Epoch 303/500, Loss: 6557.7563\n",
            "Epoch 304/500, Loss: 4735.9106\n",
            "Epoch 305/500, Loss: 4200.3398\n",
            "Epoch 306/500, Loss: 4517.6616\n",
            "Epoch 307/500, Loss: 4804.7021\n",
            "Epoch 308/500, Loss: 4817.4487\n",
            "Epoch 309/500, Loss: 4649.0747\n",
            "Epoch 310/500, Loss: 4391.4321\n",
            "Epoch 311/500, Loss: 4140.6777\n",
            "Epoch 312/500, Loss: 3916.4392\n",
            "Epoch 313/500, Loss: 3751.1023\n",
            "Epoch 314/500, Loss: 3629.8059\n",
            "Epoch 315/500, Loss: 13509.9600\n",
            "Epoch 316/500, Loss: 4238.8647\n",
            "Epoch 317/500, Loss: 4558.3501\n",
            "Epoch 318/500, Loss: 4354.1592\n",
            "Epoch 319/500, Loss: 3967.1367\n",
            "Epoch 320/500, Loss: 3763.2773\n",
            "Epoch 321/500, Loss: 3737.4602\n",
            "Epoch 322/500, Loss: 3827.9556\n",
            "Epoch 323/500, Loss: 3913.2185\n",
            "Epoch 324/500, Loss: 3933.4473\n",
            "Epoch 325/500, Loss: 3867.9219\n",
            "Epoch 326/500, Loss: 3733.9988\n",
            "Epoch 327/500, Loss: 3689.6626\n",
            "Epoch 328/500, Loss: 3531.7773\n",
            "Epoch 329/500, Loss: 3717.0032\n",
            "Epoch 330/500, Loss: 3582.8025\n",
            "Epoch 331/500, Loss: 3820.3660\n",
            "Epoch 332/500, Loss: 3651.7681\n",
            "Epoch 333/500, Loss: 3390.4766\n",
            "Epoch 334/500, Loss: 3430.0747\n",
            "Epoch 335/500, Loss: 3313.8228\n",
            "Epoch 336/500, Loss: 3303.7954\n",
            "Epoch 337/500, Loss: 3412.1560\n",
            "Epoch 338/500, Loss: 3488.3240\n",
            "Epoch 339/500, Loss: 3368.2793\n",
            "Epoch 340/500, Loss: 3191.9395\n",
            "Epoch 341/500, Loss: 3217.1870\n",
            "Epoch 342/500, Loss: 3372.1541\n",
            "Epoch 343/500, Loss: 3400.4771\n",
            "Epoch 344/500, Loss: 3453.6028\n",
            "Epoch 345/500, Loss: 3412.8730\n",
            "Epoch 346/500, Loss: 3377.4314\n",
            "Epoch 347/500, Loss: 3512.6091\n",
            "Epoch 348/500, Loss: 3431.9048\n",
            "Epoch 349/500, Loss: 3412.1868\n",
            "Epoch 350/500, Loss: 3464.0886\n",
            "Epoch 351/500, Loss: 3383.2244\n",
            "Epoch 352/500, Loss: 3378.2852\n",
            "Epoch 353/500, Loss: 3421.2375\n",
            "Epoch 354/500, Loss: 3363.9187\n",
            "Epoch 355/500, Loss: 3377.6125\n",
            "Epoch 356/500, Loss: 3400.7974\n",
            "Epoch 357/500, Loss: 3377.0532\n",
            "Epoch 358/500, Loss: 3356.4353\n",
            "Epoch 359/500, Loss: 3400.7446\n",
            "Epoch 360/500, Loss: 3382.5867\n",
            "Epoch 361/500, Loss: 3360.6646\n",
            "Epoch 362/500, Loss: 3376.1951\n",
            "Epoch 363/500, Loss: 3385.0469\n",
            "Epoch 364/500, Loss: 3364.7681\n",
            "Epoch 365/500, Loss: 3352.2524\n",
            "Epoch 366/500, Loss: 3365.5017\n",
            "Epoch 367/500, Loss: 3371.1023\n",
            "Epoch 368/500, Loss: 3355.9751\n",
            "Epoch 369/500, Loss: 3347.9614\n",
            "Epoch 370/500, Loss: 3355.6763\n",
            "Epoch 371/500, Loss: 3359.9277\n",
            "Epoch 372/500, Loss: 3343.5007\n",
            "Epoch 373/500, Loss: 3338.7683\n",
            "Epoch 374/500, Loss: 3343.4822\n",
            "Epoch 375/500, Loss: 3346.1606\n",
            "Epoch 376/500, Loss: 3340.6641\n",
            "Epoch 377/500, Loss: 3336.7185\n",
            "Epoch 378/500, Loss: 3339.4753\n",
            "Epoch 379/500, Loss: 3341.9048\n",
            "Epoch 380/500, Loss: 3339.2188\n",
            "Epoch 381/500, Loss: 3335.8352\n",
            "Epoch 382/500, Loss: 3335.6953\n",
            "Epoch 383/500, Loss: 3337.6040\n",
            "Epoch 384/500, Loss: 3344.1211\n",
            "Epoch 385/500, Loss: 3341.9539\n",
            "Epoch 386/500, Loss: 3341.9978\n",
            "Epoch 387/500, Loss: 3342.7869\n",
            "Epoch 388/500, Loss: 3341.7722\n",
            "Epoch 389/500, Loss: 3339.6997\n",
            "Epoch 390/500, Loss: 3338.9861\n",
            "Epoch 391/500, Loss: 3332.6360\n",
            "Epoch 392/500, Loss: 3332.5916\n",
            "Epoch 393/500, Loss: 3331.2642\n",
            "Epoch 394/500, Loss: 3330.4414\n",
            "Epoch 395/500, Loss: 3330.5085\n",
            "Epoch 396/500, Loss: 3336.2844\n",
            "Epoch 397/500, Loss: 3337.2681\n",
            "Epoch 398/500, Loss: 3335.6931\n",
            "Epoch 399/500, Loss: 3335.7703\n",
            "Epoch 400/500, Loss: 3333.0085\n",
            "Epoch 401/500, Loss: 3332.0742\n",
            "Epoch 402/500, Loss: 3331.3145\n",
            "Epoch 403/500, Loss: 3330.7625\n",
            "Epoch 404/500, Loss: 3330.4915\n",
            "Epoch 405/500, Loss: 3330.4126\n",
            "Epoch 406/500, Loss: 3329.8262\n",
            "Epoch 407/500, Loss: 3331.8938\n",
            "Epoch 408/500, Loss: 3331.2976\n",
            "Epoch 409/500, Loss: 3330.3149\n",
            "Epoch 410/500, Loss: 3329.9031\n",
            "Epoch 411/500, Loss: 3329.3289\n",
            "Epoch 412/500, Loss: 3328.6716\n",
            "Epoch 413/500, Loss: 3327.8308\n",
            "Epoch 414/500, Loss: 3327.1782\n",
            "Epoch 415/500, Loss: 3326.6765\n",
            "Epoch 416/500, Loss: 3326.0129\n",
            "Epoch 417/500, Loss: 3325.3137\n",
            "Epoch 418/500, Loss: 3324.6228\n",
            "Epoch 419/500, Loss: 3323.9587\n",
            "Epoch 420/500, Loss: 3323.1843\n",
            "Epoch 421/500, Loss: 3322.3730\n",
            "Epoch 422/500, Loss: 3321.6384\n",
            "Epoch 423/500, Loss: 3320.8982\n",
            "Epoch 424/500, Loss: 3320.1282\n",
            "Epoch 425/500, Loss: 3319.3806\n",
            "Epoch 426/500, Loss: 3318.6301\n",
            "Epoch 427/500, Loss: 3317.8040\n",
            "Epoch 428/500, Loss: 3316.9392\n",
            "Epoch 429/500, Loss: 3315.2246\n",
            "Epoch 430/500, Loss: 3314.9758\n",
            "Epoch 431/500, Loss: 3313.8665\n",
            "Epoch 432/500, Loss: 3313.2271\n",
            "Epoch 433/500, Loss: 3315.2649\n",
            "Epoch 434/500, Loss: 3317.4368\n",
            "Epoch 435/500, Loss: 3315.6855\n",
            "Epoch 436/500, Loss: 3313.4329\n",
            "Epoch 437/500, Loss: 3316.0642\n",
            "Epoch 438/500, Loss: 3314.3052\n",
            "Epoch 439/500, Loss: 3319.7695\n",
            "Epoch 440/500, Loss: 3320.3250\n",
            "Epoch 441/500, Loss: 3318.2830\n",
            "Epoch 442/500, Loss: 3316.8496\n",
            "Epoch 443/500, Loss: 3315.6790\n",
            "Epoch 444/500, Loss: 3313.0767\n",
            "Epoch 445/500, Loss: 3311.7415\n",
            "Epoch 446/500, Loss: 3310.9934\n",
            "Epoch 447/500, Loss: 3309.1294\n",
            "Epoch 448/500, Loss: 3307.3704\n",
            "Epoch 449/500, Loss: 3308.3652\n",
            "Epoch 450/500, Loss: 3307.0183\n",
            "Epoch 451/500, Loss: 3305.9792\n",
            "Epoch 452/500, Loss: 3304.7253\n",
            "Epoch 453/500, Loss: 3302.0754\n",
            "Epoch 454/500, Loss: 3299.1648\n",
            "Epoch 455/500, Loss: 3298.0305\n",
            "Epoch 456/500, Loss: 3296.7910\n",
            "Epoch 457/500, Loss: 3284.1641\n",
            "Epoch 458/500, Loss: 3288.6536\n",
            "Epoch 459/500, Loss: 3289.3242\n",
            "Epoch 460/500, Loss: 3283.2537\n",
            "Epoch 461/500, Loss: 3278.5208\n",
            "Epoch 462/500, Loss: 3284.3054\n",
            "Epoch 463/500, Loss: 3286.1150\n",
            "Epoch 464/500, Loss: 3288.9055\n",
            "Epoch 465/500, Loss: 3289.9829\n",
            "Epoch 466/500, Loss: 3288.6704\n",
            "Epoch 467/500, Loss: 3283.3665\n",
            "Epoch 468/500, Loss: 3280.3926\n",
            "Epoch 469/500, Loss: 3293.1282\n",
            "Epoch 470/500, Loss: 3305.4470\n",
            "Epoch 471/500, Loss: 3299.4587\n",
            "Epoch 472/500, Loss: 3178.0449\n",
            "Epoch 473/500, Loss: 3128.7498\n",
            "Epoch 474/500, Loss: 3087.3105\n",
            "Epoch 475/500, Loss: 3197.4265\n",
            "Epoch 476/500, Loss: 4533.5439\n",
            "Epoch 477/500, Loss: 3236.8931\n",
            "Epoch 478/500, Loss: 3738.0820\n",
            "Epoch 479/500, Loss: 3507.4641\n",
            "Epoch 480/500, Loss: 3756.4692\n",
            "Epoch 481/500, Loss: 3893.5994\n",
            "Epoch 482/500, Loss: 4013.8906\n",
            "Epoch 483/500, Loss: 3936.6360\n",
            "Epoch 484/500, Loss: 3721.1321\n",
            "Epoch 485/500, Loss: 3811.1794\n",
            "Epoch 486/500, Loss: 3812.7583\n",
            "Epoch 487/500, Loss: 3633.9050\n",
            "Epoch 488/500, Loss: 3268.3867\n",
            "Epoch 489/500, Loss: 3383.2649\n",
            "Epoch 490/500, Loss: 3429.4570\n",
            "Epoch 491/500, Loss: 3433.8704\n",
            "Epoch 492/500, Loss: 3432.2793\n",
            "Epoch 493/500, Loss: 3415.6707\n",
            "Epoch 494/500, Loss: 3391.6965\n",
            "Epoch 495/500, Loss: 3387.8118\n",
            "Epoch 496/500, Loss: 3380.9419\n",
            "Epoch 497/500, Loss: 3362.3750\n",
            "Epoch 498/500, Loss: 3373.9597\n",
            "Epoch 499/500, Loss: 3238.8269\n",
            "Epoch 500/500, Loss: 3379.3699\n",
            "Training complete.\n",
            "Test Loss: 3458.4297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) Extracting llm embeddings and then using an ml model Dataset-2"
      ],
      "metadata": {
        "id": "-TfljZz9jqCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/sampled_modified_reddit_data.csv')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the 'body' column (which seems to contain the text)\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features\n",
        "additional_features = torch.tensor(df[['Num of Comments']].values, dtype=torch.float)\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable\n",
        "y = df['Score'].values  # Using 'Score' as the target variable\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print test loss (e.g., Mean Squared Error)\n",
        "mse = np.mean((test_predictions - y_test) ** 2)\n",
        "print(f'Test Mean Squared Error: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk-YbQIvj82y",
        "outputId": "8f2a4456-a5bb-46d6-c921-2eb0bd972190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Mean Squared Error: 14241.0452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) Tf-idf along with ml model Dataset-2"
      ],
      "metadata": {
        "id": "u3-GCMTTkbkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/sampled_modified_reddit_data.csv')\n",
        "\n",
        "# Check if the necessary columns exist in the dataset\n",
        "# Extracting text from the 'body' column and defining the target variable\n",
        "texts = df['body']\n",
        "y = df['Score']  # Continuous target variable\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
        "\n",
        "# Fit and transform the text data to generate TF-IDF features\n",
        "X_tfidf = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R-squared: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axy0y1Pekiu8",
        "outputId": "7b708eb6-f49b-4547-a1ea-7ca2de408fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 11748.9201\n",
            "R-squared: -3.3341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) Rake"
      ],
      "metadata": {
        "id": "LJneDWywtV3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake-nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kITniRrItoPf",
        "outputId": "c98ee5b4-4de4-4940-fefe-df3001398ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from rake-nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.67.1)\n",
            "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rake_nltk import Rake\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/sampled_modified_reddit_data.csv')\n",
        "#df = df.head(1000)\n",
        "\n",
        "# Check if the necessary columns exist in the dataset\n",
        "# Extracting text from the 'full_text' column and defining the target variable\n",
        "texts = df['body']\n",
        "y = df['Num of Comments']  # Continuous target variable\n",
        "\n",
        "# Initialize RAKE\n",
        "rake = Rake()\n",
        "\n",
        "# Extract key phrases using RAKE for each document\n",
        "rake_keywords = []\n",
        "for text in texts:\n",
        "    rake.extract_keywords_from_text(text)\n",
        "    key_phrases = rake.get_ranked_phrases()  # Get ranked key phrases\n",
        "    rake_keywords.append(\" \".join(key_phrases))  # Combine key phrases into a single string\n",
        "\n",
        "# Convert extracted key phrases into a Bag of Words representation\n",
        "vectorizer = CountVectorizer(max_features=100)  # You can adjust max_features based on the dataset size\n",
        "X_rake = vectorizer.fit_transform(rake_keywords)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rake, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R-squared: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSAKbepbxTQP",
        "outputId": "9672c83d-e793-4593-e1a6-7ff5017390d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3414.7006\n",
            "R-squared: -0.0691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) WordtoVec"
      ],
      "metadata": {
        "id": "SXoRGfnqtwNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset\n",
        "file_path = '/content/sampled_modified_reddit_data.csv'  # Replace with your dataset path\n",
        "dataset = pd.read_csv(file_path)\n",
        "dataset = dataset[:1000]\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = dataset['body']  # Assuming 'full_text' contains the essay text\n",
        "y = dataset['Num of Comments']      # Assuming 'score' is the numerical target variable\n",
        "\n",
        "# Tokenize the text data for Word2Vec\n",
        "X_tokenized = X.apply(lambda x: x.split())\n",
        "\n",
        "# Train a Word2Vec model on the tokenized data\n",
        "word2vec_model = Word2Vec(sentences=X_tokenized, vector_size=100, window=5, min_count=1, workers=4, seed=42)\n",
        "\n",
        "# Generate sentence embeddings by averaging Word2Vec word vectors\n",
        "def get_sentence_embedding(sentence, model):\n",
        "    word_vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
        "    if len(word_vectors) > 0:\n",
        "        return np.mean(word_vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)  # Return a zero vector if no words in the model\n",
        "\n",
        "X_embeddings = X_tokenized.apply(lambda x: get_sentence_embedding(x, word2vec_model))\n",
        "\n",
        "# Convert embeddings to a NumPy array for training\n",
        "X_embeddings = np.array(X_embeddings.tolist())\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0_Y-t35pMT6",
        "outputId": "336f4006-5a06-4ee9-be0a-46cdfb8f3fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 5543.564505\n",
            "R-squared (R2): -0.73554891124415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extracted llm embeddings with autoencoder for dimensionality reduction and gnn model"
      ],
      "metadata": {
        "id": "REyHtR0WobSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import os\n",
        "\n",
        "# Set CUDA settings to avoid certain issues\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load the new dataset, and limit to 1000 rows\n",
        "try:\n",
        "    df = pd.read_csv('/content/sampled_modified_reddit_data.csv', on_bad_lines='skip')  # Adjust with your file path\n",
        "    df = df.head(1000)  # Limit dataset to 1000 rows\n",
        "    print(\"Columns in dataset:\", df.columns)\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Parser error encountered. Some rows were skipped due to formatting issues.\")\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use mean pooling of embeddings across tokens\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Autoencoder Architecture for Dimensionality Reduction\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim=100):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, encoding_dim)  # Compressed representation\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, input_dim),\n",
        "            nn.Sigmoid()  # To ensure outputs are in the range [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded, encoded\n",
        "\n",
        "# Apply Autoencoder for Dimensionality Reduction\n",
        "def apply_autoencoder(embeddings, encoding_dim=100, epochs=100):\n",
        "    autoencoder = Autoencoder(input_dim=embeddings.shape[1], encoding_dim=encoding_dim).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "    # Train Autoencoder\n",
        "    for epoch in range(epochs):\n",
        "        autoencoder.train()\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = autoencoder(torch.tensor(embeddings, dtype=torch.float).to(device))\n",
        "        loss = criterion(output, torch.tensor(embeddings, dtype=torch.float).to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Get the encoded (reduced) embeddings\n",
        "    autoencoder.eval()\n",
        "    with torch.no_grad():\n",
        "        _, encoded_embeddings = autoencoder(torch.tensor(embeddings, dtype=torch.float).to(device))\n",
        "\n",
        "    return encoded_embeddings.cpu().numpy()\n",
        "\n",
        "# Get embeddings for the 'essay' column\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Apply Autoencoder for dimensionality reduction\n",
        "reduced_text_embeddings = apply_autoencoder(text_embeddings, encoding_dim=100, epochs=100)\n",
        "\n",
        "# Convert reduced embeddings to tensor\n",
        "reduced_text_embeddings = torch.tensor(reduced_text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Concatenate reduced embeddings with other features if necessary\n",
        "X = reduced_text_embeddings\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['Num of Comments'].values, dtype=torch.float)  # Assuming 'score' is the target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    \"\"\"Function to create KNN-based edges.\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Parameters\n",
        "k = 15  # Number of nearest neighbors for KNN\n",
        "\n",
        "# Generate edge_index using KNN for the entire training set\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=60, output_dim=1):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.fc = nn.Linear(hidden_dim2, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the GNN model\n",
        "input_dim = X.shape[1]\n",
        "model = GNNModel(input_dim=input_dim)\n",
        "model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Convert training and testing sets to tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Training loop without batching\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Optionally, you can evaluate the model on the test set here.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwNUb7ohoaa2",
        "outputId": "9d91f941-0e79-4bf8-e92e-6ea8e536edc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['Political Lean', 'Score', 'Subreddit', 'Num of Comments', 'body'], dtype='object')\n",
            "Epoch [10/100], Loss: 0.0650\n",
            "Epoch [20/100], Loss: 0.0642\n",
            "Epoch [30/100], Loss: 0.0646\n",
            "Epoch [40/100], Loss: 0.0646\n",
            "Epoch [50/100], Loss: 0.0646\n",
            "Epoch [60/100], Loss: 0.0646\n",
            "Epoch [70/100], Loss: 0.0646\n",
            "Epoch [80/100], Loss: 0.0646\n",
            "Epoch [90/100], Loss: 0.0646\n",
            "Epoch [100/100], Loss: 0.0646\n",
            "Epoch 1/500, Loss: 5139.5439\n",
            "Epoch 2/500, Loss: 5750.7007\n",
            "Epoch 3/500, Loss: 4336.6060\n",
            "Epoch 4/500, Loss: 4641.1870\n",
            "Epoch 5/500, Loss: 4699.3218\n",
            "Epoch 6/500, Loss: 4409.8657\n",
            "Epoch 7/500, Loss: 4344.3159\n",
            "Epoch 8/500, Loss: 4532.2954\n",
            "Epoch 9/500, Loss: 4466.1597\n",
            "Epoch 10/500, Loss: 4333.9268\n",
            "Epoch 11/500, Loss: 4334.1235\n",
            "Epoch 12/500, Loss: 4399.0229\n",
            "Epoch 13/500, Loss: 4428.9819\n",
            "Epoch 14/500, Loss: 4402.3101\n",
            "Epoch 15/500, Loss: 4350.6826\n",
            "Epoch 16/500, Loss: 4319.0635\n",
            "Epoch 17/500, Loss: 4331.3159\n",
            "Epoch 18/500, Loss: 4363.4038\n",
            "Epoch 19/500, Loss: 4343.7271\n",
            "Epoch 20/500, Loss: 4318.4312\n",
            "Epoch 21/500, Loss: 4334.2925\n",
            "Epoch 22/500, Loss: 4343.9331\n",
            "Epoch 23/500, Loss: 4326.8960\n",
            "Epoch 24/500, Loss: 4318.2822\n",
            "Epoch 25/500, Loss: 4320.6504\n",
            "Epoch 26/500, Loss: 4318.6611\n",
            "Epoch 27/500, Loss: 4320.3052\n",
            "Epoch 28/500, Loss: 4318.0039\n",
            "Epoch 29/500, Loss: 4319.8335\n",
            "Epoch 30/500, Loss: 4318.3281\n",
            "Epoch 31/500, Loss: 4319.2593\n",
            "Epoch 32/500, Loss: 4318.3921\n",
            "Epoch 33/500, Loss: 4318.7324\n",
            "Epoch 34/500, Loss: 4318.6499\n",
            "Epoch 35/500, Loss: 4318.2437\n",
            "Epoch 36/500, Loss: 4318.7241\n",
            "Epoch 37/500, Loss: 4318.0195\n",
            "Epoch 38/500, Loss: 4318.6953\n",
            "Epoch 39/500, Loss: 4317.8926\n",
            "Epoch 40/500, Loss: 4318.6011\n",
            "Epoch 41/500, Loss: 4317.8711\n",
            "Epoch 42/500, Loss: 4318.4390\n",
            "Epoch 43/500, Loss: 4317.8882\n",
            "Epoch 44/500, Loss: 4318.2900\n",
            "Epoch 45/500, Loss: 4317.8965\n",
            "Epoch 46/500, Loss: 4318.1509\n",
            "Epoch 47/500, Loss: 4317.9077\n",
            "Epoch 48/500, Loss: 4318.0405\n",
            "Epoch 49/500, Loss: 4317.8940\n",
            "Epoch 50/500, Loss: 4317.9565\n",
            "Epoch 51/500, Loss: 4317.8745\n",
            "Epoch 52/500, Loss: 4317.8906\n",
            "Epoch 53/500, Loss: 4317.8413\n",
            "Epoch 54/500, Loss: 4317.8433\n",
            "Epoch 55/500, Loss: 4317.8071\n",
            "Epoch 56/500, Loss: 4317.8037\n",
            "Epoch 57/500, Loss: 4317.7676\n",
            "Epoch 58/500, Loss: 4317.7715\n",
            "Epoch 59/500, Loss: 4317.7295\n",
            "Epoch 60/500, Loss: 4317.7422\n",
            "Epoch 61/500, Loss: 4317.6909\n",
            "Epoch 62/500, Loss: 4317.7163\n",
            "Epoch 63/500, Loss: 4317.6562\n",
            "Epoch 64/500, Loss: 4317.6890\n",
            "Epoch 65/500, Loss: 4317.6235\n",
            "Epoch 66/500, Loss: 4317.6611\n",
            "Epoch 67/500, Loss: 4317.5947\n",
            "Epoch 68/500, Loss: 4317.6309\n",
            "Epoch 69/500, Loss: 4317.5703\n",
            "Epoch 70/500, Loss: 4317.5967\n",
            "Epoch 71/500, Loss: 4317.5498\n",
            "Epoch 72/500, Loss: 4317.5610\n",
            "Epoch 73/500, Loss: 4317.5308\n",
            "Epoch 74/500, Loss: 4317.5249\n",
            "Epoch 75/500, Loss: 4317.5127\n",
            "Epoch 76/500, Loss: 4317.4902\n",
            "Epoch 77/500, Loss: 4317.4907\n",
            "Epoch 78/500, Loss: 4317.4604\n",
            "Epoch 79/500, Loss: 4317.4634\n",
            "Epoch 80/500, Loss: 4317.4355\n",
            "Epoch 81/500, Loss: 4317.4331\n",
            "Epoch 82/500, Loss: 4317.4136\n",
            "Epoch 83/500, Loss: 4317.3999\n",
            "Epoch 84/500, Loss: 4317.3911\n",
            "Epoch 85/500, Loss: 4317.3696\n",
            "Epoch 86/500, Loss: 4317.3647\n",
            "Epoch 87/500, Loss: 4317.3438\n",
            "Epoch 88/500, Loss: 4317.3340\n",
            "Epoch 89/500, Loss: 4317.3198\n",
            "Epoch 90/500, Loss: 4317.3027\n",
            "Epoch 91/500, Loss: 4317.2939\n",
            "Epoch 92/500, Loss: 4317.2739\n",
            "Epoch 93/500, Loss: 4317.2637\n",
            "Epoch 94/500, Loss: 4317.2485\n",
            "Epoch 95/500, Loss: 4317.2334\n",
            "Epoch 96/500, Loss: 4317.2217\n",
            "Epoch 97/500, Loss: 4317.2031\n",
            "Epoch 98/500, Loss: 4317.1909\n",
            "Epoch 99/500, Loss: 4317.1768\n",
            "Epoch 100/500, Loss: 4317.1597\n",
            "Epoch 101/500, Loss: 4317.1470\n",
            "Epoch 102/500, Loss: 4317.1309\n",
            "Epoch 103/500, Loss: 4317.1157\n",
            "Epoch 104/500, Loss: 4317.1016\n",
            "Epoch 105/500, Loss: 4317.0850\n",
            "Epoch 106/500, Loss: 4317.0703\n",
            "Epoch 107/500, Loss: 4317.0547\n",
            "Epoch 108/500, Loss: 4317.0381\n",
            "Epoch 109/500, Loss: 4317.0229\n",
            "Epoch 110/500, Loss: 4317.0073\n",
            "Epoch 111/500, Loss: 4316.9907\n",
            "Epoch 112/500, Loss: 4316.9746\n",
            "Epoch 113/500, Loss: 4316.9585\n",
            "Epoch 114/500, Loss: 4316.9414\n",
            "Epoch 115/500, Loss: 4316.9253\n",
            "Epoch 116/500, Loss: 4316.9082\n",
            "Epoch 117/500, Loss: 4316.8906\n",
            "Epoch 118/500, Loss: 4316.8745\n",
            "Epoch 119/500, Loss: 4316.8569\n",
            "Epoch 120/500, Loss: 4316.8394\n",
            "Epoch 121/500, Loss: 4316.8228\n",
            "Epoch 122/500, Loss: 4316.8047\n",
            "Epoch 123/500, Loss: 4316.7866\n",
            "Epoch 124/500, Loss: 4316.7686\n",
            "Epoch 125/500, Loss: 4316.7505\n",
            "Epoch 126/500, Loss: 4316.7319\n",
            "Epoch 127/500, Loss: 4316.7134\n",
            "Epoch 128/500, Loss: 4316.6948\n",
            "Epoch 129/500, Loss: 4316.6758\n",
            "Epoch 130/500, Loss: 4316.6562\n",
            "Epoch 131/500, Loss: 4316.6372\n",
            "Epoch 132/500, Loss: 4316.6172\n",
            "Epoch 133/500, Loss: 4316.5977\n",
            "Epoch 134/500, Loss: 4316.5776\n",
            "Epoch 135/500, Loss: 4316.5571\n",
            "Epoch 136/500, Loss: 4316.5366\n",
            "Epoch 137/500, Loss: 4316.5156\n",
            "Epoch 138/500, Loss: 4316.4941\n",
            "Epoch 139/500, Loss: 4316.4736\n",
            "Epoch 140/500, Loss: 4316.4517\n",
            "Epoch 141/500, Loss: 4316.4292\n",
            "Epoch 142/500, Loss: 4316.4072\n",
            "Epoch 143/500, Loss: 4316.3848\n",
            "Epoch 144/500, Loss: 4316.3623\n",
            "Epoch 145/500, Loss: 4316.3394\n",
            "Epoch 146/500, Loss: 4316.3154\n",
            "Epoch 147/500, Loss: 4316.2920\n",
            "Epoch 148/500, Loss: 4316.2681\n",
            "Epoch 149/500, Loss: 4316.2432\n",
            "Epoch 150/500, Loss: 4316.2183\n",
            "Epoch 151/500, Loss: 4316.1934\n",
            "Epoch 152/500, Loss: 4316.1675\n",
            "Epoch 153/500, Loss: 4316.1406\n",
            "Epoch 154/500, Loss: 4316.1143\n",
            "Epoch 155/500, Loss: 4316.0874\n",
            "Epoch 156/500, Loss: 4316.0601\n",
            "Epoch 157/500, Loss: 4316.0327\n",
            "Epoch 158/500, Loss: 4316.0044\n",
            "Epoch 159/500, Loss: 4315.9746\n",
            "Epoch 160/500, Loss: 4315.9453\n",
            "Epoch 161/500, Loss: 4315.9155\n",
            "Epoch 162/500, Loss: 4315.8853\n",
            "Epoch 163/500, Loss: 4315.8540\n",
            "Epoch 164/500, Loss: 4315.8228\n",
            "Epoch 165/500, Loss: 4315.7915\n",
            "Epoch 166/500, Loss: 4315.7612\n",
            "Epoch 167/500, Loss: 4315.7397\n",
            "Epoch 168/500, Loss: 4315.7432\n",
            "Epoch 169/500, Loss: 4315.8511\n",
            "Epoch 170/500, Loss: 4316.3394\n",
            "Epoch 171/500, Loss: 4318.1948\n",
            "Epoch 172/500, Loss: 4322.5107\n",
            "Epoch 173/500, Loss: 4326.1450\n",
            "Epoch 174/500, Loss: 4318.9888\n",
            "Epoch 175/500, Loss: 4316.0942\n",
            "Epoch 176/500, Loss: 4321.4912\n",
            "Epoch 177/500, Loss: 4317.7886\n",
            "Epoch 178/500, Loss: 4316.1675\n",
            "Epoch 179/500, Loss: 4319.5933\n",
            "Epoch 180/500, Loss: 4315.8882\n",
            "Epoch 181/500, Loss: 4317.1455\n",
            "Epoch 182/500, Loss: 4317.6426\n",
            "Epoch 183/500, Loss: 4315.3853\n",
            "Epoch 184/500, Loss: 4317.6006\n",
            "Epoch 185/500, Loss: 4315.6729\n",
            "Epoch 186/500, Loss: 4316.2803\n",
            "Epoch 187/500, Loss: 4316.4136\n",
            "Epoch 188/500, Loss: 4315.3242\n",
            "Epoch 189/500, Loss: 4316.5352\n",
            "Epoch 190/500, Loss: 4315.2539\n",
            "Epoch 191/500, Loss: 4315.8999\n",
            "Epoch 192/500, Loss: 4315.6021\n",
            "Epoch 193/500, Loss: 4315.2769\n",
            "Epoch 194/500, Loss: 4315.7788\n",
            "Epoch 195/500, Loss: 4315.0054\n",
            "Epoch 196/500, Loss: 4315.5771\n",
            "Epoch 197/500, Loss: 4315.0854\n",
            "Epoch 198/500, Loss: 4315.1753\n",
            "Epoch 199/500, Loss: 4315.2397\n",
            "Epoch 200/500, Loss: 4314.8672\n",
            "Epoch 201/500, Loss: 4315.2031\n",
            "Epoch 202/500, Loss: 4314.8125\n",
            "Epoch 203/500, Loss: 4314.9448\n",
            "Epoch 204/500, Loss: 4314.8921\n",
            "Epoch 205/500, Loss: 4314.6841\n",
            "Epoch 206/500, Loss: 4314.8643\n",
            "Epoch 207/500, Loss: 4314.6069\n",
            "Epoch 208/500, Loss: 4314.6582\n",
            "Epoch 209/500, Loss: 4314.6382\n",
            "Epoch 210/500, Loss: 4314.4585\n",
            "Epoch 211/500, Loss: 4314.5576\n",
            "Epoch 212/500, Loss: 4314.4175\n",
            "Epoch 213/500, Loss: 4314.3530\n",
            "Epoch 214/500, Loss: 4314.3921\n",
            "Epoch 215/500, Loss: 4314.2397\n",
            "Epoch 216/500, Loss: 4314.2261\n",
            "Epoch 217/500, Loss: 4314.2124\n",
            "Epoch 218/500, Loss: 4314.0811\n",
            "Epoch 219/500, Loss: 4314.0688\n",
            "Epoch 220/500, Loss: 4314.0356\n",
            "Epoch 221/500, Loss: 4313.9214\n",
            "Epoch 222/500, Loss: 4313.8901\n",
            "Epoch 223/500, Loss: 4313.8584\n",
            "Epoch 224/500, Loss: 4313.7563\n",
            "Epoch 225/500, Loss: 4313.6958\n",
            "Epoch 226/500, Loss: 4313.6675\n",
            "Epoch 227/500, Loss: 4313.5879\n",
            "Epoch 228/500, Loss: 4313.4976\n",
            "Epoch 229/500, Loss: 4313.4487\n",
            "Epoch 230/500, Loss: 4313.3999\n",
            "Epoch 231/500, Loss: 4313.3159\n",
            "Epoch 232/500, Loss: 4313.2261\n",
            "Epoch 233/500, Loss: 4313.1577\n",
            "Epoch 234/500, Loss: 4313.1001\n",
            "Epoch 235/500, Loss: 4313.0312\n",
            "Epoch 236/500, Loss: 4312.9448\n",
            "Epoch 237/500, Loss: 4312.8525\n",
            "Epoch 238/500, Loss: 4312.7603\n",
            "Epoch 239/500, Loss: 4312.6733\n",
            "Epoch 240/500, Loss: 4312.5898\n",
            "Epoch 241/500, Loss: 4312.5083\n",
            "Epoch 242/500, Loss: 4312.4351\n",
            "Epoch 243/500, Loss: 4312.3857\n",
            "Epoch 244/500, Loss: 4312.4189\n",
            "Epoch 245/500, Loss: 4312.7388\n",
            "Epoch 246/500, Loss: 4314.1963\n",
            "Epoch 247/500, Loss: 4320.9272\n",
            "Epoch 248/500, Loss: 4343.2539\n",
            "Epoch 249/500, Loss: 4371.8384\n",
            "Epoch 250/500, Loss: 4343.7490\n",
            "Epoch 251/500, Loss: 4313.3003\n",
            "Epoch 252/500, Loss: 4343.6831\n",
            "Epoch 253/500, Loss: 4318.0229\n",
            "Epoch 254/500, Loss: 4326.1128\n",
            "Epoch 255/500, Loss: 4322.7793\n",
            "Epoch 256/500, Loss: 4319.8477\n",
            "Epoch 257/500, Loss: 4320.8174\n",
            "Epoch 258/500, Loss: 4317.7534\n",
            "Epoch 259/500, Loss: 4317.9175\n",
            "Epoch 260/500, Loss: 4318.4058\n",
            "Epoch 261/500, Loss: 4314.6787\n",
            "Epoch 262/500, Loss: 4318.8462\n",
            "Epoch 263/500, Loss: 4313.0220\n",
            "Epoch 264/500, Loss: 4318.1865\n",
            "Epoch 265/500, Loss: 4313.2832\n",
            "Epoch 266/500, Loss: 4315.9155\n",
            "Epoch 267/500, Loss: 4314.7783\n",
            "Epoch 268/500, Loss: 4313.6055\n",
            "Epoch 269/500, Loss: 4315.7026\n",
            "Epoch 270/500, Loss: 4312.8921\n",
            "Epoch 271/500, Loss: 4314.7886\n",
            "Epoch 272/500, Loss: 4313.7583\n",
            "Epoch 273/500, Loss: 4313.2729\n",
            "Epoch 274/500, Loss: 4314.4136\n",
            "Epoch 275/500, Loss: 4312.8018\n",
            "Epoch 276/500, Loss: 4313.9019\n",
            "Epoch 277/500, Loss: 4313.4585\n",
            "Epoch 278/500, Loss: 4312.8887\n",
            "Epoch 279/500, Loss: 4313.6621\n",
            "Epoch 280/500, Loss: 4312.6753\n",
            "Epoch 281/500, Loss: 4313.1694\n",
            "Epoch 282/500, Loss: 4313.0024\n",
            "Epoch 283/500, Loss: 4312.5854\n",
            "Epoch 284/500, Loss: 4313.0728\n",
            "Epoch 285/500, Loss: 4312.4805\n",
            "Epoch 286/500, Loss: 4312.7026\n",
            "Epoch 287/500, Loss: 4312.6323\n",
            "Epoch 288/500, Loss: 4312.3306\n",
            "Epoch 289/500, Loss: 4312.6089\n",
            "Epoch 290/500, Loss: 4312.2236\n",
            "Epoch 291/500, Loss: 4312.3501\n",
            "Epoch 292/500, Loss: 4312.2520\n",
            "Epoch 293/500, Loss: 4312.0771\n",
            "Epoch 294/500, Loss: 4312.2026\n",
            "Epoch 295/500, Loss: 4311.9312\n",
            "Epoch 296/500, Loss: 4312.0269\n",
            "Epoch 297/500, Loss: 4311.8726\n",
            "Epoch 298/500, Loss: 4311.8120\n",
            "Epoch 299/500, Loss: 4311.8047\n",
            "Epoch 300/500, Loss: 4311.6353\n",
            "Epoch 301/500, Loss: 4311.6807\n",
            "Epoch 302/500, Loss: 4311.5073\n",
            "Epoch 303/500, Loss: 4311.5151\n",
            "Epoch 304/500, Loss: 4311.3979\n",
            "Epoch 305/500, Loss: 4311.3413\n",
            "Epoch 306/500, Loss: 4311.2798\n",
            "Epoch 307/500, Loss: 4311.1753\n",
            "Epoch 308/500, Loss: 4311.1431\n",
            "Epoch 309/500, Loss: 4311.0186\n",
            "Epoch 310/500, Loss: 4310.9907\n",
            "Epoch 311/500, Loss: 4310.8672\n",
            "Epoch 312/500, Loss: 4310.8296\n",
            "Epoch 313/500, Loss: 4310.7139\n",
            "Epoch 314/500, Loss: 4310.6621\n",
            "Epoch 315/500, Loss: 4310.5542\n",
            "Epoch 316/500, Loss: 4310.4912\n",
            "Epoch 317/500, Loss: 4310.3882\n",
            "Epoch 318/500, Loss: 4310.3164\n",
            "Epoch 319/500, Loss: 4310.2144\n",
            "Epoch 320/500, Loss: 4310.1382\n",
            "Epoch 321/500, Loss: 4310.0337\n",
            "Epoch 322/500, Loss: 4309.9546\n",
            "Epoch 323/500, Loss: 4309.8467\n",
            "Epoch 324/500, Loss: 4309.7632\n",
            "Epoch 325/500, Loss: 4309.6533\n",
            "Epoch 326/500, Loss: 4309.5654\n",
            "Epoch 327/500, Loss: 4309.4536\n",
            "Epoch 328/500, Loss: 4309.3589\n",
            "Epoch 329/500, Loss: 4309.2480\n",
            "Epoch 330/500, Loss: 4309.1431\n",
            "Epoch 331/500, Loss: 4309.0366\n",
            "Epoch 332/500, Loss: 4308.9209\n",
            "Epoch 333/500, Loss: 4308.8130\n",
            "Epoch 334/500, Loss: 4308.6929\n",
            "Epoch 335/500, Loss: 4308.5786\n",
            "Epoch 336/500, Loss: 4308.4585\n",
            "Epoch 337/500, Loss: 4308.3335\n",
            "Epoch 338/500, Loss: 4308.2129\n",
            "Epoch 339/500, Loss: 4308.0840\n",
            "Epoch 340/500, Loss: 4307.9531\n",
            "Epoch 341/500, Loss: 4307.8237\n",
            "Epoch 342/500, Loss: 4307.6875\n",
            "Epoch 343/500, Loss: 4307.5488\n",
            "Epoch 344/500, Loss: 4307.4111\n",
            "Epoch 345/500, Loss: 4307.2681\n",
            "Epoch 346/500, Loss: 4307.1196\n",
            "Epoch 347/500, Loss: 4306.9707\n",
            "Epoch 348/500, Loss: 4306.8203\n",
            "Epoch 349/500, Loss: 4306.6655\n",
            "Epoch 350/500, Loss: 4306.5059\n",
            "Epoch 351/500, Loss: 4306.3423\n",
            "Epoch 352/500, Loss: 4306.1772\n",
            "Epoch 353/500, Loss: 4306.0093\n",
            "Epoch 354/500, Loss: 4305.8389\n",
            "Epoch 355/500, Loss: 4305.6646\n",
            "Epoch 356/500, Loss: 4305.4922\n",
            "Epoch 357/500, Loss: 4305.3262\n",
            "Epoch 358/500, Loss: 4305.1992\n",
            "Epoch 359/500, Loss: 4305.2412\n",
            "Epoch 360/500, Loss: 4306.0859\n",
            "Epoch 361/500, Loss: 4311.0132\n",
            "Epoch 362/500, Loss: 4337.3936\n",
            "Epoch 363/500, Loss: 4416.7407\n",
            "Epoch 364/500, Loss: 4418.9312\n",
            "Epoch 365/500, Loss: 4306.2744\n",
            "Epoch 366/500, Loss: 4390.7144\n",
            "Epoch 367/500, Loss: 4318.4985\n",
            "Epoch 368/500, Loss: 4360.2427\n",
            "Epoch 369/500, Loss: 4309.1255\n",
            "Epoch 370/500, Loss: 4347.9609\n",
            "Epoch 371/500, Loss: 4309.6685\n",
            "Epoch 372/500, Loss: 4328.7378\n",
            "Epoch 373/500, Loss: 4327.1284\n",
            "Epoch 374/500, Loss: 4312.3979\n",
            "Epoch 375/500, Loss: 4316.8682\n",
            "Epoch 376/500, Loss: 4318.4072\n",
            "Epoch 377/500, Loss: 4313.3325\n",
            "Epoch 378/500, Loss: 4313.7842\n",
            "Epoch 379/500, Loss: 4316.8213\n",
            "Epoch 380/500, Loss: 4315.0073\n",
            "Epoch 381/500, Loss: 4312.5444\n",
            "Epoch 382/500, Loss: 4314.4912\n",
            "Epoch 383/500, Loss: 4315.2559\n",
            "Epoch 384/500, Loss: 4312.8711\n",
            "Epoch 385/500, Loss: 4313.0376\n",
            "Epoch 386/500, Loss: 4314.5288\n",
            "Epoch 387/500, Loss: 4313.5063\n",
            "Epoch 388/500, Loss: 4312.4033\n",
            "Epoch 389/500, Loss: 4313.4541\n",
            "Epoch 390/500, Loss: 4313.6099\n",
            "Epoch 391/500, Loss: 4312.4253\n",
            "Epoch 392/500, Loss: 4312.6562\n",
            "Epoch 393/500, Loss: 4313.2661\n",
            "Epoch 394/500, Loss: 4312.6343\n",
            "Epoch 395/500, Loss: 4312.2256\n",
            "Epoch 396/500, Loss: 4312.7710\n",
            "Epoch 397/500, Loss: 4312.6689\n",
            "Epoch 398/500, Loss: 4312.1299\n",
            "Epoch 399/500, Loss: 4312.3335\n",
            "Epoch 400/500, Loss: 4312.4897\n",
            "Epoch 401/500, Loss: 4312.1182\n",
            "Epoch 402/500, Loss: 4312.0337\n",
            "Epoch 403/500, Loss: 4312.2622\n",
            "Epoch 404/500, Loss: 4312.0923\n",
            "Epoch 405/500, Loss: 4311.8838\n",
            "Epoch 406/500, Loss: 4312.0205\n",
            "Epoch 407/500, Loss: 4312.0078\n",
            "Epoch 408/500, Loss: 4311.7969\n",
            "Epoch 409/500, Loss: 4311.8120\n",
            "Epoch 410/500, Loss: 4311.8706\n",
            "Epoch 411/500, Loss: 4311.7202\n",
            "Epoch 412/500, Loss: 4311.6523\n",
            "Epoch 413/500, Loss: 4311.7085\n",
            "Epoch 414/500, Loss: 4311.6274\n",
            "Epoch 415/500, Loss: 4311.5269\n",
            "Epoch 416/500, Loss: 4311.5483\n",
            "Epoch 417/500, Loss: 4311.5166\n",
            "Epoch 418/500, Loss: 4311.4160\n",
            "Epoch 419/500, Loss: 4311.4019\n",
            "Epoch 420/500, Loss: 4311.3901\n",
            "Epoch 421/500, Loss: 4311.3081\n",
            "Epoch 422/500, Loss: 4311.2651\n",
            "Epoch 423/500, Loss: 4311.2554\n",
            "Epoch 424/500, Loss: 4311.1924\n",
            "Epoch 425/500, Loss: 4311.1367\n",
            "Epoch 426/500, Loss: 4311.1167\n",
            "Epoch 427/500, Loss: 4311.0688\n",
            "Epoch 428/500, Loss: 4311.0098\n",
            "Epoch 429/500, Loss: 4310.9814\n",
            "Epoch 430/500, Loss: 4310.9404\n",
            "Epoch 431/500, Loss: 4310.8823\n",
            "Epoch 432/500, Loss: 4310.8462\n",
            "Epoch 433/500, Loss: 4310.8071\n",
            "Epoch 434/500, Loss: 4310.7510\n",
            "Epoch 435/500, Loss: 4310.7085\n",
            "Epoch 436/500, Loss: 4310.6689\n",
            "Epoch 437/500, Loss: 4310.6167\n",
            "Epoch 438/500, Loss: 4310.5679\n",
            "Epoch 439/500, Loss: 4310.5269\n",
            "Epoch 440/500, Loss: 4310.4751\n",
            "Epoch 441/500, Loss: 4310.4253\n",
            "Epoch 442/500, Loss: 4310.3823\n",
            "Epoch 443/500, Loss: 4310.3301\n",
            "Epoch 444/500, Loss: 4310.2798\n",
            "Epoch 445/500, Loss: 4310.2334\n",
            "Epoch 446/500, Loss: 4310.1807\n",
            "Epoch 447/500, Loss: 4310.1304\n",
            "Epoch 448/500, Loss: 4310.0806\n",
            "Epoch 449/500, Loss: 4310.0303\n",
            "Epoch 450/500, Loss: 4309.9761\n",
            "Epoch 451/500, Loss: 4309.9248\n",
            "Epoch 452/500, Loss: 4309.8716\n",
            "Epoch 453/500, Loss: 4309.8179\n",
            "Epoch 454/500, Loss: 4309.7646\n",
            "Epoch 455/500, Loss: 4309.7100\n",
            "Epoch 456/500, Loss: 4309.6543\n",
            "Epoch 457/500, Loss: 4309.5981\n",
            "Epoch 458/500, Loss: 4309.5415\n",
            "Epoch 459/500, Loss: 4309.4839\n",
            "Epoch 460/500, Loss: 4309.4258\n",
            "Epoch 461/500, Loss: 4309.3662\n",
            "Epoch 462/500, Loss: 4309.3062\n",
            "Epoch 463/500, Loss: 4309.2466\n",
            "Epoch 464/500, Loss: 4309.1860\n",
            "Epoch 465/500, Loss: 4309.1235\n",
            "Epoch 466/500, Loss: 4309.0640\n",
            "Epoch 467/500, Loss: 4309.0005\n",
            "Epoch 468/500, Loss: 4308.9370\n",
            "Epoch 469/500, Loss: 4308.8750\n",
            "Epoch 470/500, Loss: 4308.8086\n",
            "Epoch 471/500, Loss: 4308.7437\n",
            "Epoch 472/500, Loss: 4308.6782\n",
            "Epoch 473/500, Loss: 4308.6108\n",
            "Epoch 474/500, Loss: 4308.5444\n",
            "Epoch 475/500, Loss: 4308.4751\n",
            "Epoch 476/500, Loss: 4308.4058\n",
            "Epoch 477/500, Loss: 4308.3359\n",
            "Epoch 478/500, Loss: 4308.2642\n",
            "Epoch 479/500, Loss: 4308.1909\n",
            "Epoch 480/500, Loss: 4308.1177\n",
            "Epoch 481/500, Loss: 4308.0425\n",
            "Epoch 482/500, Loss: 4307.9673\n",
            "Epoch 483/500, Loss: 4307.8906\n",
            "Epoch 484/500, Loss: 4307.8130\n",
            "Epoch 485/500, Loss: 4307.7339\n",
            "Epoch 486/500, Loss: 4307.6533\n",
            "Epoch 487/500, Loss: 4307.5718\n",
            "Epoch 488/500, Loss: 4307.4897\n",
            "Epoch 489/500, Loss: 4307.4058\n",
            "Epoch 490/500, Loss: 4307.3242\n",
            "Epoch 491/500, Loss: 4307.2378\n",
            "Epoch 492/500, Loss: 4307.1509\n",
            "Epoch 493/500, Loss: 4307.0640\n",
            "Epoch 494/500, Loss: 4306.9746\n",
            "Epoch 495/500, Loss: 4306.8848\n",
            "Epoch 496/500, Loss: 4306.7935\n",
            "Epoch 497/500, Loss: 4306.7007\n",
            "Epoch 498/500, Loss: 4306.6079\n",
            "Epoch 499/500, Loss: 4306.5112\n",
            "Epoch 500/500, Loss: 4306.4141\n",
            "Training complete.\n",
            "Test Loss: 3210.7141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "y2wRPR91h1hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "print(f'Shape of text_embeddings: {text_embeddings.shape}')\n",
        "print(f'Shape of additional_features: {additional_features.shape}')\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable\n",
        "y = df['score'].values  # Replace 'score' with your actual target column\n",
        "\n",
        "# Convert target variable to binary classification (e.g., score > median is 1, otherwise 0)\n",
        "median_score = np.median(y)\n",
        "y_binary = (y > median_score).astype(int)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = np.mean(test_predictions == y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, test_predictions)\n",
        "print(f'Mean Squared Error (MSE) on Test Set: {mse:.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WhY-Izvh0yV",
        "outputId": "7491e8f6-3a5f-4a67-e30e-1e8c682efc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of text_embeddings: (600, 768)\n",
            "Shape of additional_features: torch.Size([600, 6])\n",
            "Test Accuracy: 0.5417\n",
            "Mean Squared Error (MSE) on Test Set: 0.4583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/sampled_modified_reddit_data.csv')\n",
        "df_one_hot = pd.get_dummies(df['Subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot.values, dtype=torch.float)\n",
        "print(f'Shape of text_embeddings: {text_embeddings.shape}')\n",
        "print(f'Shape of additional_features: {additional_features.shape}')\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable as binary (e.g., above/below median score)\n",
        "median_score = np.median(df['Score'].values)\n",
        "y = (df['Score'].values >= median_score).astype(int)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, test_predictions)\n",
        "print(f'Mean Squared Error (MSE) on Test Set: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZP3N2E-h43L",
        "outputId": "c9d1f5e5-9db7-4cdc-c1d9-28a412339994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of text_embeddings: (200, 768)\n",
            "Shape of additional_features: torch.Size([200, 5])\n",
            "Test Accuracy: 0.5500\n",
            "Mean Squared Error (MSE) on Test Set: 0.4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Rank"
      ],
      "metadata": {
        "id": "xsImLq1sj08V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "# Define a basic list of stopwords\n",
        "basic_stop_words = set([\n",
        "    \"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"by\", \"for\", \"from\", \"has\", \"he\",\n",
        "    \"in\", \"is\", \"it\", \"its\", \"of\", \"on\", \"that\", \"the\", \"to\", \"was\", \"were\",\n",
        "    \"will\", \"with\", \"you\", \"your\", \"i\", \"this\", \"we\", \"but\", \"not\", \"or\", \"they\"\n",
        "])\n",
        "\n",
        "# Simple tokenizer\n",
        "def simple_tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "# Improved TextRank for keyphrase extraction\n",
        "def textrank_keyphrases(text, top_n=20):  # Extract top 20 key phrases\n",
        "    # Tokenize and filter stop words\n",
        "    words = [word.lower() for word in simple_tokenizer(text) if word.isalnum() and word.lower() not in basic_stop_words]\n",
        "\n",
        "    # Handle empty or short texts\n",
        "    if len(words) < 2:\n",
        "        return words\n",
        "\n",
        "    # Build similarity matrix\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(words).toarray()\n",
        "    sim_matrix = tfidf_matrix @ tfidf_matrix.T\n",
        "\n",
        "    # Apply TextRank using networkx\n",
        "    graph = nx.from_numpy_array(sim_matrix)\n",
        "    scores = nx.pagerank(graph)\n",
        "    ranked_words = sorted(scores, key=scores.get, reverse=True)\n",
        "    return [words[i] for i in ranked_words[:top_n]]\n",
        "\n",
        "# Load your dataset\n",
        "file_path = '/content/sampled_modified_reddit_data.csv'  # Replace with your dataset path\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Apply TextRank to extract keyphrases\n",
        "dataset['KeyPhrases'] = dataset['body'].apply(textrank_keyphrases)\n",
        "\n",
        "# Prepare features and target variable\n",
        "X = dataset['KeyPhrases'].apply(lambda x: ' '.join(x))  # Convert keyphrases to a single string\n",
        "y = dataset['Score']  # Target variable is 'Score'\n",
        "\n",
        "# Optional: You can include political lean and subreddit as additional features if needed\n",
        "# One-hot encode categorical variables (Political Lean, Subreddit)\n",
        "X_political_subreddit = pd.get_dummies(dataset[['Political Lean', 'Subreddit']], drop_first=True)\n",
        "\n",
        "# Combine keyphrases with other features\n",
        "X_combined = X_political_subreddit.join(X)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the keyphrases text data using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # Limit features to reduce dimensionality\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['KeyPhrases'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test['KeyPhrases'])\n",
        "\n",
        "# Merge TF-IDF features with political and subreddit features\n",
        "X_train_final = np.hstack([X_train_tfidf.toarray(), X_train.drop('KeyPhrases', axis=1).values])\n",
        "X_test_final = np.hstack([X_test_tfidf.toarray(), X_test.drop('KeyPhrases', axis=1).values])\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train_final, y_train)\n",
        "\n",
        "# Best estimator from Grid Search\n",
        "best_rf_regressor = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_rf_regressor.predict(X_test_final)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R2): {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0QS9Vr8j4lj",
        "outputId": "96902a9e-821f-4ec8-bb2d-cdfbd94527d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Mean Squared Error (MSE): 6984.209843933268\n",
            "R-squared (R2): -1.5764006152828158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YAKE"
      ],
      "metadata": {
        "id": "pMwcU4RRHsVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-s__IJHueQ",
        "outputId": "9a13af5b-9ac3-4a2c-a914-4387a92b9652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.11/dist-packages (from yake) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from yake) (1.26.4)\n",
            "Collecting segtok (from yake)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from yake) (3.4.2)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.11/dist-packages (from yake) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from segtok->yake) (2024.11.6)\n",
            "Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: segtok, yake\n",
            "Successfully installed segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yake import KeywordExtractor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/sampled_dataset_reddit.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extracting text from the 'body' column and defining the target variable\n",
        "texts = df['body']\n",
        "y = df['score']  # Continuous target variable\n",
        "\n",
        "# Initialize YAKE keyword extractor\n",
        "yake_extractor = KeywordExtractor(lan=\"en\", n=1, dedupLim=0.9, top=20, features=None)\n",
        "\n",
        "# Extract key phrases using YAKE for each document\n",
        "yake_keywords = []\n",
        "for text in texts:\n",
        "    keywords = yake_extractor.extract_keywords(text)\n",
        "    key_phrases = [kw[0] for kw in keywords]  # Extract only the key phrases\n",
        "    yake_keywords.append(\" \".join(key_phrases))  # Combine key phrases into a single string\n",
        "\n",
        "# Convert extracted key phrases into a Bag of Words representation\n",
        "vectorizer = CountVectorizer(max_features=100)  # You can adjust max_features based on the dataset size\n",
        "X_yake = vectorizer.fit_transform(yake_keywords)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_yake, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R-squared: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsqXVPmvH2ML",
        "outputId": "63192496-28e1-4280-a814-eadff776e54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3385.1757\n",
            "R-squared: -0.0365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from yake import KeywordExtractor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_modified_reddit_data.csv')\n",
        "df = df.head(1000)\n",
        "\n",
        "# Check if the necessary columns exist in the dataset\n",
        "# Extracting text from the 'body' column and defining the target variable\n",
        "texts = df['body']\n",
        "y = df['Num of Comments']  # Continuous target variable\n",
        "\n",
        "# Initialize YAKE keyword extractor\n",
        "yake_extractor = KeywordExtractor(lan=\"en\", n=1, dedupLim=0.9, top=20, features=None)\n",
        "\n",
        "# Extract key phrases using YAKE for each document\n",
        "yake_keywords = []\n",
        "for text in texts:\n",
        "    keywords = yake_extractor.extract_keywords(text)\n",
        "    key_phrases = [kw[0] for kw in keywords]  # Extract only the key phrases\n",
        "    yake_keywords.append(\" \".join(key_phrases))  # Combine key phrases into a single string\n",
        "\n",
        "# Convert extracted key phrases into a Bag of Words representation\n",
        "vectorizer = CountVectorizer(max_features=100)  # You can adjust max_features based on the dataset size\n",
        "X_yake = vectorizer.fit_transform(yake_keywords)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_yake, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R-squared score\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error: {mse:.4f}')\n",
        "print(f'R-squared: {r2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYqCNTKZH9w5",
        "outputId": "198ed88f-68b4-4b51-ee2e-2ce1d0cccb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 4066.0282\n",
            "R-squared: -0.2730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB Regressor"
      ],
      "metadata": {
        "id": "zpCnBVbaDq3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_modified_reddit_data.csv')\n",
        "df_one_hot = pd.get_dummies(df['Subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot.values, dtype=torch.float)\n",
        "print(f'Shape of text_embeddings: {text_embeddings.shape}')\n",
        "print(f'Shape of additional_features: {additional_features.shape}')\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable\n",
        "y = df['Score'].values  # Replace 'Score' with your actual target column\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost Regressor\n",
        "model = XGBRegressor(n_estimators=500, random_state=42, eval_metric='rmse')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print test loss (e.g., Mean Squared Error)\n",
        "mse = np.mean((test_predictions - y_test) ** 2)\n",
        "print(f'Test Mean Squared Error: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQeFJoHMdnOI",
        "outputId": "bb6d0f2c-5ad9-47c2-b534-11f684db84d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of text_embeddings: (200, 768)\n",
            "Shape of additional_features: torch.Size([200, 5])\n",
            "Test Mean Squared Error: 23579.1480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/sampled_dataset_reddit.csv')\n",
        "df_one_hot = pd.get_dummies(df['subreddit'], prefix='subreddit')\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings in batches\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        # Use the mean pooling of embeddings across tokens (instead of [CLS] token)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Get embeddings for the text column in batches\n",
        "texts = df['body']  # Replace 'body' with your actual text column\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Select additional features from the dataset\n",
        "additional_features = torch.tensor(df_one_hot[['subreddit_gameofthrones', 'subreddit_politics',\n",
        "                                                'subreddit_worldnews', 'subreddit_relationship_advice',\n",
        "                                                'subreddit_nba', 'subreddit_freefolk']].values,\n",
        "                                    dtype=torch.float)\n",
        "print(f'Shape of text_embeddings: {text_embeddings.shape}')\n",
        "print(f'Shape of additional_features: {additional_features.shape}')\n",
        "\n",
        "# Concatenate text embeddings and additional features\n",
        "X = np.hstack([text_embeddings, additional_features])\n",
        "\n",
        "# Define target variable\n",
        "y = df['score'].values  # Replace 'score' with your actual target column\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost Regressor\n",
        "model = XGBRegressor(n_estimators=100, random_state=42,eval_metric='rmse')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Compute and print test loss (e.g., Mean Squared Error)\n",
        "mse = np.mean((test_predictions - y_test) ** 2)\n",
        "print(f'Test Mean Squared Error: {mse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwBuKGOVds-4",
        "outputId": "017f64bd-1f45-4315-9bc2-e3128f6a9969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of text_embeddings: (600, 768)\n",
            "Shape of additional_features: torch.Size([600, 6])\n",
            "Test Mean Squared Error: 3348.1619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PCA dimensionality reduction"
      ],
      "metadata": {
        "id": "fRXHnVOZDv3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "\n",
        "# Set CUDA settings\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Load dataset and limit to 1000 rows\n",
        "df = pd.read_csv('/content/sampled_modified_reddit_data.csv', on_bad_lines='skip')\n",
        "df = df.head(1000)\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "\n",
        "# Define tokenizer and model for DistilBERT\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "distilbert_model.to(device)\n",
        "\n",
        "# Function to get DistilBERT embeddings\n",
        "def get_embeddings(texts, batch_size=32):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(batch_texts.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = distilbert_model(**inputs)\n",
        "\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "        all_embeddings.append(embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "# Apply PCA for Dimensionality Reduction\n",
        "def apply_pca(embeddings, n_components=100):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    reduced_embeddings = pca.fit_transform(embeddings)\n",
        "    explained_variance = sum(pca.explained_variance_ratio_)\n",
        "    print(f\"Explained Variance by {n_components} components: {explained_variance:.4f}\")\n",
        "    return reduced_embeddings\n",
        "\n",
        "# Get embeddings for the 'body' column\n",
        "texts = df['body']\n",
        "text_embeddings = get_embeddings(texts)\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "reduced_text_embeddings = apply_pca(text_embeddings, n_components=200)\n",
        "\n",
        "# Convert reduced embeddings to tensor\n",
        "X = torch.tensor(reduced_text_embeddings, dtype=torch.float)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "y = torch.tensor(df['Num of Comments'].values, dtype=torch.float)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), test_size=0.2, random_state=42)\n",
        "\n",
        "# K-Nearest Neighbors (KNN) to create edges\n",
        "def create_edge_index_knn(data, k=5):\n",
        "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(data)\n",
        "    _, indices = nbrs.kneighbors(data)\n",
        "    edge_index = []\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(1, k):\n",
        "            edge_index.append([i, indices[i, j]])\n",
        "            edge_index.append([indices[i, j], i])\n",
        "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "k = 15\n",
        "edge_index_train = create_edge_index_knn(X_train, k)\n",
        "\n",
        "# Define GNN model\n",
        "class GNNModel(nn.Module):\n",
        "    def _init_(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModel, self)._init_()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "# Train GNN model\n",
        "input_dim = X.shape[1]\n",
        "model = GNNModel(input_dim=input_dim).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Evaluate GNN model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "xIFDjYPk9eam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19ceb5d-ebad-4210-8fb0-12782a71a01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['Political Lean', 'Score', 'Subreddit', 'Num of Comments', 'body'], dtype='object')\n",
            "Explained Variance by 200 components: 1.0000\n",
            "Epoch 10/500, Loss: 4383.9595\n",
            "Epoch 20/500, Loss: 4100.1475\n",
            "Epoch 30/500, Loss: 4008.7278\n",
            "Epoch 40/500, Loss: 3955.9812\n",
            "Epoch 50/500, Loss: 3891.1145\n",
            "Epoch 60/500, Loss: 3827.1133\n",
            "Epoch 70/500, Loss: 3755.3438\n",
            "Epoch 80/500, Loss: 3673.3171\n",
            "Epoch 90/500, Loss: 3573.1245\n",
            "Epoch 100/500, Loss: 3442.1323\n",
            "Epoch 110/500, Loss: 3228.3999\n",
            "Epoch 120/500, Loss: 2916.6372\n",
            "Epoch 130/500, Loss: 2545.2788\n",
            "Epoch 140/500, Loss: 2201.5532\n",
            "Epoch 150/500, Loss: 1916.2351\n",
            "Epoch 160/500, Loss: 1723.5957\n",
            "Epoch 170/500, Loss: 1513.3687\n",
            "Epoch 180/500, Loss: 1313.6660\n",
            "Epoch 190/500, Loss: 1290.4644\n",
            "Epoch 200/500, Loss: 1105.2640\n",
            "Epoch 210/500, Loss: 943.9752\n",
            "Epoch 220/500, Loss: 798.2238\n",
            "Epoch 230/500, Loss: 666.2010\n",
            "Epoch 240/500, Loss: 543.8123\n",
            "Epoch 250/500, Loss: 424.5013\n",
            "Epoch 260/500, Loss: 1258.3362\n",
            "Epoch 270/500, Loss: 2367.8904\n",
            "Epoch 280/500, Loss: 1110.6049\n",
            "Epoch 290/500, Loss: 451.6869\n",
            "Epoch 300/500, Loss: 400.3171\n",
            "Epoch 310/500, Loss: 287.2755\n",
            "Epoch 320/500, Loss: 223.7365\n",
            "Epoch 330/500, Loss: 180.4132\n",
            "Epoch 340/500, Loss: 148.1992\n",
            "Epoch 350/500, Loss: 122.2323\n",
            "Epoch 360/500, Loss: 101.7423\n",
            "Epoch 370/500, Loss: 86.5764\n",
            "Epoch 380/500, Loss: 75.3425\n",
            "Epoch 390/500, Loss: 66.9879\n",
            "Epoch 400/500, Loss: 60.8789\n",
            "Epoch 410/500, Loss: 56.3968\n",
            "Epoch 420/500, Loss: 53.5597\n",
            "Epoch 430/500, Loss: 50.9016\n",
            "Epoch 440/500, Loss: 48.5221\n",
            "Epoch 450/500, Loss: 46.7381\n",
            "Epoch 460/500, Loss: 44.8757\n",
            "Epoch 470/500, Loss: 43.1954\n",
            "Epoch 480/500, Loss: 41.3605\n",
            "Epoch 490/500, Loss: 39.6900\n",
            "Epoch 500/500, Loss: 37.6996\n",
            "Training complete.\n",
            "Test Loss: 5824961.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVR"
      ],
      "metadata": {
        "id": "YoQplF0FEFgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate SVM model\n",
        "svm = SVR(kernel='rbf')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Compute and print MSE\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'SVM Test MSE: {mse:.4f}')"
      ],
      "metadata": {
        "id": "0HyWiHfWEC3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TSNE dimensionality reduction"
      ],
      "metadata": {
        "id": "tUACYLEPEJEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function to get t-SNE embeddings\n",
        "def apply_tsne(embeddings, n_components=2):\n",
        "    tsne = TSNE(n_components=n_components, random_state=42)\n",
        "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
        "    return reduced_embeddings\n",
        "\n",
        "# Apply t-SNE for dimensionality reduction\n",
        "reduced_text_embeddings_tsne = apply_tsne(text_embeddings, n_components=2)\n",
        "\n",
        "# Plot t-SNE results for visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(reduced_text_embeddings_tsne[:, 0], reduced_text_embeddings_tsne[:, 1], c=df['Num of Comments'], cmap='viridis', alpha=0.7)\n",
        "plt.colorbar(label='Number of Comments')\n",
        "plt.title('t-SNE Visualization of Text Embeddings')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.show()\n",
        "\n",
        "# Define GNN model with dropout\n",
        "class GNNModelWithDropout(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModelWithDropout, self).__init__()  # Fixed class name to GNNModelWithDropout\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set device to CUDA or CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming criterion is defined as MSELoss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Prepare data tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "# Train GNN model with dropout\n",
        "model_with_dropout = GNNModelWithDropout(input_dim=X_train.shape[1]).to(device)  # Correct input dimension\n",
        "optimizer = torch.optim.Adam(model_with_dropout.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 500  # Define the number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_with_dropout.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model_with_dropout(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Evaluate GNN model with dropout\n",
        "model_with_dropout.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model_with_dropout(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "    # Calculate MAE\n",
        "    test_mae = mean_absolute_error(y_test, test_output.cpu().numpy())\n",
        "    print(f'Test MAE: {test_mae:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zVw5kOrU_Gy_",
        "outputId": "11555942-d7b9-46a0-d53f-c4fbb501623a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500, Loss: 4360.9604\n",
            "Epoch 20/500, Loss: 4287.2881\n",
            "Epoch 30/500, Loss: 4219.3423\n",
            "Epoch 40/500, Loss: 4203.5864\n",
            "Epoch 50/500, Loss: 4193.7324\n",
            "Epoch 60/500, Loss: 4188.5659\n",
            "Epoch 70/500, Loss: 4183.2598\n",
            "Epoch 80/500, Loss: 4173.8057\n",
            "Epoch 90/500, Loss: 4152.9487\n",
            "Epoch 100/500, Loss: 4119.1660\n",
            "Epoch 110/500, Loss: 4116.0547\n",
            "Epoch 120/500, Loss: 4077.2629\n",
            "Epoch 130/500, Loss: 4137.1636\n",
            "Epoch 140/500, Loss: 4046.7715\n",
            "Epoch 150/500, Loss: 4008.1973\n",
            "Epoch 160/500, Loss: 4268.9976\n",
            "Epoch 170/500, Loss: 4079.6125\n",
            "Epoch 180/500, Loss: 4086.3040\n",
            "Epoch 190/500, Loss: 4052.0437\n",
            "Epoch 200/500, Loss: 4012.5386\n",
            "Epoch 210/500, Loss: 3948.3262\n",
            "Epoch 220/500, Loss: 4431.5669\n",
            "Epoch 230/500, Loss: 4030.3445\n",
            "Epoch 240/500, Loss: 4002.1379\n",
            "Epoch 250/500, Loss: 3954.6067\n",
            "Epoch 260/500, Loss: 3894.5112\n",
            "Epoch 270/500, Loss: 3824.6360\n",
            "Epoch 280/500, Loss: 4679.5088\n",
            "Epoch 290/500, Loss: 4234.1440\n",
            "Epoch 300/500, Loss: 4188.2910\n",
            "Epoch 310/500, Loss: 4136.6074\n",
            "Epoch 320/500, Loss: 4086.0845\n",
            "Epoch 330/500, Loss: 4023.6914\n",
            "Epoch 340/500, Loss: 3958.3853\n",
            "Epoch 350/500, Loss: 3881.6570\n",
            "Epoch 360/500, Loss: 3787.8367\n",
            "Epoch 370/500, Loss: 3621.1555\n",
            "Epoch 380/500, Loss: 4409.3823\n",
            "Epoch 390/500, Loss: 4353.6963\n",
            "Epoch 400/500, Loss: 4301.1265\n",
            "Epoch 410/500, Loss: 4223.8062\n",
            "Epoch 420/500, Loss: 4155.9404\n",
            "Epoch 430/500, Loss: 4131.7236\n",
            "Epoch 440/500, Loss: 4100.6245\n",
            "Epoch 450/500, Loss: 4032.9578\n",
            "Epoch 460/500, Loss: 4089.5261\n",
            "Epoch 470/500, Loss: 4051.9043\n",
            "Epoch 480/500, Loss: 3964.5952\n",
            "Epoch 490/500, Loss: 3871.9727\n",
            "Epoch 500/500, Loss: 3739.4570\n",
            "Training complete.\n",
            "Test Loss: 3334.0610\n",
            "Test MAE: 33.1434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IsoMap"
      ],
      "metadata": {
        "id": "rpSfelk5HScX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import Isomap\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function to get Isomap embeddings\n",
        "def apply_isomap(embeddings, n_components=2, n_neighbors=5):\n",
        "    isomap = Isomap(n_components=n_components, n_neighbors=n_neighbors)\n",
        "    reduced_embeddings = isomap.fit_transform(embeddings)\n",
        "    return reduced_embeddings\n",
        "\n",
        "# Apply Isomap for dimensionality reduction\n",
        "reduced_text_embeddings_isomap = apply_isomap(text_embeddings, n_components=2)\n",
        "\n",
        "# Plot Isomap results for visualization\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(reduced_text_embeddings_isomap[:, 0], reduced_text_embeddings_isomap[:, 1], c=df['Num of Comments'], cmap='viridis', alpha=0.7)\n",
        "plt.colorbar(label='Number of Comments')\n",
        "plt.title('Isomap Visualization of Text Embeddings')\n",
        "plt.xlabel('Isomap Component 1')\n",
        "plt.ylabel('Isomap Component 2')\n",
        "plt.show()\n",
        "\n",
        "# Define GNN model with dropout\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1=900, hidden_dim2=500, hidden_dim3=200, hidden_dim4=60, output_dim=1):\n",
        "        super(GNNModel, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, hidden_dim3)\n",
        "        self.conv4 = GCNConv(hidden_dim3, hidden_dim4)\n",
        "        self.fc = nn.Linear(hidden_dim4, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set device to CUDA or CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming criterion and optimizer are defined somewhere before this part\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Train GNN model with dropout\n",
        "model_with_dropout = GNNModel(input_dim=X_train.shape[1]).to(device)  # Fix input_dim\n",
        "optimizer = torch.optim.Adam(model_with_dropout.parameters(), lr=0.01)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float).to(device)\n",
        "\n",
        "num_epochs = 500  # Number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model_with_dropout.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model_with_dropout(X_train_tensor, edge_index_train.to(device)).squeeze()\n",
        "    loss = criterion(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Evaluate GNN model with dropout\n",
        "model_with_dropout.eval()\n",
        "with torch.no_grad():\n",
        "    edge_index_test = create_edge_index_knn(X_test, k).to(device)\n",
        "    test_X_tensor = torch.tensor(X_test, dtype=torch.float).to(device)\n",
        "    test_output = model_with_dropout(test_X_tensor, edge_index_test).squeeze()\n",
        "    test_loss = criterion(test_output, torch.tensor(y_test, dtype=torch.float).to(device))\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "    # Calculate MAE\n",
        "    test_mae = mean_absolute_error(y_test, test_output.cpu().numpy())\n",
        "    print(f'Test MAE: {test_mae:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M17fOuBtEwbo",
        "outputId": "c0d15e1a-abd3-41a0-ef39-36f37e45b629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzsAAAK9CAYAAAADsXJeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd8FNXaB/DfbN9sS98kJCQh9N4h9I6AKKIoiIJdEWyIXWkWvHa5KJZXwYYFRREUEJBO6EgnJCEkIb33ZMvM+0dkr2sSICHZTfl972c+18zMznlms1n22XPOcwRJkiQQERERERE1MTJ3B0BERERERFQfmOwQEREREVGTxGSHiIiIiIiaJCY7RERERETUJDHZISIiIiKiJonJDhERERERNUlMdoiIiIiIqEliskNERERERE0Skx0iIiIiImqSmOwQUYOwcOFCCILg7jCqjCMsLAx33XWXy2NxV7s1ERMTgzFjxsBkMkEQBPzyyy/uDqlBu+uuu6DX613S1tW+flauXAlBEHDhwgXHvmHDhmHYsGH1FhsRkasw2SGqB5c+PBw6dMjdobhN165d0bJlS0iSVO05AwcOhNlshs1mc2FkDcvevXuxcOFC5OXluTuUWpk5cyZOnDiBV199FV999RV69+5d6Zxhw4ZBEIQrbgsXLqyzuF577bWrTrwuXLhw2bhef/31OouLiIhcS+HuAIioaZo+fTqeffZZ7Nq1C0OGDKl0/MKFC4iKisKcOXOgUCjw4osv4tlnn3VDpFcWHR0Nmax+vhvau3cvFi1ahLvuuguenp4ua7culJaWIioqCi+88ALmzJlT7XkvvPAC7rvvPsfPBw8exNKlS/H888+jQ4cOjv1du3ats9hee+013HLLLZg0adJVP2batGkYP358pf09evSos7gaiz/++MPdIRAR1QkmO0RUL26//XY899xzWLVqVZXJzrfffgtJkjB9+nQAgEKhgELRMN+S1Gp1s2r3amVmZgJApSTt30aPHu30s0ajwdKlSzF69OgGNVSqZ8+euOOOO9wdRoOgUqncHQIRUZ1ouF8ZEjUxaWlpuPvuuxEcHAy1Wo3AwEDceOONTuPkAeDDDz9Ep06doFarERQUhNmzZ1ca4jRs2DB07twZx48fx9ChQ+Hh4YHWrVvjxx9/BADs2LED/fr1g1arRbt27bBlyxanxyckJODhhx9Gu3btoNVq4ePjgylTplSK5dJwvJ07d+LBBx+Ej48PjEYjZsyYgdzc3Mveb0hICIYMGYIff/wRVqu10vFVq1YhIiIC/fr1A1D1XJnNmzdj0KBB8PT0hF6vR7t27fD8889Xiu/fcW/fvh2CIGD79u2Ofbt27cKUKVPQsmVLqNVqhISE4IknnkBpaell7wOoPPfhckOeLsVy/Phx3HXXXWjVqhU0Gg0CAgJwzz33IDs723GdhQsX4qmnngIAhIeHV7pGVXMuzp8/jylTpsDb2xseHh7o378/fvvttyrv/4cffsCrr76K4OBgaDQajBw5ErGxsVe8XwA4evQoxo0bB6PRCL1ej5EjR2Lfvn1OsYeGhgIAnnrqKQiCgLCwsKu6dnU2bNiAwYMHQ6fTwWAwYMKECTh16pTj+J9//gmZTIb58+c7PW7VqlUQBAHLly8HUPH7KS4uxhdffOF4Tutq7lNYWBiuv/56bN++Hb1794ZWq0WXLl0cr7U1a9agS5cu0Gg06NWrF44ePVrldc6fP4+xY8dCp9MhKCgIixcvrjTkUxRFvPfee+jUqRM0Gg3MZjMefPDBSn97kiThlVdeQXBwMDw8PDB8+HCn5+2fTp06hREjRkCr1SI4OBivvPIKRFGsdN6/5+zU9DX1wQcfoFWrVtBqtejbty927dpV5Tyg//73v+jUqRM8PDzg5eWF3r17Y9WqVVXGTkRUGw3za1SiJujmm2/GqVOn8MgjjyAsLAwZGRnYvHkzEhMTHR8SFy5ciEWLFmHUqFGYNWsWoqOjsXz5chw8eBB79uyBUql0XC83NxfXX389pk6diilTpmD58uWYOnUqvvnmGzz++ON46KGHcPvtt+PNN9/ELbfcgqSkJBgMBgAVw4j27t2LqVOnIjg4GBcuXMDy5csxbNgwnD59Gh4eHk6xz5kzB56enli4cKEjpoSEBMcHoOpMnz4dDzzwADZt2oTrr7/esf/EiRM4efJkpQ+t/3Tq1Clcf/316Nq1KxYvXgy1Wo3Y2Fjs2bOnNk8/Vq9ejZKSEsyaNQs+Pj44cOAA/vvf/+LixYtYvXp1ja711VdfVdr34osvIiMjwzH5fPPmzTh//jzuvvtuBAQE4NSpU/jkk09w6tQp7Nu3D4IgYPLkyTh37hy+/fZbvPvuu/D19QUA+Pn5Vdlueno6BgwYgJKSEjz66KPw8fHBF198gRtuuAE//vgjbrrpJqfzX3/9dchkMsybNw/5+fl44403MH36dOzfv/+y93fq1CkMHjwYRqMRTz/9NJRKJT7++GMMGzbMkUhPnjwZnp6eeOKJJxzDv65l4v1XX32FmTNnYuzYsfjPf/6DkpISLF++HIMGDcLRo0cRFhaGESNG4OGHH8aSJUswadIk9OzZE6mpqXjkkUcwatQoPPTQQ45r3Xfffejbty8eeOABAEBERMQVYygpKUFWVlal/Z6enk69jrGxsbj99tvx4IMP4o477sBbb72FiRMn4qOPPsLzzz+Phx9+GACwZMkS3HrrrZWGI9rtdlx33XXo378/3njjDWzcuBELFiyAzWbD4sWLHec9+OCDWLlyJe6++248+uijiI+Px7Jly3D06FGn94P58+fjlVdewfjx4zF+/HgcOXIEY8aMgcVicbqPtLQ0DB8+HDabDc8++yx0Oh0++eQTaLXaq/01XdVravny5ZgzZw4GDx6MJ554AhcuXMCkSZPg5eWF4OBgx3mffvopHn30Udxyyy147LHHUFZWhuPHj2P//v24/fbbrzomIqLLkoiozq1YsUICIB08eFCSJEnKzc2VAEhvvvlmtY/JyMiQVCqVNGbMGMlutzv2L1u2TAIgff755459Q4cOlQBIq1atcuw7e/asBECSyWTSvn37HPs3bdokAZBWrFjh2FdSUlKp/aioKAmA9OWXX1a6j169ekkWi8Wx/4033pAASGvXrr3s85CTkyOp1Wpp2rRpTvufffZZCYAUHR3t2LdgwQLpn29J7777rgRAyszMrPb6l+KLj4932r9t2zYJgLRt27bL3vOSJUskQRCkhISEauOQJEkKDQ2VZs6cWW0cl56Pfz53VbX37bffSgCknTt3Ova9+eabVd5DVe0+/vjjEgBp165djn2FhYVSeHi4FBYW5njdXLr/Dh06SOXl5Y5z33//fQmAdOLEiWrvRZIkadKkSZJKpZLi4uIc+1JSUiSDwSANGTLEsS8+Pv6Kr+uqrF692un3U1hYKHl6ekr333+/03lpaWmSyWRy2l9cXCy1bt1a6tSpk1RWViZNmDBBMhqNTr9DSZIknU532d/ZP126j+q2qKgox7mhoaESAGnv3r2OfZf+xrRarVMcH3/8caXX4cyZMyUA0iOPPOLYJ4qiNGHCBEmlUjle77t27ZIASN98841TrBs3bnTaf+l9Y8KECZIoio7znn/+eQlAla+f/fv3O/ZlZGRIJpOp0mtw6NCh0tChQx0/X+1rqry8XPLx8ZH69OkjWa1Wx3krV66UADhd88Ybb5Q6deokERHVJw5jI3IBrVYLlUqF7du3Vzv8a8uWLbBYLHj88cedvgW+//77YTQaKw1V0uv1mDp1quPndu3awdPTEx06dHAMDQPg+O/z5887xXOJ1WpFdnY2WrduDU9PTxw5cqRSbA888IBTr9KsWbOgUCjw+++/X/a+vby8MH78ePz6668oLi4GUDHk5rvvvkPv3r3Rtm3bah97aR7I2rVrqxxmU1P/vOfi4mJkZWVhwIABkCSp2qFGV2Pbtm147rnn8Mgjj+DOO++ssr2ysjJkZWWhf//+AFDlc3w1fv/9d/Tt2xeDBg1y7NPr9XjggQdw4cIFnD592un8u+++22nuxeDBgwE4vxb+zW63448//sCkSZPQqlUrx/7AwEDcfvvt2L17NwoKCmoVf3U2b96MvLw8TJs2DVlZWY5NLpejX79+2LZtm+NcDw8PrFy5EmfOnMGQIUPw22+/4d1330XLli2vOY4HHngAmzdvrrR17NjR6byOHTsiMjLS8fOlv7ERI0Y4xVHV394l/yzoIAgC5syZA4vF4hhyunr1aphMJowePdrpOenVqxf0er3jObn0vvHII4849bI+/vjjldr8/fff0b9/f/Tt29exz8/PzzFv7mpc6TV16NAhZGdn4/7773fqDZs+fTq8vLycruXp6YmLFy/i4MGDV90+EVFNMdkhcgG1Wo3//Oc/2LBhA8xmM4YMGYI33ngDaWlpjnMSEhIAVCQt/6RSqdCqVSvH8UuCg4MrDSEzmUwICQmptA+AU5JVWlqK+fPnIyQkBGq1Gr6+vvDz80NeXh7y8/Mrxd+mTRunn/V6PQIDAyvNlanK9OnTUVxcjLVr1wKoqD524cKFK37Auu222zBw4EDcd999MJvNmDp1Kn744YdaJz6JiYm466674O3tDb1eDz8/PwwdOhQAqrznq3Hx4kVHnO+8847TsZycHDz22GMwm83QarXw8/NDeHj4NbWXkJBQ6fUBwFHR7N+vkX8nAJc+bF5uvlVmZiZKSkqqbUcURSQlJdU49suJiYkBUJEs+Pn5OW1//PEHMjIynM4fOHAgZs2ahQMHDmDs2LG455576iSONm3aYNSoUZU2o9HodN6/n9dLf2NX87cHADKZzCmRBOBI/C/9TcXExCA/Px/+/v6VnpOioiLHc3Lpd/7vv1E/P79KyUVCQkKl84DK7zmXc6XX1KV4Wrdu7XSeQqGoNKfrmWeegV6vR9++fdGmTRvMnj271sNUiYiqwzk7RC7y+OOPY+LEifjll1+wadMmvPTSS1iyZAn+/PPPWpW2lcvlNdov/WPy8yOPPIIVK1bg8ccfR2RkpGNByKlTp9ZJL8o/XX/99TCZTFi1ahVuv/12rFq1CnK53KlXqiparRY7d+7Etm3b8Ntvv2Hjxo34/vvvMWLECPzxxx+Qy+XVzhey2+2Vfh49ejRycnLwzDPPoH379tDpdEhOTsZdd91Vq3u2WCy45ZZboFar8cMPP1SqJHfrrbdi7969eOqpp9C9e3fo9XqIoojrrruuzp/j6lzNa6EhuPR8fPXVVwgICKh0/N/PbXl5uaMgQFxcHEpKSirNM6tP1/K3d7VEUYS/vz+++eabKo9XN6+rvtXlPXbo0AHR0dFYv349Nm7ciJ9++gkffvgh5s+fj0WLFl1rqEREAJjsELlUREQEnnzySTz55JOIiYlB9+7d8fbbb+Prr792VLaKjo52+tbXYrEgPj4eo0aNqrM4fvzxR8ycORNvv/22Y19ZWVm1C1vGxMRg+PDhjp+LioqQmppa5Zok/6ZWq3HLLbfgyy+/RHp6OlavXo0RI0ZU+aH232QyGUaOHImRI0finXfewWuvvYYXXngB27Ztw6hRoxzfKv877n/3cJw4cQLnzp3DF198gRkzZjj2b968+YoxVOfRRx/FX3/9hZ07d8JsNjsdy83NxdatW7Fo0SKnIgyXejD+6XIFHv4tNDQU0dHRlfafPXvWcfxa+fn5wcPDo9p2ZDJZpR6Ma3WpeIC/v/9Vvc4XLFiAM2fO4K233sIzzzyDZ599FkuXLnU6pybPq6uJoojz5887DeM8d+4cADh6PyIiIrBlyxYMHDjwsgUELv3OY2JinN43MjMzK/UohYaGVvkarOp3XVuX4omNjXV6z7DZbLhw4UKltZR0Oh1uu+023HbbbbBYLJg8eTJeffVVPPfcc9BoNHUWFxE1XxzGRuQCJSUlKCsrc9oXEREBg8GA8vJyAMCoUaOgUqmwdOlSp29JP/vsM+Tn52PChAl1Fo9cLq/0Tex///vfSj0il3zyySdO5aOXL18Om82GcePGXVV706dPh9VqxYMPPojMzMyrmiOQk5NTaV/37t0BwPGcXfqQvHPnTsc5drsdn3zyidPjLn0b/c97liQJ77///lXF/28rVqzAxx9/jA8++MBp/sPl2gOA9957r9K5Op0OQOWErSrjx4/HgQMHEBUV5dhXXFyMTz75BGFhYZXmltSGXC7HmDFjsHbtWqdhiunp6Vi1ahUGDRpUaVjXtRo7diyMRiNee+21KsuUX1rPBwD279+Pt956C48//jiefPJJPPXUU1i2bBl27Njh9BidTndVz6m7LFu2zPHfkiRh2bJlUCqVGDlyJICKnkG73Y6XX3650mNtNpvj3kaNGgWlUon//ve/Tq+3ql5r48ePx759+3DgwAHHvszMzGp7j2qjd+/e8PHxwaeffgqbzebY/80331RKvv5Zhh2oGLLbsWNHSJJU5euAiKg22LND5ALnzp3DyJEjceutt6Jjx45QKBT4+eefkZ6e7hjO5efnh+eeew6LFi3CddddhxtuuAHR0dH48MMP0adPnzpd7PD666/HV199BZPJhI4dOyIqKgpbtmyBj49PledbLBZH/JdiGjRoEG644Yaram/o0KEIDg7G2rVrodVqMXny5Cs+ZvHixdi5cycmTJiA0NBQZGRk4MMPP0RwcLBjgn6nTp3Qv39/PPfcc8jJyYG3tze+++47pw9ZANC+fXtERERg3rx5SE5OhtFoxE8//XTFtYKqkpWVhYcffhgdO3aEWq3G119/7XT8pptugtFodMzLslqtaNGiBf744w/Ex8dXul6vXr0AAC+88AKmTp0KpVKJiRMnOpKgf3r22Wfx7bffYty4cXj00Ufh7e2NL774AvHx8fjpp5+cCltci1deecWxxtHDDz8MhUKBjz/+GOXl5XjjjTfqpI1/MhqNWL58Oe6880707NkTU6dOhZ+fHxITE/Hbb79h4MCBWLZsGcrKyjBz5ky0adMGr776KgBg0aJFWLduHe6++26cOHHC8bz16tULW7ZswTvvvIOgoCCEh4c7Fe6oypEjRyr9PoGKpPqfBQmulUajwcaNGzFz5kz069cPGzZswG+//Ybnn3/eMTxt6NChePDBB7FkyRL89ddfGDNmDJRKJWJiYrB69Wq8//77uOWWW+Dn54d58+ZhyZIluP766zF+/HgcPXoUGzZscJQyv+Tpp5/GV199heuuuw6PPfaYo/R0aGgojh8/Xif3plKpsHDhQjzyyCMYMWIEbr31Vly4cAErV65ERESEU4/bmDFjEBAQgIEDB8JsNuPMmTNYtmwZJkyY4CiTT0R0zdxRAo6oqft36emsrCxp9uzZUvv27SWdTieZTCapX79+0g8//FDpscuWLZPat28vKZVKyWw2S7NmzZJyc3Odzhk6dGiVJVtDQ0OlCRMmVNoPQJo9e7bj59zcXOnuu++WfH19Jb1eL40dO1Y6e/ZspVLHl+5jx44d0gMPPCB5eXlJer1emj59upSdnV2j5+Spp56SAEi33nprlcf/XfJ569at0o033igFBQVJKpVKCgoKkqZNmyadO3fO6XFxcXHSqFGjJLVaLZnNZun555+XNm/eXKnk7+nTp6VRo0ZJer1e8vX1le6//37p2LFjlcpyX6n09JXKFF8q33vx4kXppptukjw9PSWTySRNmTJFSklJkQBICxYscLr+yy+/LLVo0UKSyWRO16iq5HVcXJx0yy23SJ6enpJGo5H69u0rrV+/3umcS2WCV69e7bT/Uuz/vN/qHDlyRBo7dqyk1+slDw8Pafjw4U7llv95vWstPf3PuMeOHSuZTCZJo9FIERER0l133SUdOnRIkiRJeuKJJyS5XO5UOlmSJOnQoUOSQqGQZs2a5dh39uxZaciQIZJWq61UgvnfrvQ7/edjr/Zv7J/X/efzM3PmTEmn00lxcXHSmDFjJA8PD8lsNksLFixwKjl/ySeffCL16tVL0mq1ksFgkLp06SI9/fTTUkpKiuMcu90uLVq0SAoMDJS0Wq00bNgw6eTJk1W+fo4fPy4NHTpU0mg0UosWLaSXX35Z+uyzz6669PTVvqaWLl0qhYaGSmq1Wurbt6+0Z88eqVevXtJ1113nOOfjjz+WhgwZIvn4+EhqtVqKiIiQnnrqKSk/P7/S80BEVFuCJDWwmapE1GBcWtDw4MGD6N27t7vDIaJGShRF+Pn5YfLkyfj000/dHQ4RNSOcs0NERER1pqysrNJ8tS+//BI5OTkYNmyYe4IiomaLc3aIiIiozuzbtw9PPPEEpkyZAh8fHxw5cgSfffYZOnfujClTprg7PCJqZpjsEBERUZ0JCwtDSEgIli5d6igcMmPGDLz++utQqVTuDo+ImhnO2SEiIiIioiaJc3aIiIiIiKhJYrJDRERERERNEufsXIEoikhJSYHBYHBaDI2IiIiIGgZJklBYWIigoKA6W2C5LpWVlcFisbi8XZVKBY1G4/J2GxImO1eQkpKCkJAQd4dBRERERFeQlJSE4OBgd4fhpKysDOFh3khLL3V52wEBAYiPj2/WCQ+TnSswGAwAKv54jEajm6MhIiIion8rKChASEiI43NbQ2KxWJCWXoqEE7fDaHBdRcKCQgtCu6yCxWJhskPVuzR0zWg0MtkhIiIiasAa8pQDg0EBg9F1H70liC5rqyFreIMaiYiIiIiI6gCTHSIiIiIiapI4jI2IiIiIqJ6JkgRRklzaHrFnh4iIiIiImij27BARERER1TMREkS4sGfHhW01ZOzZISIiIiKiJok9O0RERERE9Uz6+3+ubI/Ys0NERERERE0Ukx0iIiIiImqSOIyNiIiIiKieiXBx6WkOYwPAnh0iIiIiIgKQnJyMO+64Az4+PtBqtejSpQsOHTrkOC5JEubPn4/AwEBotVqMGjUKMTExTtfIycnB9OnTYTQa4enpiXvvvRdFRUWuvhUHJjtERERERPVMdMNWE7m5uRg4cCCUSiU2bNiA06dP4+2334aXl5fjnDfeeANLly7FRx99hP3790On02Hs2LEoKytznDN9+nScOnUKmzdvxvr167Fz50488MADNYym7giSxOVVL6egoAAmkwn5+fkwGo3uDoeIiIiI/qUhf167FFty/O0wGlSua7fQghbhq676OXn22WexZ88e7Nq1q8rjkiQhKCgITz75JObNmwcAyM/Ph9lsxsqVKzF16lScOXMGHTt2xMGDB9G7d28AwMaNGzF+/HhcvHgRQUFBdXeDV4k9O0RERERETVRBQYHTVl5eXuV5v/76K3r37o0pU6bA398fPXr0wKeffuo4Hh8fj7S0NIwaNcqxz2QyoV+/foiKigIAREVFwdPT05HoAMCoUaMgk8mwf//+errDy2OyQ0RERERUz0RILt8AICQkBCaTybEtWbKkyvjOnz+P5cuXo02bNti0aRNmzZqFRx99FF988QUAIC0tDQBgNpudHmc2mx3H0tLS4O/v73RcoVDA29vbcY6rsRobEREREVETlZSU5DSMTa1WV3meKIro3bs3XnvtNQBAjx49cPLkSXz00UeYOXOmS2KtD+zZISIiIiKqZ5Ib/gcARqPRaasu2QkMDETHjh2d9nXo0AGJiYkAgICAAABAenq60znp6emOYwEBAcjIyHA6brPZkJOT4zjH1ZjsEBERERE1cwMHDkR0dLTTvnPnziE0NBQAEB4ejoCAAGzdutVxvKCgAPv370dkZCQAIDIyEnl5eTh8+LDjnD///BOiKKJfv34uuIvKOIyNiIiIiKie/XMejavaq4knnngCAwYMwGuvvYZbb70VBw4cwCeffIJPPvkEACAIAh5//HG88soraNOmDcLDw/HSSy8hKCgIkyZNAlDRE3Tdddfh/vvvx0cffQSr1Yo5c+Zg6tSpbqnEBjDZISJUlJMsyi+FKEoweGohk7HTl4iIqDnp06cPfv75Zzz33HNYvHgxwsPD8d5772H69OmOc55++mkUFxfjgQceQF5eHgYNGoSNGzdCo9E4zvnmm28wZ84cjBw5EjKZDDfffDOWLl3qjlsCwHV2rqgh120nulaSJOGvqFjsWP8XLkSnQpIA/xZeGHxdVwwc2xlyhdzdIRIREV1RQ/68dim2C/G3uXydnbDw7xvkc+JK7Nkhasb+/OUIfv58JywWG/QmLQRBQFJcBr5ZthkJMWm4/ZHRkMvZy0NERHStJACii9sjFiggarZSE7Ox7us9EGQCAlv6wGDygN6ohbmFFwwmLfb+cRLH98W6O0wiIiKiWmOyQ9RMHd4ZjaKCUnj5GSod0xm0sNvt2Lf1tBsiIyIianpEN2zEZIeo2Uq7mAOZTAZBEKo8rtaqkByf6eKoiIiIiOoOkx2iZkqjVUESq//ex2a1Q+PhuomURERERHWNyQ5RM9WpTzhkCjnKy6yVjol2ETaLHT0Ht3NDZERERE2PKLl+IyY7RM1W597haNslGFmpeSgpKsOlKvTlZVakJeUgIMQb/Ud2dHOURERERLXHZIeomVKqFLj3mevRLbI1SovKkZqYjdTEbORlFyKsXQAeeOEGePs137r8REREdUlyw0ZcZ4eoWfP00WPO4sk4fyYFsaeSIYkSWoT7oWPPUC4oSkRERI0ekx2iZk4QBER0bIGIji3cHQoREVGT5epy0Cw9XYHD2IiIiIiIqEliskNERERERE0Sh7EREREREdUzV5eDZunpCuzZISIiIiKiJok9O0RERERE9UyEABGCS9sj9uwQEREREVETxWSHiIiIiIiaJA5jIyIiIiKqZxzG5h7s2SEiIiIioiapwSQ7O3fuxMSJExEUFARBEPDLL784HZckCfPnz0dgYCC0Wi1GjRqFmJiYK173gw8+QFhYGDQaDfr164cDBw7U0x0QEREREVVNkgSXb9SAkp3i4mJ069YNH3zwQZXH33jjDSxduhQfffQR9u/fD51Oh7Fjx6KsrKzaa37//feYO3cuFixYgCNHjqBbt24YO3YsMjIy6us2iIiIiIiogRAkSWpwSw4JgoCff/4ZkyZNAlDRqxMUFIQnn3wS8+bNAwDk5+fDbDZj5cqVmDp1apXX6devH/r06YNly5YBAERRREhICB555BE8++yzVxVLQUEBTCYT8vPzYTQar/3miIiIiKhONeTPa5diOxJ7OwwGlcvaLSy0oGfrVQ3yOXGlBtOzcznx8fFIS0vDqFGjHPtMJhP69euHqKioKh9jsVhw+PBhp8fIZDKMGjWq2scAQHl5OQoKCpw2IiIiIiJqfBpFspOWlgYAMJvNTvvNZrPj2L9lZWXBbrfX6DEAsGTJEphMJscWEhJyjdETEREREZE7NIpkx5Wee+455OfnO7akpCR3h0REREREjZwEGUQXbhI/5gNoJMlOQEAAACA9Pd1pf3p6uuPYv/n6+kIul9foMQCgVqthNBqdNiIiIiIianwaRbITHh6OgIAAbN261bGvoKAA+/fvR2RkZJWPUalU6NWrl9NjRFHE1q1bq30MEREREVF9kNywEaBwdwCXFBUVITY21vFzfHw8/vrrL3h7e6Nly5Z4/PHH8corr6BNmzYIDw/HSy+9hKCgIEfFNgAYOXIkbrrpJsyZMwcAMHfuXMycORO9e/dG37598d5776G4uBh33323q2+PiIiIiIhcrMEkO4cOHcLw4cMdP8+dOxcAMHPmTKxcuRJPP/00iouL8cADDyAvLw+DBg3Cxo0bodFoHI+Ji4tDVlaW4+fbbrsNmZmZmD9/PtLS0tC9e3ds3LixUtECIiIiIiJqehrkOjsNSUOu205EREREDfvz2qXYDsTeCb0L19kpKrSgb+uvGuRz4kqNYs4OERERERFRTTWYYWxERERERE2VKAkQJcGl7RF7doiIiIiIqIlizw4RERERUT27tNinK9sj9uwQEREREVETxWSHiIiIiIiaJA5jIyIiIiKqZyIEiHBhgQIXttWQsWeHiIiIiIiaJPbsEBERERHVM5aedg/27BARERERUZPEZIeIiIiIiJokDmMjIiIiIqpnEgRILiwa4Mq2GjL27BARERERUZPEnh0iIiIionrG0tPuwZ4dIiIiIiJqktizQ0Sw2+w4sz8W508kQpKAlu2D0HlgOyhVfIsgIiKixoufZIiauYzELHz+0g+IP5UEu80OABBkMgS3CcDdi6agZfsWbo6QiIio8eMwNvfgMDaiZqysuAyfPLsK547Ew9PPgKAIM4IizPAJ9ETimWR88uy3yMsscHeYRERERLXCZIeoGTvy5ylcOJMMc5gv1B5qx36VRomAVv5Ijc/AgY1/uS/ARkCSJFjKrZAkyd2hEBFRAyZBBtGFm8SP+QA4jI2oWTu59xwgSVXOzZHLZVAo5fhr22mMuXOIG6Jr2HIz8rH7p33Yu+4QSgpKYPDSY+Ckvhg0uR8MXnp3h0dERERgskPUrJUVl0Emr/6bH7lChvJSiwsjahwykrLwwaOfI/HMRag91FBpVMi8mI3Vb/2Kw5uPY85/74Gnn8ndYRIRUQMiSoAouXDODgccAOAwNqJmLbhNAGxWe7VDsMpLLAhuG+jiqBq+1W/9ioQzFxEQboZfsA9Mvgb4h/jCP9QPsUfj8fPS390dIhEREYHJDlGjZ7fZcSrqHH56/3d898ZabPt+LwqyC6/qsX3GdofO5IHc9PxKx/KzC6H2UKH/+B51HXKjlno+HaejzsHTzwSFUu50TKlSwOitx9GtJ5GbnueeAImIiMiBw9iIGrH8rEJ89uJ3OHcoDpZyKwShonv89//7E7c9fQN6j+562ceHtA3EDQ+Ows/LNiElLh06Tw8IgoDivBLIFXKMvnMw2veNcMWtNBqp8RkoLSyFl3/Vw9R0Jg9kJecg7UImvMyerg2OiIgaLJaedg8mO0SNlCiKWDH/e5zccxa+Qd7Q6CqqqdntIrIu5uCrxT/Cy9+IiG5hl73OqOmDYA71xc6f9iP2rwRAAtr3bY0hk/ui95iujgSqOchKzsHxnWdQUlACT38Tug/vBL2nzukchVIOQSaD3W6HQlb5LdRuFyHIZVyQlYiIqAHgv8ZEjdS5w/GIPhgHn0AvR6IDVFRR82/pg5S4dOz4cd8Vkx1BENB1cAd0HdwBZSXlgCRB7aFuVkmO3WbH2g82Ydv3e1CcVwJBJgAS4Gk2YtLscRh8cz/HuRHdw+BlNiE/swA+Qd6VrpWfWQC/Ft5o2THYlbdAREQNnCQJkFxYoMCVbTVknLND1EidO1wxdE2r11Q6JggCdEYtTu6OhtViu+prajzU0Og0zSrRAYANn/+J3/9vKyRRQmArfwS1MsMc6oui3BKsWrIGhzcfd5yrM3pg2G0DUV5qQX5WoaO4gyRKyE3Ph90uYuT0wVCple66HSIiIvobkx2iRspmtV/2uEwhhyiKsNsuf15zV5RXjD+/3QOVRgkvfxNksoq3RblCDv8QH1jKrNi0cjtEUXQ8Zty9IzB65jDYbXYkx6QhOSYVyXFpgABMfGg0hk0d6K7bISIion/gMDaiRiogzA+CTIDNaoNCWflPuSS/BBHdwqDWqtwQXeMRfTAOeRn5CAj1q/K4p58RSdEpSIlLR3CbijLccoUcU5+ehEE39cOxbSdRlFcCk68BPUZ2gbma6xARUfNmhwx2F/YzuLKthozJDlEj1WN4Z/gFb0HmxRwEhFYkPpcUF5QAgoBBN/VpdkPSaqq81AJJQrWLqyqUcoh2OyxVLK4a3CbQkQARERFRw8OUj6iR0uo1uOOFyTB665Ecl4ac1DzkZxYgNT4DhTnFGHhjb/Sf0NPdYTZ4fsHeUGmUKCsur/J4SUEpNHoNfFtULkZARER0tUQ3bMRkh6hR6xTZFk98dD/G3DkUHkYtZAo52veJwD0v34Y7XpgMuUJ+5Ys0cxHdwxDWKQQ5qXlO83IAwGa1oTCvBL3HdIPRx+CmCImIiKi2OIyNqJELbhOIqU/fgNuemghRlCCvZjgWVU0mk2HqMzfiwye+QHJsGvSeOqjUFT09pcVlaNW1Ja5/YJS7wyQiokZOggySC/sZXNlWQ8ZngaiJEASBiU4thXduiceX34+R0wdDoVLAUm6F3kuHibPG4NEP7oOX2dPdIRIREVEtsGeHiAhAi9YBuPOlW3DL3OtRVlwOncmDa+UQERE1ckx2iIj+QavTQKurvFArERHRtRAlAaLkugqprmyrIeOYFyIiIiIiapLYs0NEREREVM9ECBDhwp4dF7bVkLFnh4iIiIiImiQmO0RERERE1CRxGBsRERERUT2TXFygQGKBAgDs2SEiIiIioiaKPTtERERERPVMhAyiC/sZXNlWQ8ZngYiIiIiImiT27BARERER1TNJqthc2R6xZ4eIiIiIiJooJjtERERERNQkcRgbEREREVE9Y4EC9+CzQERERERETRJ7doiIiIiI6pkIASJct9CnK9tqyNizQ0RERERETRJ7doiI/kGSJBTnl0CSAL2nBwSB34wRERE1Vkx2iIhQkeQc2nwcO1bvQ9LZZABAcNsgDL65L/qN68Gkh4iIrgmHsbkHkx0iavYkScL6T7bgt0+3wm4Xoff0ACDg3JHziD12AcmxaZj8yDgmPERERI0Mkx0iavbOn0jEppXbodKq4OlndOw3eOmQn12Ird/sRucB7dCud4QboyQiosZMkgRIkuu+NHNlWw0ZCxQQUbN3cOMxlBaVw+RrqHTM5GNAeakF+38/6obIiIiI6FqwZ4eImr3k2DQo1Ipqh6mpNEokx6a5OCoiImpKOGfHPdizQ0Q1JkmSu0OoU1q9GnabvdrjNqsdGp3ahRERERFRXWDPDhFdleL8EuxddxhR648gL6MAJj8DIq/viQETe0HvqavVNSVJQlJsOrLT8qHWKtG6cwhUGmUdR35lXYd0xJGtJ2Gz2KBQOb8t2qx2iHYRPYZ3dnlcREREdG3Ys0NEV5SXWYClj67Ed2+uQ0pcGmw2G1LPp+OHt9bj/TkrkJeRX+NrJsak4b15q/DGI1/iwxdXY+kz3+Pl+/8PO9cdcXnPUc+RnRHWMRjpCVkoKy537C8vKUfahQyEtAtCr9FdXRoTERE1LaIEiJLgwq1m8S1cuBCCIDht7du3dxwvKyvD7Nmz4ePjA71ej5tvvhnp6elO10hMTMSECRPg4eEBf39/PPXUU7DZbHXx9NUakx0iuqKfl21CzNF4+Lf0gX9LX3j6GeHf0hd+LX0QdzwBPy3dUKPrpcRnYvlLP+LUwXhodWoEhvrC29+IrLR8fLv0D2xbc6ie7qRqHgYtHnjjDrTrE4GC7EKkxKUjJS4NeVmFaNMjHA/+5w4YvGrXe0VERNRYdOrUCampqY5t9+7djmNPPPEE1q1bh9WrV2PHjh1ISUnB5MmTHcftdjsmTJgAi8WCvXv34osvvsDKlSsxf/58d9yKA4exEdFlZafm4a9tp2Dw1kH5ryFeSpUCRm89ju08i8yLOfAL9r6qa25evR+ZybkIDPeFTFbxnYtSrYB/Cy9kpeVh47d70XdUJ+hNHnV+P5dYyiw4vT8OhTlF8DBp0alfGzz56YOIPhiHCyeTAAChHVugfd/WkCvk9RYHERE1DyJkEF3Yz1CbthQKBQICAirtz8/Px2effYZVq1ZhxIgRAIAVK1agQ4cO2LdvH/r3748//vgDp0+fxpYtW2A2m9G9e3e8/PLLeOaZZ7Bw4UKoVKprvqfaYLJDRJeVej4dJYWl8G/pU+VxnacH0i9kIe1CxlUlO8UFpTi2JwZ6Tw9HovNPXr4GZFzMxckDceg/uss1x1+Vg5uP45cPNyPzYjZEUYQgCPAJ9MSEe0Zg0KTe6Ni/Tb20S0RE5GoFBQVOP6vVaqjVVRfdiYmJQVBQEDQaDSIjI7FkyRK0bNkShw8fhtVqxahRoxzntm/fHi1btkRUVBT69++PqKgodOnSBWaz2XHO2LFjMWvWLJw6dQo9evSonxu8Ag5jI6LLUijlkMlkEO1ilcdFuwiZTIBMfnVvJ0UFpbBabNUWIrjUi1KUX1q7gK/grx1n8OXLa5B5MRs+gZ4IamWGXwtv5GUW4ts3f0XU+iP10i4REZE7hISEwGQyObYlS5ZUeV6/fv2wcuVKbNy4EcuXL0d8fDwGDx6MwsJCpKWlQaVSwdPT0+kxZrMZaWkVSzOkpaU5JTqXjl865i7s2SGiywrrFAwvswn5WUXwbeFV6XhBViG8zCa06tLyqq6nN2mhUitQXmqBtopyzpdKQBvrYY6MKIr4fcU2lBaXITDc37GujkKlgH+ID9ITsvD7iu3oPaYrVGrXV4UjIqKmS4IAyYVr31xqKykpCUaj0bG/ul6dcePGOf67a9eu6NevH0JDQ/HDDz9Aq9XWb7D1qNH07ISFhVWqECEIAmbPnl3l+StXrqx0rkajcXHURI2fRqfBsFv7w2qxIj+70FEpTZIkFOQUobzMiqG39INWf3V/XzqDFj2HtkdxQWmVvUU5GQXw8jeic7+IOr0PAEiKTsXFc6nw8jdVuYCol9mEzIvZiDl6oc7bJiIicgej0ei0VZfs/Junpyfatm2L2NhYBAQEwGKxIC8vz+mc9PR0xxyfgICAStXZLv1c1TwgV2k0yc7BgwedqkNs3rwZADBlypRqH2M0Gp0ek5CQ4KpwiZqU0XcMxqjpg2G32pESl47k2DSkxKbDVm7DqGkDMXbm0Bpdb9SUfggM9UVqQhYK80pgt9lRVmJBWmI2ZIKA62cMgsdVJk81UVpUBpvVDqW66k5tpVoBm9WOsuKyOm+biIiaN8mlZacFSNK19SIVFRUhLi4OgYGB6NWrF5RKJbZu3eo4Hh0djcTERERGRgIAIiMjceLECWRkZDjO2bx5M4xGIzp27HhNsVyLRjOMzc/Pz+nn119/HRERERg6tPoPWYIguDWTJGoq5Ao5bp07AQMm9sLRP0+iMLcYBi8dug/riJB2QVX2klyOOdgbD78yBWs/34Ezh+KRlZIHuUKO4Ah/jJ0aiT4j6udN0dPfCLVWhbLicug9K7/9lRWXQ6VVwdPfVC/tExERNVTz5s3DxIkTERoaipSUFCxYsAByuRzTpk2DyWTCvffei7lz58Lb2xtGoxGPPPIIIiMj0b9/fwDAmDFj0LFjR9x555144403kJaWhhdffBGzZ8++6t6k+tBokp1/slgs+PrrrzF37tzLfsgqKipCaGgoRFFEz5498dprr6FTp06XvXZ5eTnKy/+3qOC/K1jUl9Tz6Yhafwgxh+Mhkwlo368N+k3oCf8QX5e0T3QlgiAgpG0gQtoG1sn1AkN98dCim5F+MQc56fnQaFVo2TagXss8B4T6oX2fVji89SQ8jFqnanCSKCEnLQ9te4ajVeeQeouBiIiap0s9Lq5sryYuXryIadOmITs7G35+fhg0aBD27dvn6HB49913IZPJcPPNN6O8vBxjx47Fhx9+6Hi8XC7H+vXrMWvWLERGRkKn02HmzJlYvHhxnd5XTQmSq5cqrwM//PADbr/9diQmJiIoKKjKc6KiohATE4OuXbsiPz8fb731Fnbu3IlTp04hODi42msvXLgQixYtqrQ/Pz/faXJXXTq48Si+fuVHFGQVQqlWQpIAa7kVPkFeuPvlqeg8qEO9tEvUHCWdS8WHT36F9KQsGL31UHuoYSmzIj+rEN5mEx78z+1o0z3M3WESEVENFBQUwGQy1evntdq6FNtHx16C1uC6+eOlhWV4qNvLDfI5caVGmeyMHTsWKpUK69atu+rHWK1WdOjQAdOmTcPLL79c7XlV9eyEhITU2wvlYkwq3rxrGUqLyuDf0tfRUyWKEtIupMPL34TnvnkcPoGVq2ARUe0kx6Vjw8rtOLE7GpYyK5QqBTr0a41xM4cirFP1X4YQEVHDxGSnMiY7FRrdMLaEhARs2bIFa9asqdHjlEolevTogdjY2Mued7mFlurDvvWHUJBdiBZtAp2G5MlkAgLC/JEal46DG47iuntGuCwmoqauRYQZ9718G/IyClCQUwSdpwd8AjzdHRYRETVhIgSILiw97cq2GrJGU43tkhUrVsDf3x8TJkyo0ePsdjtOnDiBwMC6mW9QV87uj4FKq6py7pFMJoNMLkPMkfNuiIyo6fP0N6Jl+yAmOkRERE1Uo+rZEUURK1aswMyZM6FQOIc+Y8YMtGjRwrEq7OLFi9G/f3+0bt0aeXl5ePPNN5GQkID77rvPHaFXSxAEoNENJCQiIiKimnDXoqLNXaNKdrZs2YLExETcc889lY4lJiY6VVbKzc3F/fffj7S0NHh5eaFXr17Yu3evW+t8V6V9vzaIPRoPSZIq9e6IdhF2u4g2PVu5KToiIiIiosarUSU7Y8aMQXX1FLZv3+7087vvvot3333XBVFdm8iJvbHzx31IT8iCuaUvBNmlAgUi0i5kwCfQC33H93BzlNScSJKEi+dSkXD6IgRBQKuuLRHYyuzusIiIiIhqrFElO01RUEQA7pw/BV8vXo3k2FQoVEpAkmCz2ipKT78yDd4BrMRGrpGbnodvXl2D01HnUFZcDgmAh0GL7sM64bZnboTRW1+r6xYXlODI5hM4FRUNm8WGlh1aoO+4HggI86/bGyAiImqgWKDAPZjsNAC9x3RDSLsg7P/tCM4djvt7UdG26Du+B3yDvN0dHjUTJYWlWD73S5w7fB5e/kZ4/z1pvyi3GHvWHkRBTiEe/eA+KFU1e9u4GJOKj5/6CikxqZBQUXjj8Obj2PL1Ltw67wYMuqlv3d8MEREREZjsNBjmUD/c8PBYd4dBzdihTccQ91c8AkJ9oVQrHfsN3nqoNEqc2ReD4ztOo9forld9TUuZBf/37De4GJ2CgDA/KJQVbzmSKCErJQffvv4LzKG+nJdGRERNnigJECUX9uy4sK2GrNGVniai+nHoj2OAIHNKdC5Re6gh2kUc/fNEja55bPtpJEWnwNzS15HoAIAgE+DbwhslhaXY/fOBa46diIiIqCrs2SEiAEBRXjGUKnm1x+UKOQpzimt0zbjjCRDtYpUJlCAI8NBrcHJPdJXVCImIiJoSSRIgubC3xZVtNWTs2SEiAIB/S19YyqxVHpP+Lprh39KnRteURPGyxwWZAPEK5xARERHVFpMdIgIA9BvfE3KlHCUFpZWOFeUWQ61Vo/eYbjW6Zki7FhBkAmxWe5XHSwpK0bZnK/bqEBERUb3gMDYiAgB0HdIB/Sf0xJ61B1FcUAKDlx6SJKEwpwg2u4iRtw9C294RNbpmz1Fd8NsnW5CemInAcH/Hwr+SJCEvswAqrQqDJ/erj9tpFERRRPTBOPy17RQKcgrhHeCFXqO6ILxLSyaARERNDIexuQeTHSICUDEnZ8bCWxEUEYCdP+1Dblo+IAD+ob4YdusADLttQI0/gHsYtLj7lan49NlvkBKXDqVaCblchrKScmj1Gkx8aDQ6DWxXT3fUsJWXWvDFgu9xePMJWMoskMlkEEURf67ahSG39Met826AXFH9HCoiIiK6MiY7ROSgVCkw7t4RGDl9ENITsiAIgDnMv8Zr6/xT216t8MzK2di3/jCObT8Fq8WG8C4tETmxN9r0DG+2PRg/L/0dUeuOwMtshH9IxVwoSZJQmFuMLV/vgk+gN8bMHOrmKImIqK7YIcDuwoU+XdlWQ8Zkh4gqUWlUCGkXVGfX823hjesfHI3rHxxdZ9dszHIz8hG17jB0Ji10Rg/HfkEQYPTWo7ykHNu+34Nht0VCpVG5MVIiIqLGjQUKiIhcLP54AgpzimDyMVR53OhjQE5qLpKiU1wcGRERUdPCnh0iIhez20VIqCi9XRVBJkASJYh2luUmImoqpL83V7ZH7NkhInK54LZB8DBoUZRX9SKtRbnFMHjrERQR4OLIiIiImhYmO0RELhYY7o8ug9sjP6sQVovN6Vh5STlKCkvR//pe0Jk8qrkCERE1NhJkkCQXbvyYD4DD2IiI3OK2p29Edkou4o5dgFwug0qjQllJOQCg27BOmPDAKDdHSERE1Pgx2SEicgMvfxMeX34/9v92BPs3HEV+VgHCu7RE/+t7oe+47qzCRkREVAeY7BARuYnO5IERtw/CiNsHuTsUIiKqZxIAV5adYYGCChzMR0RERERETRJ7doiIiIiI6pkoCRClqpccqK/2iD07RERERETURLFnh4iIiIionklwbTlolp6uwGeBiIiIiIiaJPbsEFGzkW8txt6sMziYHY1iWzmCtN4Y6NcR3T0joJDJ3R0eERER1TEmO0TULKSU5uC/59YiqSQTCkEOhUyO5NIsHMmNxWC/zrgrfDQTHiIiqjeiVLG5sj1iskNEzYAoifj8/CYklmQgSOMN+T+SmmJbGXZmnkRLnT/GBPR0Y5RERERU1zhnh4iavOjCZMQVpcJXbXRKdABAp9BABgHb04/DJtrdFCERETV1EgAJggs3ApjsEFEzkFicAatog1aurvK4QalFZnk+ciyFLo6MiIiI6hOHsRHRFVktNhzZG4t9284gIyUXeoMWvYe0Q/9h7WHw9HB3eFckCBULq0mS5Pjvf5L+/v5LJvD7HyIioqaEyQ4RXZal3IoV727CkT2xgCRBpVUhJ6MQ56NTEbX1FGY9PxF+gZ7uDvOy2upbQCNXodheBr1CW+l4gbUUrfVB8FEZ3BAdERE1B5IkQJIqf+FWn+0Rh7ER0RVsWXsUh3adg8lHh4CWPvD2M8C/hRf8W3ghMS4T33z4JySpYY8MDtX5o4spDLnlRSi3Wx37JUlCrqUIMggYae5eZa8PERERNV7s2SGialnKrdjzx0moNEpoPZznuygUcnj56hF7OhkXYtIR3jbATVFemSAImBk+GqV2C04XJMIuiZALMthFER4KNW5sEYkBvh3cHSYRETVhIgSIcN2Xaq5sqyFjskNE1cpMzUd+bjH0hspDvwBAq1MjL7sIF+MzG3SyAwCeKh2ebD8Zx/PicTQ3DiW2cgRovdDXpx3CdGZ3h0dERET1gMkOEVVLJpdBEITqh6lJACBAJm8cI2KVMgV6ebdBL+827g6FiIiaGc7ZcY/G8QmFiNzCP9AEcwsvFOSVVHm8qKAUHjo1WncIcnFkRERERFfGZIeIqiVXyDFsQjcAQH5OsVMPT2lJOQryStBjQATMLbzcFSIRERFRtTiMjYgua+DoTsjOKMDWtUeRkpANmUyAJEpQKOXoMaA1ptw31N0hEhERNXji35sr2yMmO0R0BYIg4IbpkegR2RqH98QgOz0fOoMGXfq0QoduIZAr5O4OkYiIiKhKTHaI6IoEQUDLCH+0jPB3dyhUB4qLypCTVQSlSg5zoCfXFyIicgEWKHAPJjtERM1EQV4JNq49gv27z6G02AKZXIbQCD+Mvr47uvcOd3d4REREdY7JDhFRM1BYUIoP3vwdMWdS4KHXwGDSwmazI/pkMhJiM3D7fUMwYBgXViUioqaFyQ4RUTOw/Y+TiD2bCnOQF5TKinlWaijhoVMjM70AP3+7H117hVW7gCwREV0bDmNzD5aepmZPkiQU5xejuKCk+sUziRoxq9WGvdvOQq1ROhKdSwRBgI+vAbnZRTh26IJ7AiQiIqon7NmhZkuSJBzYcBQ7V0ch6WwyIADhXVpi6JQB6DGyCydtu4AkSSgpKIFMLoNWzx6F+lJSXI7iolJotKoqj8sVMkAAcrKLXBwZEVHzIUKACNd9tnBlWw0Zkx1qliRJwpr3f8OmFdtgt4sweOogSRJO7j6LswdiccOssZjwwGh3h9lk2e12RP16CLt+2oeUuHQIgoA2vcIx/LaB6DyI80bqmlqjhEKpgM1qq/K4JEmAKEFbTTJERETUWHEYGzVL0QdjsfnLHdDoNAhqZYbBWw+jjwFBEQFQqhT4/dMtiD+Z6O4w61V+VgFS4tJQmOvab/NFUcSq19bgi/nfI+6vC5DLK96Gjm49iQ8fX4Ft3+1xaTzNgUajQs++rVBUWAZRrDxUsyCvBB56Nbr2CnVDdEREzYMkuX4j9uxQM7Vv/WGUl1rgF+xT6ZinvwkXY1Jx4PcjCO/c0g3R1a+EMxfxx4ptOL7rDGwWG1QaJXqM7ILr7hmBgLD6X0fnr22nsOvHfdB76aD31Dn2m3wNyErOwc9Lf0PHyLYwh/rVeyzNyfDruuD4kQtIvZgDHz8DNFoVRLuI/LwSlJZYMPr67vAP8HR3mERERHWKPTvULCVFp0BdzZAdQRCgVClx8Vyqi6Oqf3HHLmDpw59i768HIQgC9J4eEEUJ27/fi/dnfYLU8+n1HkPU2oOwWe1Oic4lPoFeKMwpxsGNf9V7HM1Ni5Y+eHDudWjVNgAFeaVIScpBWkoeFAo5xk/uhZvviHR3iERERHWOPTvULGn1Gtis9mqP2202aPVqF0ZU/yRJwuq31yEnLQ8tWgdCkFVMXNToNDB665Ecl4Zflm3ArHfuqtc4ks6lQKur+rkVZAJkMgGp8fWfdDVHEW0D8OwrNyPmTAoy0/KhVCvQoUswTFUknkREVLckFxcokFigAACTHWqmug/vjFN7o2G32SFXOJfitVlsAAR0HdrJPcHVk/gTibhwMhE+AZ6OROcSmVwGT18jTu05i4ykLPiH+NZbHBoPNXLT86o9LopStb1udO3kchnadw5G+87B7g6FiIio3nEYGzVLfcf3QHDbQKTGZ6C81OLYX1ZSjrQLGQjrFIKeo7q6McK6l52ai/ISCzR6TZXHtXoNykstyE3Lq9c4eo3uCkupFaJdrHSsvNQCuULGimxERNTkXFpU1JUbMdmhZsrobcBDb89Eq66hyE3PQ3JsGpJjUpGfWYC2vSPw0Nsz4NHEVpLX6jWQK+V/91xVZrXYIFfIoalmiFldibyhN/xDfZF6Ph2WMiuAiiF2pUVlyEjKQpterdBlcPt6jYGIiIiaBw5jo2arRetAPP/NYzi1NxoJp5IAQUCrrqFo37d1paFtTUHbXq3gF+yNnNQ8+Ld0HqYmSRJy0/PQqmsoQtq3qNc4fFv44KG3ZmDl/O+RHJtW0cMjSVBqlOg8sD3ueXUalCplvcZAREREzQOTHWrW5Ao5ug7piK5DOro7lHqn0qhw3T0j8c2rPyHzYja8zJ5Q/N3Tk5WSC7WHGuPuHQmZrP47fMO7hOKF757AyV1ncPFcKmRyGdr0DEebXq1c0j4REZGrSX9vrmyPmOwQNStDbukPu9WG3z7dgozETACAaBeh99Jj1B2D0W2Y64oyqNRK9BzVtcnNjSIiIqKGg8kOUTMiCAJG3D4Y/Sb0xP7fj2L3mv1IOHMRpUVl2PB/f+LIlhMYPWMoBk7qC0HgxEYiIqK6IkoCRBcWDXBlWw0Zkx2iZkiSgH3rD+H88QTovXTQmTwg2uxIiUvDlwt/QFFuMa67Z4S7wyQiIiK6JhwcT9QM7fxxH2KOxCMgzA9e/iao1EpodBoEhPlDqVLg9//bgqzkbHeHSURE1GSw9LR7MNkhamYkScKeXw5ApVFCqa5c9czTbEJRbjGObj1Z42vb7SLOHIjF9h+isPuXg8hOya2LkImIiIhqhcPYiJqZ8lILCnOLoPGoej0dmUwGCEBeZkGNrht/MgmrlvyMxLMpsFlskCQJek8dIif2ws2PjYNKo6qL8ImIiIiuGpMdomZGqVZA46FGYU5RlcclSYIkAjqTx1VfM+1CJj6a9xUyL2bDJ9ALGp0aoiiiMLsIm7/aCUuZFTPm38yiB82cJEmIO3YBGQlZUGqUaNcnAkZvg7vDIiJyCZaedg8mO0TNjFwuR/+JvbDuwz9gt9krLaBakF0ED6MW3YdffRnqHT9GISMpC0GtzJDJK0bHymQymPyMkClkOLDhKIbfFomW9bxgKTVcCWcu4tslP+PCiURYyiyAIMDkZ8TQKZGY+NCYJrmQLxERuR/n7BA1Q0OnDEBQ6wCknE9HcX4JJEmC3WZHTmouivOKMeimvgiKCLiqa9ltdhzadBweeq0j0fknvacOpUVlOLH7bF3fBjUSaRcy8OHjKxB9IAZ6Lx2CWgcgIMwPlpJyrFu+CT+9t97dIRIR1TsJgss3Ys8OUbPkE+iFOUvvwXf/+RnnDp9HbkY+BEGAp78Ro2cOw/UPjr7qa1nKrbCUWaBUV/12IggCBAEoLSq7ppgvxqQh9lgCrBYrtDo1wjsFw7+lL5SqykUWqGHZ9t1upCdkokVEgCMhlivk8A70Ql5mAXau3oehUwbAHOrn5kiJiKipaTTJzsKFC7Fo0SKnfe3atcPZs9V/W7x69Wq89NJLuHDhAtq0aYP//Oc/GD9+fH2HStQoBLYy4/GPHkTi2WSkxWdAqVaiTc9wGLz0NbqOxkMNTz8j0i5kwuBd+bGiXQQgwNvsWas4i/JK8O2bv+LYrrPISctDSUEp7DY7VCoFwjsGYeyMoRg+bSAUykbzdtasWMqtOLTxGHRGjyp7/kw+BqTEpeH4jtMYPWOoGyIkIqKmrFENY+vUqRNSU1Md2+7du6s9d+/evZg2bRruvfdeHD16FJMmTcKkSZNw8mTNy+kSNVWCICC0QzD6je+JniO71DjRuXSNgZP6wma1V8zF+JectDwYffToOapLja9tt9nx+cLV2LfhL+RnFaI4twiQJKhUclitdsSeuIhvXluDrxavht1ur/H1qf6Vl5TDUm6Fqooy5wAgyAQIMgHFBSUujoyIyLVESXD5Ro2oZwcAFAoFAgKubh7B+++/j+uuuw5PPfUUAODll1/G5s2bsWzZMnz00Uf1GSZRszN4cl+c2HUGp6LOQaNTQ2f0gN1mR0F2EVQaJSbNvg6efsYaX/fMwTic3hcLrU6DnJQcKFRKKFQVE9nlKgnlpVYIcjmifj2EXqO7oeuQjtd8LxdTc3Hw6AVkZhfCw0OF7p1C0KFNIORV9ErQlXkYtNCZPJCfkQ+9l67ScdEuQpIkePmb3BAdERE1dY0q2YmJiUFQUBA0Gg0iIyOxZMkStGzZsspzo6KiMHfuXKd9Y8eOxS+//HLZNsrLy1FeXu74uaCgZmuNEDVHWr0GD719Jzat3IF964+gMLcIMrkMbXu3wqjpg9BzZM17dQDg5J5zsFqssJZbINpFp7V6BEGATCagtNQKQSPD/t8OX1OyI0kSfv3jGNZvPoHiknIIggBJkrBl5xl06xSCB+8cAg8t1wqqKblCjoE39sGapb/DarFBqXL+ZycnNRcmXyO6j+jspgiJiFxEEio2V7ZHjSfZ6devH1auXIl27dohNTUVixYtwuDBg3Hy5EkYDJXXaUhLS4PZbHbaZzabkZaWdtl2lixZUmluEBFdmc7ogcmPjsO4e4cjJzUPSrUSfsHe17S2TmlxGWQyGUoLSyH8vdjpPwkyAXabCJVGg7QLmdcU/+4DsVjz+1GolAoEB3o54i4pteDgXxeg81DhgTuGXFMbzdXQ2wbg2I7TiD0aD72nDjqjFjabHfmZBVCoFLjh4etg8q15zx8REdGVNJpxGePGjcOUKVPQtWtXjB07Fr///jvy8vLwww8/1Gk7zz33HPLz8x1bUlJSnV6fqKnT6jRo0ToA/iE+17yIqF8Lb4iSBLlCBkmqvDyaaJeg1iphtdig96w8ROpq2e0ituw8A0mU4O2pc4rbQ6uCyaDFwb8SkJqeX+s2mjOjtwGPLLsXo2cMhVKlQF5mAUoKShHeNRT3vnY7ht02wN0hEhHVO1Fy/UaNqGfn3zw9PdG2bVvExsZWeTwgIADp6elO+9LT068450etVkOtVtdZnERUe71GdsYf3+xGkd0OAYBkFyH8PXfGbhMBAAaTFuVFpeg1umut28nIKsTFtDwYDdoqjxv0GiSn5eHc+XQEmjm3pDZMvkZMf+FmTJw1BtkpuVCqlQiKMEMmazTfuRERUSPUaP+VKSoqQlxcHAIDA6s8HhkZia1btzrt27x5MyIjI10RHhHVgcBwf4y/exhUWjVkSgVKi8thKbPCUmaFzWKDh16FkvwiRHQLRe+x3Wvdjl0UAUmCTHb5nii7Xax1G1TB6G1AeOeWCG4TyESHiIjqXaPp2Zk3bx4mTpyI0NBQpKSkYMGCBZDL5Zg2bRoAYMaMGWjRogWWLFkCAHjssccwdOhQvP3225gwYQK+++47HDp0CJ988ok7b4OIamjsnYPhbTZh8ze7cXz3WZQWlkEQJGg1SpiMGrTv1wZ3zJ8Cj2p6Za6Gn48BnkYP5OaXQKupXISgtMwKlUqBkCAv5/3FZcjPLIBaq4Knv+mah+0REVHTJUGA9O/Jp/XcHjWiZOfixYuYNm0asrOz4efnh0GDBmHfvn3w86tYcTsxMdHpW8IBAwZg1apVePHFF/H888+jTZs2+OWXX9C5Myv+EDUmgiCg79hu6DOmK7JTc5Eck4qc1FzI5HKEdQpGyw7B15xkqFUKDI1si+9/PYTSMotTwmO3i8jOLUKndkFoHe4PACjIKcLmr3Zg37rDKC4ohVwhQ5uerTD6ziHo0K/NNcVCREREdUeQqpr1Sw4FBQUwmUzIz8+H0chqQURNVXm5FR99uROHjicAADRqJaxWOyxWG1q28Maj941AkNkThblFWPbYCpw7dB5agwYeBi1sVhsKs4vgYdTirsW3odeo2s8fIiKimmvIn9cuxfbw9o+g1td+FEJNlReV4sNhDzXI58SVGk3PDhE5Ky0qw7Htp5CTlgetXoMugzvAt4W3u8NqtNRqJR6+axj2HTmP3ftjkZ5ZAJ2vGv17tcKgvq3hZfIAAGz7dg9iDp+HOdQXSrXS8Xi9pw7pCVlY/dY6dIxsC61O465bISIior8x2SFqhA5sOIof31mP7NRcQKpYEFNn8sDgW/pj8qPjoFDyT7s2lEo5Bvdrg8HVDEWzlFux59eD0OjUTokOUDHczjfIC5kXs3Fi5xn0HdfDFSETERHRZfATEVEjc3LPWXyxcDUspRb4h/hAoVRAFCUUZBdi04ptUCjkmPzYeHeH2SQV5hShOK8EGn3VvTYKlQKSBGSn5Lo4MiIiaugkqWJzZXvUiEtPEzVHkiRh85c7UVpYCnOor6MHRyYT4OlnhFanxo7VUcjN4OKX9UGjU0OulMNmsVV5XBQlSJIEjY5rdRERETUETHaIGpHslFzE/nUBJl+DUwUyu11EWYkFWr0WhblFOBN1zo1RNl06owe6DGqPwtxiVFXbpTC7EDqjFp0GtnNDdERE1JBJbtiIyQ5Ro1JeaoHdZnf06NhsdqTGZyD6UBxijpxHzF8XkJOWh9ij8W6OtOkaOX0IPH2NSD2fAUuZBQAg2kXkZeSjuKAEgyb1hX+Ir5ujJCIiIoDJDlGj4mU2QWfUoqSwFDabHRdOXUR6YhbsNjvkSjkgSbCUWrH9p/2IWn/Y3eE2SeGdQ/DAf+5Ai9Zm5KTmITUuHWnxGZDJZbju7uGY/PgEd4dIREQN0KVFRV25EZMdokbFw6BF3/E9UFJYiozELBTlFUOtVUGlVkImE2C3i9B76aBUK7Bm6QYU5RW7O+QmqUP/Nnjp+7mYs/RuTHvuJtz98lTM/2EupsydCKWKdV+IiKjxe/311yEIAh5//HHHvrKyMsyePRs+Pj7Q6/W4+eabkZ6e7vS4xMRETJgwAR4eHvD398dTTz0Fm63qua6uwH+ViRqZ6+4ejpjD57Hv96OQRAmiXYTdKsFmtUGpUSK4bSC0Bi3SE7JwbMdpDLyxj7tDbpKUKgW6De3k7jCIiIjq3MGDB/Hxxx+ja1fnRbKfeOIJ/Pbbb1i9ejVMJhPmzJmDyZMnY8+ePQAAu92OCRMmICAgAHv37kVqaipmzJgBpVKJ1157zR23wp4dosbG5GvE3a9Og8nPCKVaAVEUAQHwCfJGq65h0HvpIVfIAQA5aXnuDdZFMpKysGvNfmz/fg+iD8ZWPCdEREQNiSRAcuEGqXbD2IqKijB9+nR8+umn8PLycuzPz8/HZ599hnfeeQcjRoxAr169sGLFCuzduxf79u0DAPzxxx84ffo0vv76a3Tv3h3jxo3Dyy+/jA8++AAWi6VOnsaaYs8OUSPk18Ib5lA/WMwm6D31kMtlFXN2/iZJf5dA9mjaJZBLi8uw+q1fcWDDUZQUlAAQoFQpENY5BHe8dAtC2rVwd4hERERuVVBQ4PSzWq2GWl3954PZs2djwoQJGDVqFF555RXH/sOHD8NqtWLUqFGOfe3bt0fLli0RFRWF/v37IyoqCl26dIHZbHacM3bsWMyaNQunTp1Cjx6uX3CbPTtEjZBKo0LPkV1QUlgGpUrhlOgAFYtfehi06DywvZsirH+SJOGrRT9g23d7IJPJENQqAC1aB8Dgrce5w3FY/sRKZCVnuztMIiIiAP9bVNSVGwCEhITAZDI5tiVLllQb43fffYcjR45UeU5aWhpUKhU8PT2d9pvNZqSlpTnO+Weic+n4pWPuwJ4dokZq2K2ROLbjNFLj0+ET5A21VgVRFFGQXYSSglKMmDYQga383R1mvYk7dgFHtpyAl78JOpOHY79Wr0FQqwCkxKVh988HMGnOODdGSdUpyC7E4c3HkRqfAYVSjna9I9BpYDtHWXUiIqobSUlJMBqNjp+r69VJSkrCY489hs2bN0Oj0bgqvHrHf1WIGqngNoF44D/T8e1/1iI5Jg2i3Q5JAvSeHhgzYwgmzbnO3SHWqxM7z6C8xALfFt6VjsnkMqjUSmz4v61IPH0RxQUlCGxlRr8JvdC+b2unBVnJ9Y5sPYFVr65BTlqeY3HWzV/uRESPMNz/+nT4BHpd4QpERHS1jEajU7JTncOHDyMjIwM9e/Z07LPb7di5cyeWLVuGTZs2wWKxIC8vz6l3Jz09HQEBAQCAgIAAHDhwwOm6l6q1XTrH1ZjsUK1YLTZkJedAEAT4BXs7JsSTa7XpEY4Xvn4EZw/EIiMpGyqNEu37tm4WHxZLi8oAAVUmLpZSCzKTc1BeaoHVaoNSqcC5w+exb/1hDJs6ELfOuwEyGUfxukP8yUSsnP89SgvLEBDuD7m84vdQXmrB2f2x+L9nv8G8z2bxPYWImhzp782V7dXEyJEjceLECad9d999N9q3b49nnnkGISEhUCqV2Lp1K26++WYAQHR0NBITExEZGQkAiIyMxKuvvoqMjAz4+1eMLtm8eTOMRiM6dux4zfdUG0x2qEZsVhu2fbcXO9fsR3ZKLgAgINQPQ6dEYvDNffkB0g3kCjk6DWiH5lYE2TvAE5AkiKIEmex/CY8kSUiKTkFpURkM3jq0iPjfN0kFOUXY+tVOBLUyY8gtkW6Imnat2Y/CnCK0aB3glKiqtSr4BXsj9q8LOB11Dl0Gd3BjlEREzY/BYEDnzp2d9ul0Ovj4+Dj233vvvZg7dy68vb1hNBrxyCOPIDIyEv379wcAjBkzBh07dsSdd96JN954A2lpaXjxxRcxe/bsyxZFqE/8ZEpXzW4X8fUra/D9m+uQkZgFD4MWWr0GF2NS8fWra7D6nd8cQ1KI6luvMd1g8NYj91/ltUsKSlGYVwyZQgafIOchbkZvPSQAO1dHwW63uy5YAlCRiB7bdgoeBm2VPXIaDzVsVjuiD8W5IToiIhe4VBLaFVs9ePfdd3H99dfj5ptvxpAhQxAQEIA1a9Y4jsvlcqxfvx5yuRyRkZG44447MGPGDCxevLhe4rka7Nmhq3Zy91nsXXcYRh+904RwD4MWBTlF2PFDFHqO7Iw2PcLdGCU1F37BPpj40Fj89O56pMSlweRrhEwuQ3piJmzlNngFmOBl9qz0OKO3HqnxGchNz4dvUOX5PlR/RLsIu12ETH6Z79kkCTYrE1EiooZg+/btTj9rNBp88MEH+OCDD6p9TGhoKH7//fd6juzqsWeHrtr+34/CbrU5JTqXGLx0KCsux6FNx9wQGTVXo+4cgnuX3I7WPVuhrKQcxfkl0Oq1MHjrENox2DEfpCosUuB6coUcoR2CUVJYWuVxu80OQSYgqJW5yuNEREQ1xZ4dumppCZlQaVRVHhMEAQqVHGkJmS6OipozQRDQ57oe6D22OzKTsmCz2pGfWYD3H/4UljJrlWWMC3KKENYpGF5m0zW3X1JYivSETMjkMgRFBECp4lvqlQy6qS9O7zuHwtxiGLx0jv2SJCEjKRs+Qd7oNbqrGyMkIqofoiRArKfhZdW1R0x2qAYMnjokWWzVHrdZ7U4fXohcRRAE+Lf0AwAEtjKjTc9WOLn7DJRqpSMBkSQJhTlFAIChtw68pmIapcVl2PDZn9i79hAKc4oqqhKGeGP41EEYdlskC3VcRq8xXTH86EBs/27P34vfamC3iyjKL4HOoMWE+0fCw6h1d5hERNRE8F9kumo9R3aBKEqwVpHwlJdaIJPL0G1oc6sJRg2NIAiYufg2RHQPR0ZiFpJj0yr+PyYV5aUWjL1rGAZO6lPr61vKLPjkqa+xbvlmlBSUwORrgMFLh/SELKxasgZr3vudhTouQyaTYeozN+L+N+5A1yEdIAEoyCqErdyKspIyrH5zLd576GOc2R/j7lCJiOqW5IaN2LNDV6/32K7Y/fMBxB67AG+zJ7SGitV1i/NLkJdZgI6RbdFt6NWViy3KK0bs0XjYbXYEtjIjKMI9C01R0+Qb5I0n/+8hHNlyAn/9efLvRUX90XdcT7TtHXFN83UObjyG4ztPw7eFFzQe/yujqdGpkZ9VgD+/3YM+47ojtENwXdxKkySTydBnbHeEtAvC+w9/isKcQnj7ekKrU8NSbsXxnWcQfyIR971+B7oOcc+6DERE1DQw2aGrpjN64KG37sRXL/+Ec4fPIy+zAEDFh7w+Y7ph+gs3VTun5xKb1YbfPt2CnT9EIS8zH6JdgodBg44D2uHWp26EX7CPK26FmgGtXouBk/pi4KS+dXrdqHWHAMAp0bnE6GNAcmwajmw5wWTnKvz+6RakxqUjuE2go0KbSquCzuSB1PPpWP32r+jQvw2UKqWbIyUiunYSBEhw3TwaV7bVkDHZoRrxCfLCYx/eiwunLiLxTDIAoFXXlghuG3jFb8slScL3b6zFn9/sgkanhjnUDzKZDMX5JTi46S9kJmXhiU8egsnX6IpbIaqVzKTsKhMdoGIInUwmOBbcperlZebjr20nYfTRVypFLQgCfIO8kRafgegDseg8iAuMEhFR7TDZoRoTBAHhnUMQ3jmkRo9LPJuMPT8fgN5LB6OPwbFf76WDRq9BwumL2L1mPyY8MLquQyaqMwYfPXLT86o9LooS9J6Vy7OTs/zMApSXWqr9ckOlVcFuE5Gbnu/iyIiIqClhskMuc2zbKZQWlcE7sPL8HJlcBrtNxLev/4xDm0/A5GtE77Hd0Gt0F2h1GjdES1S1fuN64PyxBNistkqlrUsKS6HSKNFtGAt1XInWoIVCqYC13Aq1tvLwV5vVDkEAK7MRUZMhSRWbK9sjVmMjFyrOLwGEyos5inYRiWeTkZ2ai9yMfKTGZ+DknmismP89ls75HPlZBW6KmKiy/hN7IaxzCNIuZKIovwSSJEEUReRnFSAnLQ/dR3RGuz4R7g6zwfML9kHbXq2Ql5FfZfW63PQ8eAd6oUP/tm6IjoiImgomO+QyRh89IEmVPthkJGUhLyMfMpkAndEDfsE+CGzlD98gb5w9EIsf3lrvpogbF0u5FX9tP43Nq3Zjx0/7kZmc4+6QmiSDlx4Pv3sXeozsgsKcIsQdT0D8ySTY7RJG3jEYdy2+jevsXAVBEHDdvSNh9DEg9Xw6ykstAACbxYbMi9kQ7SKuu3sEPAzs2SEiai5KS0tRUlLi+DkhIQHvvfce/vjjj1pfk8PYyGV6juqKDZ9tRX5mATz9K1avt9vsyEnLh0yQQYQI7wAvx/kqjRImHwOO7TyNtAuZCAjzc1foDd7p/bH47s1fkZaQBdEuAqgY/jNgYi9MnjMWKnXV1awy0/KRkpgNuVyG8LYB0Bk4ZPBq2Kx2iKIEQSbD392VkCsVMPoYq32uqbJ2vSNw/xt3YvVbvyIlLg12qx2CTIB3oBfG3TMCw6cNcneIRETkQjfeeCMmT56Mhx56CHl5eejXrx+USiWysrLwzjvvYNasWTW+JpMdcpnAVmaMunMo1n+8GZbELJj8jCgrKUd5STmAim/MvQK9nB6j99Qh5Xw6Es8mM9mpxoVTF/F/L36Hwtxi+AR5QaVWQhQlFOYUYcs3uyGJIqY9dYPTY/JyirHmi104djAeJUXlEGQCTF4eGDS6M8ZP6QOlkm8N1clOzcWHT3yBpHMp8PI3wRzmB9EuIj+zEGs/3ITSwlLc9q/nm6rXeWB7dOjXBmcPxCI3PQ8eRg906NcaWj17dIiImpsjR47g3XffBQD8+OOPMJvNOHr0KH766SfMnz+/VslOjcZalJaWYvfu3Th9+nSlY2VlZfjyyy9rHAA1Lzc8PBa3P3cT/IJ9kJ9ZgPzMAkAAvAK8ENqlZaUJ39Lfy/9eyyKQTd2fP0QhL7MQAWF+jl4FmUyAydcAnacH9q4/grSETMf5xUVl+Oj19diz9TRkMgEBwZ7wCzCirNSCdd/uw7efbK9yDgVV2PXTfiSdS0FguD90Jg8IggC5Qg7vQE/ojB7YteYAUuLS3R1moyJXyNFpQDsMuqkfeo7swkSHiJokSRJcvjU2JSUlMBgqKvb+8ccfmDx5MmQyGfr374+EhIRaXfOqk51z586hQ4cOGDJkCLp06YKhQ4ciNTXVcTw/Px933313rYKg5kMmk2HE7YMx/6d5ePqLOZj3+cNo368ddF76KhcOLMwpht5Th1ZdWroh2oavpLAUx3efhcFLV2VCaPTSo6SgFKeizjn27d9+FrFnU2AO8oTR0wMymQwKhRzevgaYvDywf/tZxJ9Lc+VtNBqiKGLfb0eh0akhV8grHTf66FFSWIpjOyp/IeSK2M4eiMGP76zD1y//iA2fbUXmxWyXx0FERFRbrVu3xi+//IKkpCRs2rQJY8aMAQBkZGTAaKzdOoxXnew888wz6Ny5MzIyMhAdHQ2DwYCBAwciMTGxVg1T86ZSKxHRLQxdBnXAyOmDYCu3oiiv2OmcsuJyFOUWo/eYrvAJ8qrmSs2bpdQKu9UOhbLyB28AEGQVi1yWl1gc+/bvOAuFXAalqvJQNZ1Bg7JSC47ui6u3mBsza7kNpcVlUGkql0oGKnogBQGVXsv1raSwFMufWIl3H/gYv32yGVtX7cQPb/2Kl299G1u/2cWeOiIiahTmz5+PefPmISwsDP369UNkZCSAil6eHj161OqaVz0wf+/evdiyZQt8fX3h6+uLdevW4eGHH8bgwYOxbds26HS6WgVANPqOwchMysbeXw8hP6sQCqUcNqsdcoUc3Ud0wi1PTHB3iA2WztMDBi8d8jILoDNVXsjSZrVBQsWE70vycoqrnUQvCBXJUUFeSZXHmzuVRgmDlw5ZyTmAt77ScVGsGHhZ3UKZ9eXb19bg0KZj8A7whIfR1xFLTlouVr/9Kzz9jeg1uptLYyIiIqqpW265BYMGDUJqaiq6dfvfv1sjR47E5MmTa3XNq+7ZKS0thULxv9xIEAQsX74cEydOxNChQ3Hu3LnLPJqoegqlAne8OBmPL78PI6YOQMf+bTHopr6Y/d5MPPzODJaevQylSoHI63uivNQCS7nV6ZgkSchKyYVvoBe6D+ng2O/lq0f5v87952NEUYKnN7+8qIogCBh4Yx9YyqywWmyVjudl5kNv0qHnyM4uiyk5NhVHtp6AydfgtACnTCbAN8gb1nIr/vx2N3t3iIjcjHN2ruyee+6BTqdDjx49nJZx6NSpE/7zn//U6ppX3bPTvn17HDp0CB06dHDav2zZMgDADTew+hDVnkwmQ/s+rdG+T2t3h9LojLg1EmcPxOHsoThoPNTQGrSwW20oyCmCzuSBKXPHQ6NTO87vP6wD4s6kwFJug0r9v7cAa2k58rMKoZQL6NGfv4fqDLqpD47+eRIxR+Oh99RBZ/KA3WZHfmYhIAATZo+Ebwtvl8Vz7tB5lBaWwqt1QJXHjT4GXDiVhJy0PPgEcjgoERE1XF988QVef/11R5GCS0pLS/Hll1/i888/r/E1r7pn56abbsK3335b5bFly5Zh2rRp/OaQyA10Jg88/NYduOHBUTB461BWXAa7XUTPEZ3x8Ft3oNcI516GfkPboW3nYGSk5iEvpxiFWfmI230SJ36JQvyO4yg4EYfN//cHkqKT3XRHV89qsaK4oAR2u91lbRq89Jj93kyMnDYQcrkMOWl5KMwpQmC4H+54YTLG3TPcZbEAFUMVIQjVViyUyWWQ7BLsNtc9R0RERDVRUFCA/Px8SJKEwsJCFBQUOLbc3Fz8/vvv8Pf3r9W1BYkZymUVFBTAZDIhPz+/1lUgiFylvNSC/OxCqNRKePpV/3otzC/B2lVR2LPhGC7uOw17aTlUHhp4m43Q69QoyCmCX4gP5iy9B6EdQ1x4B1cn7UIGtn+/Bwc3/gVruRUGbwMGTuqLoVP6Q2dy3RC8vMwCZCRlQalUIKR9UKXS6a5wam803p/1CUx+Rmg81JWOZyRlwTfIGwt/fqrKiodERE1BQ/68dim2GRs+h0pXeX5tfbEUl+DLcfc0yOfk32Qy2WWXGREEAYsWLcILL7xQ42tz5UCiJkStVcE/2OeK5xlMHpj+0Ahc3HcGBToVfNsHQWfQQC6v6Ow1+OiREpuGNe//hsc/erBBrXMUfzIRy59YicykLHgYPaBUKZCVnI0f3/4VJ3adxsPv3Q2DV+XiAfXB08942aTSFdr3bY2WHYIRd+wCglqZIZP/r8O+tKgM1nIrBk3ux0SHiIgarG3btkGSJIwYMQI//fQTvL3/NxxcpVIhNDQUQUFBtbo2kx2iZio5JhWJp5JgbulbqZKbTCaDl9kTMYfjkRyTiuC2tXuDqWuiKGLVqz8h82IWgloHOCYvGrz1sJRbcWZ/DDau2IYpcye6OVLXkSvkuHPBFHw0dyVS4tKg8VBDoVKgtKgMkgT0Gt0NI6cPdneYRERE1Ro6dCgAID4+HiEhIU7FCa4Vkx2iZionLQ/lpeXwMpuqPK7Va5CfVYCctLwGk+zEHD6PxDPJ8A3yrvRGqFIroTNosW/dIUy4f1SzquIX2iEYT/7fLOz++QAO/H4EpUVlaNOrFQbc2Bf9JvSsttQ4ERFRQxIaGoq8vDwcOHAAGRkZEEXR6fiMGTNqfE0mO0TNlEanhlypgKXcWuVcD2u5FXKlwqmSm7ulJ2TCarFBo9NUedzD5IHCnCJkp+TAo10LF0fnXr4tfDBpzjhMmjMOkiQ1qKGHREREV2PdunWYPn06ioqKYDQanf4tEwShVslOjfuIdu7cCZut8voSNpsNO3furHEAROQerbqGIjDcH7np+VUez0nPR2C4P1p1DXVxZNVT/t1DIdrFKo/bbXbI5DLHec0VEx0iogZIEly/NTJPPvkk7rnnHhQVFSEvLw+5ubmOLScnp1bXrHGyM3z48Coby8/Px/Dhri25SkS1p1AqMP7+UVCqFEhPyITt70UybRYb0hMyoVRVHHdHhbHqtO/bGgYvHfKzCqs8npdZgJYdgmEO9av2GgU5Rdi+eh++e3MdVr/7G47vOltRvpmIiIjcKjk5GY8++ig8POqual2NP8VUNzwiOzsbOh1XXSdqTPqO6wFruRXrlm9CRlIWJAkQBMC3hTcmzhqLfuN7ujtEJ15mTwy8qR82frYVcoUMBm89BEGAaBeRnZoLtUaF0XcOqbZn468dp7Hq9bXITssD/q66v2XVHkR0C8W9L98Gn0BP190MERE1K5Lk+KfHZe01NmPHjsWhQ4fQqlWrOrvmVSc7kydPBlAxPOKuu+6CWv2/cfx2ux3Hjx/HgAED6iwwIqp/giBg0E390GtMN5zeG43CnCIYvPXoOKAdtNXMi7lWkiQh7q8LiD0aD9EuokXbQHQa0O6qe5BuenQcrOVW7F17EMmxaRWJjSTB6GvETY+MQ6/R3ap8XMKZZKxc9CNKCkoREOoLuUIOoGJtorMH4/DZS9/jyY/uc+xvbooLSlCQVQgPoxYm34a9HgMRETVNEyZMwFNPPYXTp0+jS5cuUCqdh6XfcMMNNb7mVSc7JlNFxSZJkmAwGKDV/q/SkUqlQv/+/XH//ffXOAAicj+tTlNtklCXcjPysfKlbxF9MA6WUgsgCJArZAhpF4SZi6citEPwFa+hVCkx/YWbMey2ATix8wxKCkvhHeCJHiO7XPZD+q5fDqAwpwhBEWannh+1VgW/Fl6IO5aA0/ti0GVQ+zq518YiOzUXm1Zuw8ENR1FWUg6FUoFOA9phzMxhDWq+FhFRoyf9vbmyvUbmUi6xePHiSscEQYDdbq/xNa862VmxYgUAICwsDPPmzeOQNSKqEavFiv975muc3hsN70Av+LbwhiAIKC+1IP5kEj5+8gvM+/xheAd4XdX1WrQORIvWgVd1riRJOLbjDLR6TZVD3NQeatisuYg+HN+skp2s5Gwsnf1/SDyTDL2nB3RGD1jLrdj322FEH4zFg2/NQPu+bdwdJhERNRP/LjVdF2pcoGDBggVMdIioxk7sOovog7Hwa+kLD6PWkXSotSoEtTIj9XwGon49VC9ti6IEu02ETH6ZtzwBsDezQgW/fboFiWeSERRhhpfZE1q9BkYfA4LbBKIguxDfv7EWdlvNv0UjIiK6VmVlZXVynRonO+np6bjzzjsRFBQEhUIBuVzutBERVeXkrjOw20WotapKx2RyGVQaJQ79caxe2pbLZWjZPgilRVW/cdptdggQEBDuXy/tN0QF2YU4svk4DN76SvOUBEGAT6AXkmNSEX0ozk0REhE1LRIEl2+Njd1ux8svv4wWLVpAr9fj/PnzAICXXnoJn332Wa2uWeNqbHfddRcSExPx0ksvITAwkOs5ENFVKSspg0xW/fuFQilHWXF5vbU/cGIvnDkQi6K8Yug9/9c7LUkSMi/mwDvAEz1HdK639huanLQ8lJWUVzvPqWJonx05qbkujoyIiJqrV199FV988QXeeOMNp1oAnTt3xnvvvYd77723xtescbKze/du7Nq1C927d69xY0TUfAWEmSHaxWrL15cWl6Nj5NXNwamNXqO7IOavC9jx034U5BTDw6CBaBdRUlQGk48Bdzx/EwxezWeIrkanhkIhh81iq7K3raK3qyLpISKiOsACBVf05Zdf4pNPPsHIkSPx0EMPOfZ369YNZ8+erdU1azyMLSQkBFJjLNxNRG7V57ru0HvqkJOaV+lYUV4xFEo5Im/oXW/ty2QyTH1qIu57ZSq6DGwLhVIBD4MWo6YNxBMf3IOug5tPYQIAMIf6IbxrKPIy86t8T8/NyIen2YSO/VmggIiIXCM5ORmtW7eutF8URVit1lpds8Y9O++99x6effZZfPzxxwgLC6tVo0TU/AS2MuOG2dfhp3fXIyU2DXpvPWQyAYW5xQCAIbf0R7fhneo1BplMhj5juqLPmK4QRRGCIDSbobhFecU4/McxJEYnQyaToXWPcIy4fTAunExC2oVM+LbwhlKlgN1mR15GAazlNoyaNQQ6U/Pp7SIiIvfq2LEjdu3ahdBQ56UPfvzxR/To0aNW16xxsnPbbbehpKQEERER8PDwqLTYT05OTq0CIaKmb9QdQ+AX7INt3+3G+eOJsFslhHUMxpApkRg4qa9Li5zIZDXu2G60TkdFY+X875F1MRuiVDFl9c9VuxHSLhATZ43B9u/3ICMxG4AESIDR14DrHxyNsXcPd3foRERNB4exXdH8+fMxc+ZMJCcnQxRFrFmzBtHR0fjyyy+xfv36Wl2zVj07RES1IQgCug/vjG7DOqEorxiiXYTBW9+sEg9XS0/IxGfPr0JeZgECwv0dldesFhsSTl+EKEp4+otHEH88Abnp+dAaNOg8qD2M3gY3R05ERM3NjTfeiHXr1mHx4sXQ6XSYP38+evbsiXXr1mH06NG1umaNk52ZM2fWqiEiqj1JkpAYnYpzRy/AZrUjKNwPHfu1hlJV4z/hBkEQBBi89O4Oo15dmgfj7mFye389iJzUPLRoHQDhH9XwlCoFAsL8kRyTitN7ozFwUl83RklERFRh8ODB2Lx5c51dr1aflOLi4rBixQrExcXh/fffh7+/PzZs2ICWLVuiU6f6HXNP1NwU5Zfg6/+sw8mocygrsUAQBMhkAoJa+ePOZ29Aq84h7g6R/ma32XFobyz2bjuDi/FZUKkV6NE/AoNGdUJQiLdbYjq2/RTUWpVTonOJQqWAJEo4s+8ckx0iImpQioqKIIqi0z6jserlEi6nxmNHduzYgS5dumD//v1Ys2YNioqKAADHjh3DggULahwAEVVPFEWsfOVnHNx8AhqtCkHhfggK94O32YSkmDR88uIPSE/KdneYhIpE55tPtuPz9zfjzF9JsNnsKCwoxaZfjuDdhT/j7Ikk98RltUOQV9+7JMgEWC02F0ZERNRcCW7YGpf4+HhMmDABOp0OJpMJXl5e8PLygqenJ7y8vGp1zRr37Dz77LN45ZVXMHfuXBgM/xvTPWLECCxbtqxWQRBR1c4duYBT+2LhE2CCVq9x7FdplAgM80XK+UzsWX8Ek2fVbhxrY5Gdmoui3CLovfTwCazdm11927czGnu2noHBpIHuH78rSZKQlpyHr5Zvw0tvT4WmijVt6lOrrqG4GJNa5TFRFCHaRYR2ZO8gERG53x133AFJkvD555/DbDbXyVDwGic7J06cwKpVqyrt9/f3R1ZW1jUHRET/c2p/LCzlVqdE5xKZTAatTo1DW0422WQn4cxF/P7pFpzeGw1LuRUqtRIdB7TD+PtHIbRDsLvDc5AkCbs3n4IkSU6JDlAxZ8fPbERGSh5+/GQb8hIykJaQCb3JA71Gdkb/cd1h8K6/+UuRN/TGgQ1HkZueDy+zySnmzKRsmPyM6Duue721T0REdLWOHTuGw4cPo127dnV2zRoPY/P09ERqauVvCY8ePYoWLVrUSVBEVMFSdvkFtORKOcpLLE1yod/4k4n47+xPsf+3I5Ap5DD5GiFTyLH/tyP47+xPEX8iwd0hOpSXWZGWnAudQV3lcZlchtysAvz25S4c23UGeZkFuHD6Ir5/93e8M/tzpCfW3xdF7fq0xvUPjobNakNybCpy0vKQnZqL5JhUqD3UmPbcZPi28Km39omI6G+SG7ZGpk+fPkhKqtth3zXu2Zk6dSqeeeYZrF69GoIgQBRF7NmzB/PmzcOMGTPqNDiihqa0uAxHt5zAX9tPoqSgFIGtzOg3viciuofVS9Ut3yAvCKgYblRVeebSojK07VE/bbuTJElY895vyE7JRXCbQMfkerVWBYOnDsmxqVjz/m+Y++msBnHvMlnF4qR2u1jl8czkHJQVlcNoUiPI/L/hvzabHYnRqfh6yVrM/fCeerkXQRAqesI6hWDPLwcQc/g8ZHIZIif2xqDJ/RDeuWWdt0lERFQb//d//4eHHnoIycnJ6Ny5c6X1PLt27Vrja9Y42Xnttdcwe/ZshISEwG63o2PHjrDb7bj99tvx4osv1jgAosYiOzUXH81difPHK3oU5Ao5Tu05i91r9mPkHYNx8+PX1/mH1Z7DO2LDFzuRnZYPvyDnuSqlRWWAAESO716nbTYEF8+lIO6veHgFeFaqIibIBHgFeCL2rwtIik5By/bu71FWqZXo1KMlorZFw+Tl4fQ6EEUJWal5kAkCvExap8cpFHJ4B5gQdzwR508kIaJr/SQegiCg88D26Dywfb1cn4iIrgIXFb2izMxMxMXF4e6773bsEwQBkiT9/aWivcbXrPEwNpVKhU8//RRxcXFYv349vv76a5w9exZfffVVva5+vmTJEvTp0wcGgwH+/v6YNGkSoqOjL/uYlStXQhAEp02jqTz3gehKJEnCype+Q8zRePgF+yAoIgDmUD+0aBMIpVqJTSu2I+rXQ3Xerk+AJ26aNRoymQzJ5zNQmFuM4oISZCRlIzezAL1HdkbfMTX/lqOhy03PR3mpBVpd1X+vWp0GllILctPzXBvYZQwZ0wUeBjUy0/KdSmUW5pegvNwOvVYOnbrye6RWp4a13Iqkc1UXESAiImou7rnnHvTo0QNRUVE4f/484uPjnf6/Nmq9ImHLli3RsqXrhj/s2LEDs2fPRp8+fWCz2fD8889jzJgxOH36NHQ6XbWPMxqNTklRQxjyQo1P3F8XEHPkPHwCvaBU/69LVRAEmHwNKCkowfYf9qD/xF5VDje7FoNv7AUvfwP+XH0A508kwmaVEBDmh4ETe2LoTX0a7cKil+Nh0EKhVMBSboXGo/I8GEu5FQqlAh4GbRWPdo82HYNwx4PD8cOKXUi9mAdIEiRUFP7UKACzXnnZ9x+ZvG5fN0RERI1NQkICfv31V7Ru3brOrlnjT0l2ux0rV67E1q1bkZGRUWmxnz///LPOgvunjRs3Ov28cuVK+Pv74/DhwxgyZEi1jxMEAQEBAfUSEzUf8ScSYSmzwLdF1QtDGrz1SI5NQ15GPrwD6r40cufItujUvw2K8kpgt9lh8NJBrqi/nlR3C+/SEkERZiRFpyCwlbnS8dy0PAS3DUKrrqFuiK56fQe3RdtOLXAkKhbpKXlQKOVo3yUYa9//DUnRqTB6elR6THF+CTQ6NVrX0xA2IiJqKFy99k3j+4J/xIgROHbsmHuTncceewwrV67EhAkT0LlzZ7f1lOTn5wMAvL0vvyp5UVERQkNDIYoievbsiddeew2dOnWq9vzy8nKUl5c7fi4oKKibgKlRu1K1s0t/B/VZFE0QBBi8qu/FbErkCjnG3z8KK178DmkXMuET6AmlWgmrxYbslFyoNEpMeGBUg0z4PL11GDGhm9O+gin98dWrPyMvqxAmH73j9VJWUo68rCL0H9cNQRGVkzoiIqLmZOLEiXjiiSdw4sQJdOnSpVKBghtuuKHG16xxsvPdd9/hhx9+wPjx42vcWF0RRRGPP/44Bg4ciM6dO1d7Xrt27fD555+ja9euyM/Px1tvvYUBAwbg1KlTCA6ueo2OJUuWYNGiRfUVOjVSoZ1CoFQrUVZcXuWaNwU5RQjrFAxPf6Mbomua+lzXAzarHb9+uBGZSdkQRQkymQC/EB/c8PB16HNdD3eHeNUGXN8T2am52PzNHiTHpUMul0MURcgVcnQd1A5T5010d4hERFTPJKl+vxStqr3G5qGHHgIALF68uNKx2hYoqHGyo1Kp6rRrqTZmz56NkydPYvfu3Zc9LzIyEpGRkY6fBwwYgA4dOuDjjz/Gyy+/XOVjnnvuOcydO9fxc0FBAUJCuLp4c9emZzgiuoXhzL5zCAjzh+If82QKc4ogABg6ZUC9FulojiIn9kav0V1xOuocCnOKYPDWo2NkW6g0KneHViOCIGDi/SPRfWhHHNpyAlnJufAwaNB1cHt07NcaCqVr5l1JkoTzJy/i0NZTyEzJhd6kRbfB7dG5f+smOfeLiIgal39Pj6kLNf7X7cknn8T777+PZcuWuWUI25w5c7B+/Xrs3Lmz2t6Z6iiVSvTo0QOxsbHVnqNWq6FWV70wIDVfMpkMd708FcufWImEU0mQyWVQKBUoL7NArVFh5B2DMWBSH3eH2SSpNCp0H159D25jIQgCWrYLQst2QW5p324XsebDzdjxyyGUFVsgV8og2kREbTiGjn0jcM/8m2DwbB7DJImI3IKlp92ixsnO7t27sW3bNmzYsAGdOnWqNJZuzZo1dRbcP0mShEceeQQ///wztm/fjvDw8Bpfw26348SJE24dgkeNl3+IL+Z9NguHNh3DkT9PoKSgFEERFYuKdujflpX+qEHb9ethbP1hH7R6LbzNJsfrtbzUghN7z+H79zbivoU3uzlKIiJq7g4ePIht27ZVWQjtnXfeqfH1apzseHp64qabbqpxQ9dq9uzZWLVqFdauXQuDwYC0tDQAgMlkglZbUX52xowZaNGiBZYsWQKgYrxf//790bp1a+Tl5eHNN99EQkIC7rvvPpfHT02DzqTD0FsHYOitA9wdCtFVs1nt2PnzIQiCAKO3c++NWquC0UePE3vOIfVCJgLD/NwUJRERNXevvfYaXnzxRbRr1w5ms9npi+Tafqlc42RnxYoVtWroWi1fvhwAMGzYMKf9K1aswF133QUASExMdFrjJDc3F/fffz/S0tLg5eWFXr16Ye/evejYsaOrwqYGzG6z43TUOZyOOgdruRXmUD/0HtsNXmZPd4dGVKcyLuYgIzkHBu+qh6npTR5Ijc/E+VMXmewQEdUXSajYXNleI/P+++/j888/d3y2rwu1npGamZnpWKyzXbt28POr338gr1T6FwC2b9/u9PO7776Ld999t54iosYsLzMf//fsN4g+GAubxfZ3KXoBv326Bbc+dQMG3MD5N9R0SKIISIBwhTUXRHvdTwwlIiK6WjKZDAMHDqzba9b0AcXFxbjnnnsQGBiIIUOGYMiQIQgKCsK9996LkpKSOg2OqD5IkoQVL36Lk7vPwtPPhOC2QQhuE4SgVmaUFpbim1d/QvTB6otYEDU2fi284eVvRFF+1e/RJYVl0Hio0LJdoIsjIyJqPgQ3bI3NE088gQ8++KBOr1njZGfu3LnYsWMH1q1bh7y8POTl5WHt2rXYsWMHnnzyyToNjqg+xBw5j7MHYuEb5AWN7n+V92RyGfxCfFBSUIrtP+x1Y4REdUulUWLQxJ6wlttQUljmdMxmtSEvowBte4ShZVsmO0RE5D7z5s1DdHQ0IiIiMHHiREyePNlpq40aD2P76aef8OOPPzrNnRk/fjy0Wi1uvfVWx9waooYq+kAsLGVWaKpYHFQQBBg8dTgdFY3y0nKotSxDTk3DiCn9cDE2HQe3nkR+ViFUGiWsFhtEu4hWXUJw+7wJrChIRERu9eijj2Lbtm0YPnw4fHx86uTfpRonOyUlJTCbzZX2+/v7cxgbNQp2mwhBEKr9A5LJZRBFEXYb5y9Q06FUKXDXCzei57AOOPDHCaQnZUPv6YFewzuh96hO0Bm07g6RiKhp4zo7V/TFF1/gp59+woQJE+rsmjVOdiIjI7FgwQJ8+eWX0GgqvhkvLS3FokWLEBkZWWeBEdWXoNYBEAQBVoutylXji/KL0apLKLRV9PwQNWZyhRw9hnZAj6EdrvladpsdMrmMvUFERFRnvL29ERERUafXrHGy8/7772Ps2LEIDg5Gt27dAADHjh2DRqPBpk2b6jQ4ovrQbVhHmMP8kH4hA4HhZgiy/31YK84vASBg8M39+SGO6F9EUcTh7Wewd8NxJMakQSaXoWtkawy+vgfC2ge5OzwiooavEfa2uNLChQuxYMECrFixAh4eHnVyzRonO507d0ZMTAy++eYbnD17FgAwbdo0TJ8+3bG4J1FDptaqMXPhrfj0ma+RHJsKjU4DhVKO0qJSCIIMAyf1wYAbWXqa6J9EUcQPyzZjx9rDEO0StHoNrOU27Pj1CI7sPIsZ8yagx5D27g6TiIgasaVLlyIuLg5msxlhYWFQKpVOx48cOVLja9ZqnR0PDw/cf//9tXkoUYPQrk9rPPnZLOz++QAO/3EM5aUWdOwaioGT+qL3mG6QK+TuDpFqoazEguN7zyEzOQdKlRIdeocjuLWZvXR14OjOaOxYexgeBi30pv992+YpGZBxMQffLt2EiM4hMFazcCkREdGVTJo0qc6vWatkJzo6Gv/9739x5swZAECHDh0wZ84ctG/Pb/Wo8QgMN2PK3ImYMnciJEniB+JG7uT+WHz37kZkJOcAqFhPSeOhQo8hHTDtieug1XEO1rXYu/EY7HbRKdEBKioY+gZ5IT0xC0d2nsGwSb3dFCERETV2CxYsqPNr1qr09NSpU9G7d29HQYJ9+/ahS5cu+O6773DzzTfXeZBUdyxlFhzfeQbJMamQK+Ro0zMcbXq1gkxW4yWXmpT6TnQunEpC1LqDiD16AXK5DJ0HdUD/ib3gH+Jbr+02FwlnU7Di1bUoyiuGb5AnlCoFJElCcUEpojYcgyRKuOelSUxoa0mSJCREp1WbMMrlMkgSkJqQ7eLIiIioKTp8+LCjU6VTp07o0aNHra9V42Tn6aefxnPPPYfFixc77V+wYAGefvppJjsNWOxf8fhi/vdIOZ8OSZQgSRJUGiXa9WmNu1+ZBi9/k7tDbJJ2/LAXq99eh6L8Ymi0aoiiiJgj57Fj9V7c8+rt6DSgnbtDrFN2mx1n9p1Dcmwa5Ao52vaOQEi7oHpNNLb/cgj52YUICvdztCMIgqMX4q9dZ5F4Lg2h7bhoZm0pVQqUl1qqPS4AUKo4/JOIqFosPX1FGRkZmDp1KrZv3w5PT08AQF5eHoYPH47vvvsOfn5+Nb5mjb/OT01NxYwZMyrtv+OOO5CamlrjAMg1MpKy8PG8L5Ecmwq/Ft5o0ToALVoHwOClx/Edp/F/z3wNm9Xm7jCbnLhjF/DD27/CbrMjuE0g/EJ8YA71Q1DrQOT9P3v3HR5VmT1w/Hun90nvIYFQQ++9I6AgKtjrquu6dtG19/3trmVd19VF3WJdO/YKIiC990AoIQkJ6XUmZfq9vz+C0ZgESUgySXg/z5Pn0bmTe8+ESeaet5xT7OCNR9/HUeoMdpht5tiBXP58+fP84+b/8MEzn/Punz/mqStf4JW736S6sqZdrul1+9i78TBmm7HJhMpsM+Ku9ZK+PbNdrn8mkCSJYZP64qrxoCiNPz09bi9qrZq+w5KCEJ0gCILQXdx2221UVVWxf/9+ysvLKS8vJy0tDafTye23396qc7Y42Zk2bRrr1q1r9Pj69euZPHlyq4IQ2t/6T7dQeryc2F7RaPV1lS0kScJoMRDVI4LD24+yf8OhIEfZ/Wz8fBu1jlrC40Ib3IirVBIxyVGU5pWzffmeIEbYdkrzynj5rjfJ2pdDaJSd+N4xxPWOQW/SsfWbnbz64LsEAoE2v67P6yfgl5stKiFJEpKKk85KCL9u4tlDsYdbKMopI+D/6d/R4/JSml9Br4HxpI7qFcQIBUEQOjklCF9dzLJly3jppZcYMOCnfnCpqaksWbKEb7/9tlXnbPEytgULFnDfffexY8cOxo0bB9Tt2Vm6dClPPPEEX3zxRYPnCp3Dzu/3oTfpmtybozfq8Pv87N90iKHTBgYhuu7r0LYMDGZDkzMOPzZkzNx7jJlXdP2Bgg2fbaMou5i4lBhU6rr3mSRJWELMqDVq9m84yKGtGaSOb9tle0aLnrAoGwXHSrGGNK7J7/cFQIHI+NA2ve6ZJqF3NNc+cC5vP/ctxcfL62d4NFo1/YYnc/1D56HRimVsgiAIQuvJstyo3DSAVqtFluVWnbPFyc7NN98MwEsvvcRLL73U5DGou8lpj1FcoXU8NZ6T3ohIKgmvGPlucz9vWNokRfn157SAx+Vh+/I9bP56B+X5FdgjbYw9ZwRjzhmO0dK+fbC2LduF3qSvT3R+zmgxUJZfTtr6g22e7KhUKibOG84HLyzHXevFYNLVH1MUhbKCSsJi7AybLKpFnq5BY3vzyH9+y861Byk4VopGo6bv8CQGjEgW5doFQRCE0zZjxgzuuOMO3nvvPeLi6ppV5+XlsXjxYmbOnNmqc7Y42WltViUEV0K/WPb+cIDQ6MbHZFlGkRWik1q+6Us4udTx/Vj+xuomS1v/uBSoz/CebXKtGmct/77nLdLW1zX71Rv1FOWUcHBrBpu+2sFNz12DPcLWJtdqiqvajUZ7kj8pkoS71tMu1540fzgHtmeyd8NhNFo1ZpsRvy9AjaMWS4iZS26fi8kiSk+3BbPNyOT5ra+KIwiCcOaSTnx15PW6ln/+858sWLCA5ORkEhMTAcjNzWXQoEG8/fbbrTpnq/rsCF3PxPPHkrb+ENWVNVhCfmr6pygKZfkV2CJsjJ47LHgBdlMTzx/Dpi+2U5xTSlRiRP0sTsAfoDC7mOjkSEbOHtom1/ry5eXs/eEAkT0i0Bt/mt3wenwc3HKEj/72Jdc/eUWbXKspsb2iSd9yhFAaV/WTZQUUiIgPb9Nr+rx+Nn+3j03L91JwrBRJrUYOKNRWuzEYdYydPZhpF4ym95AebXpdQRAEQRDaXmJiIjt37uT777/n4MG6wdsBAwYwa9asVp+zVcnOtm3bWL16NcXFxY1mep577rlWByO0n+EzBzF50VjWfbSZqvJqLCFmZFmmuqIGo8XAhYvnt/mNaHcS8AdQFOXkMxdN6NE/nqsevZB3/vQxeRkFqLUalBMzaVFJkfz2qSsbJJ+t5SyvYstXOzGHmBokOgA6vRZ7hJXdq9MoOV5GZEL7/DtPOG80B7ccwVXlwmhtuGSuorACa5iZUXPaJrGDuipsrz/1BTvXHARJwmjWozPpcFW5sdrNXPvAuQwcndJm1xMEQRCE0yJKT58SSZI466yzOOuss9rkfC1Odv7yl7/w8MMP069fP6KjoxsszREN+zovtVrNFQ8toteQJNYu3URBVjEqlcSoOcOYevGEbtfrpS0oisL+jYdZ/9k2Du3IBAV6D09m8gWjGTyp/ym/30fPHU7SwES2fL2TzD3ZaLQa+o/tw+i5w7CFW9sk1vyMQqodNYTHhTV53BJqpuBoEbmH8tst2Rk9dxj71qWz9ZudVFXUYA4xIQcUqsqr0Oq1nHfL2W3aRHXNlzvZ8cNBQiKtGM36+sflSCtFOeV8/Moq+g5NQqsTE9iCIAiC0JmtWrWKW2+9lc2bN2OzNVxy73A4mDBhAq+88kqrKj+3+C7gH//4B6+99hq/+c1vWnwxIbjUGjWTLhjLxPPHUOusRaVRN9sRXYDv393AZ/9chqfWi8luREJi16o09m88xPzfzeLsa6edcsITlRjBub+f3W6xSioVIKHITQ/jKHJdIQR1E8UD2opWp+W6P19Gz0E9WP/pFsryK5AkidTxfZl+2WRGzBzcZtcK+ANs+GYPaq26QaIDdQULwmPs5GeVkL49iyET+rTZdYVfpygKmXtzOLz9KH6fn7jeMQye1B+dQffr3ywIgiCckZ5//nluuOGGRokOgN1u58Ybb+S5557rmGRHpVIxceLEFl9I6DwkScJsP/2lU91ZzsE8vnj5OySVRFzvn6o62COtVBQ5+Oa/q+g3qhcpQzpHE8UeA+IJjbbjLKsiIr7x7I6zrApbmJWeg9t374pWp2X2NdOYcfkkKkucqDVqQiJtbT7r6yivoaLYidnWdLKuM2iRZYWCnFKR7HQgZ3k1bz3+Ifs3HcZT60WlkkCSiO0VxVWPXEjfkaIPjyAIZzCxjK1Ze/bs4emnn272+OzZs3n22Wdbde4WD/MuXryYJUuWtOpigtBVbPl2N7VOF6HRjTfbh0TZqK12s+Wb3R0fWDOMZgPTLp6A1+WlqqKmQZf7GmctNQ4X488b3WbL5n6NRqshIi6M0Ch7uyxv1WjVSCoJOdDMTJai1O2xEuWQO0wgIPPaQ++x4/t9mKwG4npHE5sSTUR8KPlHC/nPfW9TkFUc7DAFQRCETqioqKjJ/jo/0mg0lJSUtOrcLZ7Z+cMf/sC8efNISUkhNTW1UWCffPJJqwIRhM4kJz0PjV7T5I26JEnoDFpyDuYFIbLmzf7NNErzy9n4+TYcJQ7UGjWBgIxOr2XCglGcf+vcYIfYZqwhJlIGJrB30xEsdmOjf6capxuDSU+/4Z1j5u1McHDLEdI3HyYiPhTDz5bHavVaYnpGk59RwIbPtnLh4vkdFlON00VlsQOtXktkQpjYVyoIgtBJxcfHk5aWRu/evZs8vnfvXmJjY1t17hYnO7fffjurV69m+vTphIeHiw8PoVvSm3TIgeZ7SskBudPtQdBoNVz16EWMP3cUO7/fS1lBBSGRNobPHEK/0SmoVO23X6ejSZLE9IWjOLwnh9ICB+ExNlQqFYqi4Krx4CirYuxZg4nvFRXsUM8YBzYfxuf1N0h0fqRSSRgtBrZ/t4dFd85r988NR2kVy99cw9Zle6itcqFWq0gelMjsq6YweJIoxiIIgtDZnHPOOTzyyCPMnTsXg6Hh54jL5eKxxx5j/vzWDZa1ONl58803+fjjj5k3b16rLigIXcGgCf3YvfoAAX+gUWf4gD9AwC8zZEr/IEXXPEmS6DOiF31GdM69Ea5qF7tX76c4pxSdQUvqhH706B/fqpvfQWNSuOTWs/j0vz9QeKwMRalrn6YzaBkxdQCX3zFHDMZ0IK/bd9Ljaq0Gj8vb7nE4y6v5551vcnTvMcw2I5ZQEwFfgPTNR8hOy+XKhxcy9uxh7R6HIAjCL0lK3VdHXq+rePjhh/nkk0/o27cvt956K/361Q1MHTx4kCVLlhAIBHjooYdade4WJzthYWGkpIjeFUL3Nmr2EFZ/uInjhwuJ7BGGTl+3XLO6oprcg3lIwPdv/UDeoTzGLxhF35Hid+LX7Fmzn/f+8gklx8vr9hQpCgaznuEzB3PlIxditBh//SS/MGneMAaO6cXONQcpLaxEZ9AycHQKvQcndKuZrK7gx7LickBG1UTVP1eViwFj+rR7Arrq/Q0c3XuM6KSIBmXHTTYjxTllfPyPbxk8qR8ma8vfb4IgCEL7iI6OZuPGjdx000088MAD9XuPJUlizpw5LFmyhOjo6F85S9NanOw8/vjjPPbYY7z++uuYTKZWXVQQOjtLiJkbnryM1x7+kONHCggEZNw1bhxFFUgSRCaE4yhx8sMHG9jy9U7Ov+1sZl8zLdhhd1qZe4/x2oPvUuOoJSoxHI1Og6Io1Dhq2fj5dgB++9SVrboRDo20MfPCMW0dstBCo2YP4Zv/rqQsv4KIX+yPqa1yIakkJpw3ql1j8Hp8bPpqF0azvlF/JUmSCI8LpTi3jL1r0xk3b0S7xiIIgiC0TFJSEt988w0VFRVkZGSgKAp9+vQhNDT0tM7b4mTnhRde4OjRo0RHR5OcnNyoQMHOnTtPKyBB6CwS+sRy/1s3s2/9QdI3Z7DizVXYwy0kDUhAra1b2qYoChVFDj578VuSUhPoN7rpjXVnutXvr8dZVkV8n9j6m2BJkrCE1JVA37UyjZyDeSQNSAhmmMJpCI0O4cK75vPek5+Sf7QQS4gFtVpFtaMWRZYZP38ko+cOa9cYqitqqHXWYrDomzyuOfF7W17kaNc4BEEQmiad+OrI63U9oaGhjB49us3O1+Jk5/zzz2+ziwvdl9ftJW39QUrzytEbdaRO6EdkQniww2oxnV7LyJmDqSioQK1WkTAwscESHUmSCIsJ4fiRukpTItlpzF3rYe/aA1hCLU3O3JjtJhwlTg5sPCSSnS5u4nmjCYsOYfWHGzi0ra6paI9+cUxaOJbJC8eg0bb4I6dFDGY9aq0Gn8ff5HFZVkBWRDNlQRCEM0iLP3kee+yx9ohD6EbS1qfz3lOfUZRdjCLX9Tsx201MPH8Mi+6aj1bXfB31zion/ThAk3sRoK7PzZGdmR0ZUpfh8/iQ/TLqZm50Jamu8eSvbXAXuoYB4/owYFwfaqtc+H0BLCGmDts/ZbIaGTYtlbUfb8EebkVSNUyunWVVmOwmUZFNEITgEE1Fg6LVw2w7duwgPT0dgIEDBzJ8+PA2C0roujL3HuM/979DdUU1kQnhaPV1neydZVV899YaAC69/4IgR9lyKpXqpH8zFEVpVLVNqGOyGQmLDaUgswhrqLnRcb+3bhQ+qkdER4cmtKMfCwDIssyRnVkUHitFq1PTf3QKIVGNm/W2lRmXjCdt/SEKMosJjw9Fb6wrI+8orcJd42H2NVOJiA9rt+sLgiAInUuLh9uKi4uZMWMGo0eP5vbbb+f2229n5MiRzJw5s9WdTYXu4/u31+AsdRLbKxrtiQpmKpVESKQNS4iJ9Z9upTi3NMhRtlzvET1RqST8vsbLYxRFwV3jZuDEzleKujNQq9VMumAsAV8Ad42nwTFFUSg5XkZkQhjDpg8MUoRCe8k5lM9fr/8Xz930X958fCn/feh9Hr/4eZb+/Wu8nvaZyevRP54bn76cHgPiqSx2kn+0iMLsEjRaDedcP50LbpndLtcVBEHo6l5++WWGDBmCzWbDZrMxfvx4vv322/rjbrebW265hfDwcCwWC4sWLaKoqKjBOXJycpg3bx4mk4moqCjuuece/P6mlxb/aMSIEVRUVADwxz/+kdra2jZ9XS1Odm677TaqqqrYv38/5eXllJeXk5aWhtPp5Pbbb2/T4ISupcZRQ9r6Q1jDrE3uzbCFWal11pK2/mAQojs9I2YNIS4lhsLsEvy+QP3jsixTdKwEW7iVSReIimDNmXLROIbNHER5QQVFx0qoqqihssRJ3pECzHYTlz+4qFWlp4XOqzi3jJf/8DaHd2RiCTERmxJFTHIkckBm+Rtr+PDZL+tLi7a1PiN68tDbt3L7i9dy1cOL+O2fL+XxpYu54Na57b5vSBAEoVlKEL5aICEhgaeeeoodO3awfft2ZsyYwXnnncf+/fsBWLx4MV9++SVLly5lzZo15Ofns3DhwvrvDwQCzJs3D6/Xy8aNG3nzzTd54403ePTRR0963fT0dGpqagB44oknqK6ublngv0JSWvhpY7fb+f777xtVSdi6dSuzZ8+msrKyLeMLOqfTid1ux+FwYLPZgh1Op1ZWUMGj5z2N3qTDbGu6LHl+RiEX3n0uZ18/s4OjO33H0o/zn3v/R8HRIhRFQVJJKLKCPcrOlQ8vYuRZQ4MdYqfmcXlYu3Qz6z/dQnlBBSqNiiFTUpl+6SR6DUkKdnhCG/voH9/wzX9XEZcS3WivW1V5NT6Pn/vfvJmEPrFBilAQhO6kM9+v/RjbVe+8g64D27Z4a2v53xVXnNbPJCwsjL/+9a9ceOGFREZG8u6773LhhRcCdQ0/BwwYwKZNmxg3bhzffvst8+fPJz8/v74nziuvvMJ9991HSUkJOp2uyWuMHz8ei8XCpEmTeOKJJ/jDH/6AxWJp8rm/ljg1pcVDXLIsNyo3DaDVapFlucUBCN2HNcyCJdSMs7SqyWTH5/WDJHXZ9fJJAxJ44J072LliLwe3ZRDwB0hOTWT02cMJjz29GvBnAr1Rz1lXT2XGFZOodbrQ6rUYTE2XCO6u8jOL2fztLvZvOoIckOkzPJlx5wyn16DEYIfWpgIBma3L9mC0Gpss6mEJNZN/tIi9a9NFsiMIwhkjWIWnnU5ng8f1ej16/ck/fwOBAEuXLqWmpobx48ezY8cOfD4fs2bNqn9O//796dGjR32ys2nTJgYPHtyg+eecOXO46aab2L9/f7P7+9944w0ee+wxvvrqKyRJ4ttvv0WjaZyiSJLUMcnOjBkzuOOOO3jvvfeIi4sDIC8vj8WLFzNzZtcbrRfajk6vZcKC0Xz24jd4PT50+p+SYkVRKM0rIzIxnMFTUoMY5ekx20xMXjSOyYvGBTuULkutVmMNbXrEpjvbszadt/70KZWlTvRGHZIkkXOogM3f7ObC2+cyZWH3WQbpc3vxurxo9c1X4JMkidoqdwdHJgiCcOZJTGw4oPbYY4/x+OOPN/ncffv2MX78eNxuNxaLhU8//ZTU1FR2796NTqcjJCSkwfOjo6MpLCwEoLCwsEGi8+PxH481p1+/frz//vtAXUGolStXEhUV1ZKXeFItTnb++c9/smDBApKTk+t/eLm5uQwaNIi33367zQITuqZZV07m4NYjHNyagcGkx2Qz4vf6cZZXYQ21cOl9559xo/mCUFZYydtPfka1o5b4lOj6PW2KolBeWMlHLywjsV8sPQd2jxkevUmPzqQn50gBhUVVAFisBkLDzBhNddXRFAXCotuvKltn4vcH2LfvOLt2ZuNw1BIebmX06J70HxDX5P5GQRC6qSCVns7NzW2wjO1kszr9+vVj9+7dOBwOPvroI6655hrWrFnT3pHWa49VYi1OdhITE9m5cyfff/89Bw/WbTQfMGBAg2kt4cxltpu55R/X8f3ba9n0xTaqKmpQa9SMnjOcmVdOod+olGCHKAgdbvuKvVQUO4ntGdng5vbHprR5R4vZ/M3uNkt2FEUh70gB6Vsy8Hl8RCVFMGTyAHSGptdLt7Vtm49S5A5QVVmLxmRAUqtw1XopL6smPiEM2ePFFmZh+IxBHRJPMDkdNTz78FIO7cxClhX0kTbUdgvr1x1iwsQ+XHnVRDSibL0gCO3ox+pqp0Kn09G7d12D9JEjR7Jt2zb+8Y9/cMkll+D1eqmsrGwwu1NUVERMTAwAMTExbN26tcH5fqzW9uNzTsXRo0d5/vnn61vcpKamcscdd5CS0rp7yFaVpZEkibPOOouzzjqrVRcVujdLiJnzbz2bc347E0dpFXqjDlu4NdhhCULQZKUdR6WSmmyuKUkSBpOOwzuz2uRarmo37z75CTu/34e7xnOiaSvEJEdxxYMLGTCuT5tcpzmFBZW8+/o6dJEh2OPCqS6uRKXVoNFp8Hp8ZKfnER0XwqLbzya0m8/s5BzM4/Gr/klBRgFqVd3SPU+WCnN0KJZRfVnzw0GiouycM08UNxEEoXOSZRmPx8PIkSPRarWsXLmSRYsWAXDo0CFycnIYP348UFdo4M9//jPFxcX1y9BWrFiBzWYjNfXUtjAsX76cBQsWMGzYMCZOnAjAhg0bGDhwIF9++WWrco9TLj29atUqUlNTG21yAnA4HAwcOJB169a1OACh+9IZdEQmhItERzjjqdQqTlb3UlGUJjfyt5SiKLz9p4/Z8Nk2tAYdsSnRxKZEExEfRmF2Mf954B1yDuad9nVOZuuGIzgra4lOCCNpykCiUhNRa9X4PT7UgMpiIGlcXyzhVnatSafG0bb9FDoDt9/PN7v28sC1fyfvSB4qkw5DmBV9iBmNXkf18VLKthxErYI1P6TjaaeeQ6fK5/VTW+Vqt1LggiCc0MlLTz/wwAOsXbuW7Oxs9u3bxwMPPMAPP/zAFVdcgd1u5/rrr+euu+5i9erV7Nixg2uvvZbx48czblzdPubZs2eTmprKVVddxZ49e1i+fDkPP/wwt9xyy68WRPjR/fffz+LFi9myZQvPPfcczz33HFu2bOHOO+/kvvvua9kLOuGUZ3aef/55brjhhianwex2OzfeeCPPPfcckydPblUggiAI3VXfET3ZunwPAX8A9S+WLCmKgsflZeD4059xyd5/nF2r9mGPtGEJMdc/rtVriekZRf6RQtYs3cRVj1x42tdqzpFDhWi0aiRJQqPXEjs8haiBSXhr3PhqvRzfn8OelfvJ3p5Z33B4ygWjOeeaKY1+Nl3RkYoyntm+lqxP9kJmMRi0BNQKfq8Hs1aHWqdBspmoKarE5qyhXKXm+PEKUlLabjPuqco7UsCajzaxY8Ve/N4AodF2Jl0whokXjMFoNnR4PIIgBFdxcTFXX301BQUF2O12hgwZwvLly+tnU/7+97+jUqlYtGgRHo+HOXPm8NJLL9V/v1qt5quvvuKmm25i/PjxmM1mrrnmGv74xz+ecgzp6el8+OGHjR6/7rrreP7551v1uk452dmzZw9PP/10s8dnz57Ns88+26ogBEEQurORMwex4p31FOaUEdMjvP6mXpZlinPLCYmwMf6cpktytsSBTYdw13gJa6IUuiRJmOwmdq3cx6X3nY9W1z7NNdVNzGKpdRrUPi25W4/gKa/GEmomvlcUckCmsrSKL/69CleVm4vvPLtdYvo5Z3k16VszcFV7CI+x039M7zb7WZS7a/nzltUcq6rEvL8Sv1ZDQFYhSRIBRabG58Wi06PSqEFRqM0rwxhi5aTTfu3k8I5M/n3v/ygvqMRkN6LRaijIKua9pz8jbcMhbnz2KpHwCMIZ5tVXXz3pcYPBwJIlS1iyZEmzz0lKSuKbb75pdQyRkZHs3r2bPn0aDgDu3r271RXaTvkvfFFRUZP9depPpNFQUlLSqiAEQRC6M2uomev/eBGvPrqUwmOlSFJd8iHLCqFRNq584Hxie57+yL7X5a0/d1M0WjUBfwCfx9duyU7/gfHs3XUMWZYb7FEqzyrE7axFZdQREmFFkiTUGjXhMSE4yqpY/8UOJp8/itjkyHaJS5Zllr25lpXvbcBRVlchTqVSEZMcyUV3nM3gSf1P+xqrczM5VlVJD0sI5Z4Akl6N5JEgACp1XcLjCwTQq9UggbvGTbTdRGxcyGlfuyV8Xj/v/PljKoocxPWOQVLVvV+sYRY8Li/71qWz6t31zLtBFB4SBKFj3XDDDfzud78jMzOTCRMmAHV7dp5++mnuuuuuVp3zlD/t4uPjSUtLq6/Q8Et79+4lNlY0hxOEjuJ2+9i36xilxVXo9RoGDetBVEz33vDdlfUa3IP7X72RHav2c3hnFnJApuegBEadNYTwmJA2uUZEQjhINLlcDqC2ykV8SgxGS/uN2I+Z0JtV3+2jsKCSmJiQuv1KskxlTimyAga9ltAwc4PvsYVZyM8qYc+6g+2W7Cx7cy2fvfQdWr2W6B4RqDVqvG4fBVnFvProh9z87FX0HdHztK6xKT8XjaRGrVKhSbDhL6hBZdQRqPbXJxQ+OYBOpUIOKChGPZMm9cXUweX4D2w6RP7RIiISwurj+pHeqENr0LLhs22cdfXUBv3SBEEQ2tsjjzyC1Wrlb3/7Gw888AAAcXFxPP7449x+++2tOucpJzvnnHMOjzzyCHPnzsVgaPhB6XK5eOyxx5g/f36rghAEoWV2b8/igzc3UFLkrNt/qCiYzHomTO3PoivGoWunUXvh9FjDLEy7cCzTLhzbLucfMXMwX7y0nNK8cqJ6RDSY4XHXepD9MhMvGNNuvV0URaHwcB5Rkp9jRZUcKKjEaNajM2hx13rR6DUkJkU0en9KkoQE1Dhd7RKXs7yale9tQKvXEh4bUv+4zqAlJjmS/KNFfPf2utNOdtwBP+oTyYNxbDyeXYVIWgXFoEL2yKAoyGqZ2uoaJI2KsWePCEoltqJjpciy3GwpcrPdhKO0CmdpFRHxYR0cnSB0Y0Hqs9OVSJLE4sWLWbx4MVVVdbPwVuvpFbo65Tuihx9+mE8++YS+ffty66230q9fPwAOHjzIkiVLCAQCPPTQQ6cVjCAIv+5wej6vv7SK2hovEdE2tFo1iqLgdLj4/ts9AFx27aQgRykEg9lu4uJ7FvDWE0vJP1qINdSCWqOmxlmL3+tn2LRBTF7YPolWwB/g/ac/Y+1Hm/C6fVj1OqqQcDs16COsxCSEopIVrLbGs0qyLKMA9naq3Ji+NQNHWRXRPSIaHZMkCVu4lUM7MikrrDytWbbeIeGklRahKAr6wVEYp/Sgdk0OKllBMqrx1QaQXH6MJgOzr5/JdQ+dj1bb8UUZtHotKKDISqOZHYCAL4BKLaERgyaCIATR6SY5Pzrlv2TR0dFs3LiRm266iQceeKC+RKUkScyZM4clS5YQHR3dJkEJgtC8ld/uo8rpJi4xtH6EXpIk7CEmADauPcjMcwYT1c17mAhNGz1nGLYwK6veX8/BLRl43T6iEiOYeN5opl0yAb2xfRqLrv1oM6vfW48l1ExUYl1SEQv4PD4KjxVg7xFFZYULn9ffaL9QZUkVFruJ4dMGtEtsrmoPQLPV3rR6DR6XB3e1+7SuM7NHCiuOZVDmriXCaMZ2cSraHnZc63Jw5TtR2zWMHz+IBVdNZ9j0Qe02w/Zr+o/pjdFqpKqiulFrAEVRqCqvZui0VOwRom2AILQpMbMTFC0atvmxwkJFRQUZGRkoikKfPn0IDW1c+UcQhLbndLhITzuO1W5s8kbJajNSmFfB/j25RM0Wyc7pCPgDpG8+TNGxUnQGLQPG9SEiPjzYYZ2SfqNT6Dc6hRpHLV6PD1uYpV3LOgf8AX74YAOSSoU11NLgmFavJSwmBGdxJdG94ynMLsViN2G2GQkEAjhKq0CSmH/99Dbbu/RL4TF2VCoVXrcPnaHxHhR3tQe9UX/aN/eDwqO4vP8Q3k7fzbGqCqxaPcrIcKoGmdG7Fa4aNJzLho8MWpLzo9ieUYyeO4w1H25EpVZhtpvqKsb5A5TlV2C0GJh52eSgxykIgtAWWjVHHRoayujRo9s6FkEQfoXX4yMQkDE0ccMGoDrRpd3r8XdwZN1Lxq4s3v7TR+QdKSDgr9trYbabGH/eaC5cPL/ZvQ6djdluwvzrTzttpXnllOSWYQuzNHncZDVSWeRgwpwhVJbXsH3VfsqLHKjUKmJ7RjHrsglMmHf6pbeb039Mb2KSIynIKiYmObLBTXzAH6DaUcOsyyY26E3UGpIkcXn/ofS0h/FN1iEOlBUDMCWhJ/N69WN0TMJpnb8tXfyHc/F7fexYsQ9HSRWSClAgJMrOhXfNZ+DEfsEOURC6HUmp++rI6wmtTHYEQQgOm92ExWKgyunCZG5cwcnn9YMEEVFi+UlrHT9SwMt3vUFFUSUR8eHojTpkWaaqvJrv31qD3+vn6scuDnaYncqpTQBImKwG5t0wk/m/nU7x8XK0Wg2JfWPavZmoVqfhojvO5tVHPyT/aBG2cCtavQZ3tYdqRw09+sUx55qpbXItSZKYENeDCXE98AYCAOjUna9ZqtFs4Lo/XcZZV05l3/p0PLVeIuLDGDZjULNJqyAIQnvy+XzMnTuXV155pVGfndMhkh1B6EJ0eg0Tp/Xnsw+24vX6G1S1UhSF0pIqomNDGDwsKYhRdm0/vL+BsoIKEnrH1m/eVqlU2CNsSCoVW77awYzLJ5PQR5Ta/1F4XBhRPSLIyyjEZDM2Ol7rdKE360gelAjUFSJor2IEzRk8qT83P3sV3/1vLYd2ZuFx1S1dm3XZROZcM7VdltB1xiTn5yRJoseAeHoMiA92KIIgCGi1Wvbu3dvm5xXJjiB0MTPPHszB/XkcTMtDb9BgMuvx+QJUO13Y7CYuvWYiOr341W4Nr9vLjhV7sNhNTVapsoaayc8oJG1dukh2fkatUTP14gm88+ePqCqvxvqzmQGvx0d5USXDZwwmeWBiEKOEviN60md4MuWFlbhrPNgjrKe9dE3oXPw+P5l7c3DXuAmLDSW+d4zYeyQIXciVV17Jq6++ylNPPdVm5xR3RILQxZgtBm75w1xWLUtjw5qDVDvdqNUS46f0Z8bcQaT0jQl2iF2W1+3D7wug0TW9J0qSJJAk3LWeDo6s85ty0TgKMotYu3QTjrIqdHotfl/d3rF+o1K4+rGLTvums6jQwcFDBQQCMnGxIfTtF4uqiaT0ZCRJIjxWFNXpbhRFYdMX21n2+moKs0sI+APojXr6jerFwjvnkdgvLtghCoJwCvx+P6+99hrff/89I0eOxGxuOCD13HPPtficrUp2Dh06xIsvvkh6ejoAAwYM4LbbbqvvvSMIQvsyWwyce+Eo5iwYRpXThcGgxWxp3L9EaBmjxYA9wkrJ8TKsoY1H/AP+AKC0+mbZ6/GRtvEwRTllaHVq+o3qRUI3GXlWq9Vc9sAFDJ85mK3f7KQwu6SunPTMwQyfNRijufXvT5fLy/vvbWbbtkxqa72AglajISk5gmuumURij65RJU9oP2uXbua9pz4l4JcJjbaj1WmorXaza/V+8jOLuPPlG4jtJdpjCMElChT8urS0NEaMGAHA4cOHGxxr7Wdli5Odjz/+mEsvvZRRo0Yxfvx4ADZv3sygQYN4//33WbRoUasCEQSh5XQ6DeGiF0abUWvUTDx/DEuf/QKv29ug6pqiKJTlVxAaHcKwGYNafO5DO7J495kvKMguQZEVFEXBYNYzbOoALr/nXEzWur0usiyTvvkIm7/eSX5mMWabkeEzBjFm7jDMdlObvdb2IEkSA8b2YcDYtttYqigKb7y+js2bM7DZjMTFhSBJEi6XlyOHC1nyz++5+55ziIwUvwdnqhpnLV/+awUAMcmR9Y9b7CZMFgN5R4tY/uYP/OaJS4IVoiAIp2j16tVtfs4WJzv33nsvDzzwAH/84x8bPP7YY49x7733imRHEIQuberFE0hbf5ADmw5hsBgw20wEfAEcZU6MZgOLFs9v1Evm1+QdLeK/j3xIZYmTyPhQtHotiqJQ46hl09e7CPhlfvfnS5BlhQ+e+Zy1H2/B5/GjNWjxe/3s33CItR9v4aZnryKqR0Q7vfLO6ciRInbtzCY01Iz5ZxUIjUYdcXEh5OdXsmH9Ic6/YFQQoxSCKW39ISqKKuub2f6cSq3CGmpm18o0Llw8X+zREoQuIiMjg6NHjzJlyhSMRiOKorR6ZkfV0m8oKCjg6quvbvT4lVdeSUFBQauCEARB6CxMViM3P/8bFtwyF0uImVpnLT6vj8GTB/D7537DhAUt7zG29pOtlBdVEpsciVZftx9IkiQsIWZCI23sXXeQrP3H2fDpVlZ/sAmjxUBcSjSR8WHE9owiKimC7P25vPH4UmRZbuuX3Knt25uDx+vHZGrc20ilVmEwaNm86WgQIhM6i6ryalBAo226+p3eqMPn8VFVUdPBkQnCLyhB+OpiysrKmDlzJn379uWcc86pzy2uv/567r777lads8UzO9OmTWPdunX07t27wePr169n8uTJrQpCEAShMzHbzVxw2zmcff1MKosdaPVawmJCWjWqFPAH2Ll6PyarsckKbyabkcqSKtI2HmbP6n0AjUafNVoN4bGhZO49xpGdWfQbldK6F9YFud0+UJpfq63RqnG5vMiy0uJiBUL3YA2zgERdcZEmEh6Py4tWr8US0rmXgQqCAIsXL0ar1ZKTk8OAAQPqH7/kkku46667+Nvf/tbic7Y42VmwYAH33XcfO3bsYNy4cUDdnp2lS5fyxBNP8MUXXzR4riAIQldlMOmJSY46rXP4fQH83qZvwqDuJl5SSVSWOinKLsUa1vQyG4NZT0WRg2MH8s6oZCcszIIk0Wwy43Z56dkrSiQ67agwu5gDmw7jdXmJTAxn8OQBDfazBdugSf0IjQ6hoqiSyISGxSrkgExVRTXTLpnQ4uWngiB0vO+++47ly5eTkJDQ4PE+ffpw7NixVp2zxcnOzTffDMBLL73ESy+91OQxqPsAD5zoHi0IgnCm0hm0hMeFkHu4sMnO9AF/AEVRiIgJAYlfXXbQDQq3tcio0T35+qvdVFTUEB7e8OfndvtQFIVJk/oGKbruzev28sEzn7P56x24nG5AQZEkopMiufLhRQya2D/YIQJgtpk498azeO+pTynMLmlQja2yyEF0UiSzr54a7DAFQTgFNTU1mEyNZ2HLy8vR6/VNfMeva/GeHVmWT+lLJDqCIAh1Az8TF4xEkeVG/XkURaGsoJLQKBuTzhtFXEp03f6DJriq3egMWnoN7tERYXcakZE2zjt/BHJAJj+/gpoaDy6Xl9KSKspKqxg6rAcTJrZd9TfhJ+899Smr31uPWq3CHG7DK2lw1PjZvzuX/7vmZb59cw2K0jk2BUy5aBxXP3YRsb2iqCxxUnisBE+th2HTB3LrC9cRlyL6jwnB92Pp6Y786momT57MW2+9Vf//kiQhyzLPPPMM06dPb9U5RVNRQRCEdjZx/kgObM5g95p0NDo1ZpuRgF+mqrwGk83AhXecjS3cyrSLxpO9/ziO0ips4Zb6fSo+j4+KwkoGTxlAr6FJQX41HW/WWYOwh5hY+f1+co6VISsK9hATkyf3ZdZZg9Dp2u+jTFEUnCeSVJtJ3y16Ip2KvIwCtn6zC0uoGbdPoaSoDEUBtVqFTq+husrNG3/5DBk45+opQf+5SJLEhPNGM/rs4WTty8Fd4yYsNpT4btLHShDOFM888wwzZ85k+/bteL1e7r33Xvbv3095eTkbNmxo1Tlb9QlRU1PDmjVryMnJwev1Njh2++23tyoQQRCE7kpn0HLDny7hh4+3sOGLHVQUO1CpVYycOYjpF4+l/4k9OOPPHUnRsRJWvL2O/IwiNDo1Ab+MJEn0GdGLqx+98Iy8cZMkiTFjUhg9uhclJVX4/QEiIqztnuSsTcvku52HOVZcCUDPmDDmjOjLxNTkbv/vsH/DIWqrXITGhlKaV4qkUqH72b4zg6LgrvbwzRtrGTAqhV4DE05yto6j1WnoO7JXsMMQBKGVBg0axOHDh/nnP/+J1WqlurqahQsXcssttxAbG9uqc7b4k2LXrl2cc8451NbWUlNTQ1hYGKWlpZhMJqKiokSyIwhCAz6vn0NbM6gocmCyGRkwrk99A80zic6gZfYVk5h5yXiqKmpQa9RYQxsWI5AkifNvncuQKalsXbabwqxiTHYjQ6ekMmz6QAym1q1X7i4kSSIqytbu11EUhbdX7eTzLQeQZRnbiZ/7/mOFHMwt5nipg0umDO3WCY/H5UUlSTgqXAQCCnpDwwIbkiShUinUVrnZumJfp0l2BEHo+ux2Ow899FCbna/Fyc7ixYs599xzeeWVV7Db7WzevBmtVsuVV17JHXfc0WaBNWfJkiX89a9/pbCwkKFDh/Liiy8yZsyYZp+/dOlSHnnkEbKzs+nTpw9PP/0055xzTrvHKQgC7F17gKXPfUVhVjEBfwBJkgiLCWHutdOZcfmkbn2z2By1Rk1IZPM37JIkkTI0iZQTy9Vqq90c2X2MtE0ZRMaH0qNf7Bn5c+tI+3OK+GpbOiadhhDLT4m5zWSgvKqWzzfvZ1hKHP0TTq9SX2cWER8GEtTWeFCppEbvuYBfRmfQojfqOH6kMEhRCoLQHVVUVPDqq6+Snp4OQGpqKtdeey1hYWGtOl+LCxTs3r2bu+++G5VKhVqtxuPxkJiYyDPPPMODDz7YqiBO1QcffMBdd93FY489xs6dOxk6dChz5syhuLi4yedv3LiRyy67jOuvv55du3Zx/vnnc/7555OWltaucQq/TlEUnOVVVBQ7RDGLburg1gz++8C75B8pJCzaTnxKDFGJEVSVV/P+M5+z6t31wQ6xUwsEZJa/s4EnrnqJJfe9xysPfchfb36d5+/8H8czxM1le1q7LxO3198g0flRqMVIrcfH+rSsIETWcYZNH0h4XBhel7dREQIlUFeIKDQmFDkgYzB3njLUgtCpiaaiv2rt2rUkJyfzwgsvUFFRQUVFBS+88AI9e/Zk7dq1rTpni5MdrVaLSlX3bVFRUeTk5AB1U065ubmtCuJUPffcc9xwww1ce+21pKam8sorr2AymXjttdeafP4//vEP5s6dyz333MOAAQP4v//7P0aMGME///nPdo1TOLk9a/bzj5v+zUPznuSRc5/kT5c8x6r31uP3+YMdmtBGFEXh29dWUVVeTWyvqPqeHBqtmsiEcNRqFcteX01tlSvIkXZeX7++hk9e/p4ah4vI+DDiekVitOg5sOUoLz/4IUW5ZcEOsdvKLa1Ef5K+SDqNipySyo4NqoMZLUYuve98rDYDPq8Pn8dHwB/A6/LicXuxhloIibKhKApDJvQLdriCIHQTt9xyC5dccglZWVl88sknfPLJJ2RmZnLppZdyyy23tOqcLU52hg8fzrZt2wCYOnUqjz76KO+88w533nkngwYNalUQp8Lr9bJjxw5mzZpV/5hKpWLWrFls2rSpye/ZtGlTg+cDzJkzp9nnA3g8HpxOZ4Mvoe2sfn8Dr9z1JnvXHkClVqHVazl+uJB3/vQxbz72AQG/mOXpDkpyy8jYmUVIpK3JJVeh0SGUF1aSvvlIEKLr/EoLKlj10RYMJh3hsSFotGokScJkNRKTHEHRsVJ++GRbsMPstow6Hf6A3Oxxf0DB3ImaaraXEbOGcMc/ryciJhSfL4DfF0Cr1xDbM5q4lBhK8ipI6B3DyBmpwQ5VEIRuIiMjg7vvvhu1+qcBJ7VazV133UVGRkarztniZOcvf/lLfTWEP//5z4SGhnLTTTdRUlLCv//971YFcSpKS0sJBAJER0c3eDw6OprCwqaXdBQWFrbo+QBPPvkkdru9/isxMfH0gxcAKM4t5dMXvgYgvncstjALlhAzMcmRhETa2PzlDrZ/tyfIUQq/VJhdzJcvf8fLd7/Jaw+/z5ZvduFxeU/6PbVVrhM3Rtomj2u0ahRFETM7zdi74TA1Dhe28MZNSFVqFSabke0r9+N1+4IQXfc3pm8isqI0mfD4/AFAYXTf7v/ZoCgKllAL5980i+SBiYREh2CNsOOXFRwV1aQMTuR3/3cRZlvjBoCCIAitMWLEiPq9Oj+Xnp7O0KFDW3XOFhcoGDVqVP1/R0VFsWzZslZduLN64IEHuOuuu+r/3+l0ioSnjWxfvoeq8mriejcuHWiyGXGUOtjw2VbGnjMiCNGdntpqNzt+SGfvxiO4az3E94pizMyB9EyN79Kbydd8uImPn/+qrnqYWoUsK2z4bCs9B/fgd89cSVRiRJPfFxJlR2/U4a5xozc2HgH3uLyoNWpCo+3t/RK6pFqnC0kl1S8Z/iWtXoPX48NV40FnaDqhFFpvQmoSy3ceIrOwjKgQC0Zd3c/Y5fFR7KimT1wkY/t17+au+VnFvPPXr8g6cByfx4+sKGi0aqISwhk5PZU+w5JIHZOCRiva9QmCcHr27t1b/9+33347d9xxBxkZGYwbNw6AzZs3s2TJEp566qlWnb/L/JWKiIhArVZTVFTU4PGioiJiYprujBwTE9Oi5wPo9Xr0+jO7vGt7Kc4tOVGutOmbf4PZQH4X3HhdlFvGv5/4lNwjhSDVTbem78hmwzd7mHPZOOZdPblLJjz7Nx7ig79+jiIrxKfEIKl+anB5dFc2rz74Hve+fjNqTeO9DSGRNobNGMTajzZhCbWgVv90064oCmUFFST0jaX/mN4d9nq6Enu4FUVRkAMyKnXjhMfj8mINMWOyGoIQXfdnMxn4w6Kp/PPLDWTkl1ESqAFAp1YzKDmW286d2K2XsVWWOHnloQ/IO1pMeIy9ruS5AtWOWoqPl1F8vJwLbprVbDIuCEIzOrpoQBcpUDBs2DAkSWpQDOXee+9t9LzLL7+cSy65pMXnb3GyU1ZWxqOPPsrq1aspLi5GlhtO85eXl7c4iFOh0+kYOXIkK1eu5PzzzwdAlmVWrlzJrbfe2uT3jB8/npUrV3LnnXfWP7ZixQrGjx/fLjEKJ2cw6htV9fk5vy+AwdK1bt4C/gBvPPUlxw7lE50YgebEpmZFUXCUVfPN/zYQmxTJyGkDghxpy635aDPuGg/xvRsODmj1WiISwsjce4z0zUcYNKl/k98/74aZHN2dTV5GAbYwCwazAZ/HR2WJE1u4hYvuOleMCjdjyKR+2P5joSi3FL1ei6KA0WLAZDPi9wVw13iYdck4tO3YVPNMFx9u5/+umkvasUKOFpQhSdAnLoLUHtGog3CT7671sHdtOsePFKJWq+g9PJn+o1OaHGw4XRu/2U1eZjGxSZGoNSdeqwTWUDNqrZq9Gw9zeFc2/UXzTkEQ2kBWVvtWt2zxJ+VVV11FRkYG119/PdHR0R06Yn3XXXdxzTXXMGrUKMaMGcPzzz9PTU0N1157LQBXX3018fHxPPnkkwDccccdTJ06lb/97W/MmzeP999/n+3bt7fr3iKheYMm9Wflu+tw13gwmBvOnskBGU+th9FzhgUnuFY6tOsY2QcLiIgNrU90oK5iU0iElcJjJaz9YicjpvbvUrM7Xo+PQ1szMNubXotvMOkJ+AJk7M5qNtmJTork9iXX8/V/VrJ7VRqOsio0WjXDpg1k7nXT6TdazOo0R0JBr4EjWSXIAQWVCtRqFTqTHpPNSK9BiUy7YHSww+z2NGoVw3rFMaxXXFDjOLIrm7f++DGF2cXIct2AkVanIWVoEtf98WLC40Lb9Hpbv9+HTq/9KdH5GZPFQHmRg30bj4hk5zQVZhVTml+BwawneWCCGPw5E4iZnSYlJSW16/lb/Ju1bt061q9f3+pNQqfjkksuoaSkhEcffZTCwkKGDRvGsmXL6osQ5OTkNJhWnzBhAu+++y4PP/wwDz74IH369OGzzz5r16pxQvMGjOtL6ri+7F17gNDoEEw2I5Ik4XF5KT1eRlRSJBPP71o3cNmHCgj4A03uSwEw203kHCmktsqN2da4Z0dnpcgKikKzSw5/JJ+kYhXUJTzX/elSHKVOKoudGK0GIhPCu1Ti19G8Hh//vvd/5B3IISrKQk2tD4/HjxyQcTldWG16rn3ovJM2JhW6j+LcMv774HuUFVQQmRheP5vnrvWQviWD/zz4Hnf96wZ0zRQDaY1ap+uks4aSJOGqcbfZ9c40eUcL+fTFZRzamoHb5UWtVhHTM4rZV09h/PyR4u+jcMbLz89n/fr1Ta4gu/3221t8vhYnO/3798flCl4FpVtvvbXZZWs//PBDo8cuuugiLrroonaOqvMoPl7Gnh8OUFVZgzXEzNBpqUQlhAc7LKCuc/z1T13Bm499wIGNh6ksdoAkoVar6DEggWv+eAkR8Z0j1lOmKL8ycCKhoJx0+V5npDNo6TEgjvTNR7CFWxsd93l8SCqJxH7xp3Q+e4QNe4S4OT8V+9Ye4OCWI0QnRaI36lAUBbfLhywrqCQozy/n6K4sEvo0LvQhNOYsr2b7d3s5vCOTQECm1+AejJkztM1nQ9rLxi+3U5JXTlxKVIPBPINJT1SPMDL35rBv/UFGzhzcZteMTgzn4M4sQptIqOv+limER4e02fXOJIXZJSy5800Ks4sJibRhi7Di9wXIP1rE//7vY7xuH9MuEkvthTPXG2+8wY033ohOpyM8vOHgqCRJHZPsvPTSS9x///08+uijDBo0CK224WiSzSZuaIJBlmW+/PdKVr63gRqHC0kCRYEv/7OSs66YxLzfzugUm0ltYVZufeF6svfncnj7UQJ+mfg+MQyc0K9LTuH36BeLRqPC4/I2ObtT46il3/CkTjOr4/P6SdtwiMy9dc2AewyIZ+iU/vVNP38kSRJTFo3j8LZMnOXV2MJ+KoEsB2SKc8uI7xPD0Gmiv0Zb2706DVmW699PkiRhNP3076PSqNi2fDdTL54QrBDbRCAgU1VRg1anbrfSxUf3HOPVhz+gKKcUSSUhSbDz+318/856rnzoAoZPH9gu121Lu1buR2/SNfn3W2fQEfAHSN+S0abJzrizh3FoV3aTS44rSpyYbUZGTBe/+63x/TvrKMwqJi4lur74iFqjJiY5kpLjZXz975WMnj202SXEQtcmAVIHjn12xTnCRx55hEcffZQHHnigze5bW3x3GRISgtPpZMaMGQ0eVxQFSZIIBERTyGBY9f4mvvrvKowmPXG9opBUErKs4Ch18uW/V2KyGpl52cRghwnU3bz1HNSDnoO6funWASOSSeoXS8a+40T3CEej+alAgbOiBpVaxaT5wzvFsoS8o0W8/sgHHDuYX7/8TKWSiEuJ5to/XkxyakKD54+eO4zsA8dZ+c46qsqr6/bp+AN4PT6iekRy7f9d2ihJEk5fVUX1STeda3VaqitrOjCituXz+ln3+Q7WfbmDssJKVCqJPkOTmLZwDAPHtt0+Lmd5Na8+/AHFOaXEJEfU/0xlWaYkp5y3/vgxUT0iiE+J/pUzBZfX7WtQzfCXJJXU5v2WRs8axN71h9jxwwF0ei0WuxFZVnCWV6NWq1hwwwxikyPb9JpnghpnLTu/34clxNRklcWwmBCKjpWyb/1Bxs3rei0YBKEt1NbWcumll7bpAH2Lk50rrrgCrVbLu+++2+EFCoSmeVxeVr63AY1GTUjUTzNrKpVEaJSdkuNlrHx/I5MvGC1uTtuYWqPmmvvO5T9PfEJuRjGSSkKjVeP1+DAYdcy9fDyjO0F38RpHLf+5/11yD+UTmRhe35vF5/Fz/Egh/77/Xe79742ERP3U90aSJC66az6pY/uw8cvt5Bw4jt6kZ8TMwYydP4KIuLBgvZxuLTopkj0/7K8fQPolj8tDTHJUECI7fT6vnzf+/CnbVqShUquw2I0EAgq71h7k4PYsLll8NpPmt81N3s7v91H0i0QHQKVSEZUUTn5GEZu/3smi289uk+u1l8T+cexcua/JY7Iso8gKsT0bvx8C/gDFx8tRFIXI+LAWVe7T6bVc/9gikvrHsf6rnTjKqlBJKnqmJjDjwrGMmd12s0hnkhqHC6/bi9Ha9Ey/WqMGCarKqzs4MkHoPK6//nqWLl3K/fff32bnbHGyk5aWxq5du+jXr1+bBSGcnqy0XMoLKwmLabpBoz3CRllBBZlpufQfldLB0XWMGkcNW77eyfbv9lBdWUNMzyjGzR/F0Kmp7VKa9edikyK46+9Xsv2HdPZuOIyrxkNCSjRjZg2k9+DETjEgsHNlGsePFBCdHNmgapxWryG2ZyQFWSVsXb6H2VdNafB9kiQxaFL/ZiuuCW1v9NzhrF26mary6kb7pWqctag1asZ20VHfbd/vY/v3aYREWDH+rMy8NcREaX4Fn7y0goFjehMadfrLoQ/vzEKSaPL3X5IkdEYd+zcebrdkx13jYd+mw1SUVGE06xk0rk+rXteEc0ewd206VRU1WEPN9Y8rikJZfiW2cCujZw+pfzwQkFn32XbWfLKVkrxyFAXCou1MPm8k0y869XLlOoOWc66ZwqxLxlNWWIlaoyIiLrRTLIfuqsw2I1qDDo/L2+D9/6OAPwAKWH727ywIZ5onn3yS+fPns2zZMgYPHtxou8xzzz3X4nO2ONkZNWoUubm5ItnpRHweH4GA3OxNvVqjQg7I+L3+Do6sbfl9fnLS8/C6vUQmRhAeW7fBuOR4GS8vfoPstBxUGjVanYbjhwvYtXIf4+aP5OrHL0ara98u8xa7iWnnjWTaeSPb9TqtlbbxEEhSg0TnRyq1CrVGxZ41BxolO0LHSxmazPTLJvLdGz9QW+XCFm5FkiSqyqvx+/xMPH8MQ6YEf7awNTZ+vRsFGt3oSZJEeGwIBdkl7PhhP7MuPv0N2nJAPulAgyTRqMpPW9m+Mo2PX1pBWUElUJeYWEJMTF80hnm/mdqiAZghUwYw7aJxrP5wE9UVNZjtJmRZpsbhwmQxcOGd5xARH1Z/nY9fXM7KDzYhqSRsoWaQoKyggqUvLCfvaDFXP3hei66vM2jFkrU2YrabGD5jID98sAlbmKXRUraKIgchUTYGi8El4Qz25JNPsnz58vo845cFClqjxcnObbfdxh133ME999zTZMY1ZMiQZr5TaC9RPSIwWvTUOF0NRv5+VOt0YTAbiOoREYToTp+iKGz4bCsr3lpT12ciIGMwGxg2fSDn3Xo2bz3+IZn7jhGbHIXmZ6OWNc5aNn6+jcR+8cy+ZlrwXkAn4DlR3rQ5ao0ar7trJ8PdhSRJXHjXuUT3iOSHDzdSlF2MokBkjwimLBrHjMsntftsZXuQZZmC7GKM5qYbB/84Y1CaV9Em1+s5uAfbvtuLHJAb3FT6vX4qSxyU5JYTGRdG9v5cklIT2mwGNm3zEd566gs8Li+R8aFotBrkgIyjrJqvXl+DSq1i/rXTTvl8KpWKi/8wn+RBiaz/dOuJpqJqxp4znCkLx9B/9E+z9Rl7c1jz6TZMVkODoiJGs4HaKhdblu1hxPRUhk4WN9PBctYVU0jfnEF+ZhGhUXaMVgN+b6C+Ouk5183AEiJmdrorSengAgVdqxAsAH/729947bXX+M1vftNm52xxsnPJJZcAcN1119U/JkmSKFAQRNE9Ihg0oS9bvt2N0WJoMHrv9wVwlFUxbt6ITlOCuqVWvLWGj577EkWBkCgbGo2aGqeLdR9v4eDWDCqKHITHhDZIdADMNhM1lbWs/Xgz0y+b2O6zO51Zj/5x7F13sMl9IIqi4HX7SBoQ3MaJwk9UKhVTL57ApIVjKTlehiIrRCSEden3sCRJ6Aw6PK6TF1fQtlG/mNGzh7Di7XUU55QRnRyBJElUFFaSf6QAV40bSZI4uieLp69ZwohZg7nykUXNJmKnSlEUvnt3I65qN7HJkfW/ayq1itAoG+VFDn74eBtTzx/d5MBUc1QqFePOGc7Ys4fhdftQqVVNLkfbvjINd62H8CaWNJusRipLq9i6fK9IdoIotlcUN//9aj75x7cc2ZmJo7QKtVZNVGI4s6+awqQLxgQ7REEIKr1ez8SJbVtQq8XJTlZWVpsGILSNhbedTWF2CTkH89Gb9OiNWjwuH+4aD0kD4ll465xgh9gqFcUOvv7P92i0asJ/tiHeHmHFbDeRuScbOaAQ08wyC2uYhbL8ckqPlxPbq3NXXWpPo+cM44cPN1Ne6CA8NqTBMUdJFQaTnrFnDw9OcEKz6krSds1iBL8kSRKjZg7kmzfXIstyo70frho3Wp2GgWPbZl9hWEwIVz+ykDce/4i8jCLkQIDS3NL6JsBxvWIIi7FT46hl4+fbUWtUXPeny07rmqX5FWQfOI493NLkTJE93EpRbinp2zMZc1bLN/lLktRsA2Ooa0Cq0aqbnaXS6bUU5Za1+LptwevxkXswn4A/QExyZJP9u84UiX3juP2f15GXUUhpXjkGs4GUoUktKiIhdFHKia+OvF4Xc8cdd/Diiy/ywgsvtNk5W/yblZSU1GYXF9pOZHwYd7xwHWs/3cqmr3bgqnZjj7Ay95qpTLlgTIMqbV3J7lVpVJVVNZmoaLRqdAYdFcWVyLKCWt34A16RFSQkJFXwiwQEU2LfWM6/eTYfv7CM/IwiTHYjEhI1zlq0ei3zfjuD3sOTgx2m0M1NnD+CrSvSKDhWSmRcKDq9FkVRqK1yU1HiZOjkfvRtw/fhkMkDuPfVG9n09S4+f/FbVJJEZHIUodH2ulkcScISYkaRFXZ8t5c5v5lOfO+YVl/PXevB75cxNdMzTK2pS/A8Lm+rr3EyFpuJgL/5fUg+XwCzvWN7fsmyzOr3N7Lq/Y2U5tVVhzPbjIyeM5Rzf38W1lDLr5+kG5IkiYQ+saI5sCD8wtatW1m1ahVfffUVAwcObLRd5pNPPmnxOVs1jHD06FGef/550tPTAUhNTeWOO+4gJaV7VvrqKkKibCy4cRbzrp9e3+SyK67t/zlHqRMkqcmeBADWMDMVxQ6qy6uxN9Ht21lWRWL/eCK76BK+tjTjsolEJ0ey7pOtHNqRCQoMmzaQSReMZuiUAZ2iapzQvcX0iOB3f7yI/z39OflZJSiKgqIo6I06Rs0YyJX3ndvm1b5ikqOYedlEVr+zFoNFj9ft51h6PoqioDPoCIu2ERJpozCrmINbjtQnOwWZxRzPKECjUZMyNOmUZiJCo+wYzXpc1e4mZ2A8Li9qjZrwmJA2fY0/GjZ1AFu+29tkk2Of148SkBnZwY1UP/vncr59bTUqtQp7hBWVWkVNZQ0r3l5H7uECbnvhWkzNlGIWBOHMExISwsKFC9v0nC1OdpYvX86CBQsYNmxY/Zq6DRs2MHDgQL788kvOOuusNg1QaDm1Rt1tPjzMdhMoCrKsoGpmdsYaZsZZVoXBrEdvquv2rSgKzrIqAKZdMqHLJ31tZeD4vgwc35eAP4CiKGiaGYEWhPaSMjiRh177Pfs3Z5CfVYxGq6bviJ4k9Yttt4Tb5/FR43RRVuio+1uiVqFSSbiqXRyvdlFVWYtWo8Ln8VNWUMGHf/uSA5sOU1tVt7fHFm5h/LmjOO+ms07aq8xiNzFq5kC+/2AzlhBzg/2TiqxQVlhJj36x9BuR3C6vc/DEvvQf1ZP9mzIIibDWz+LUVrmpKHaSMiSRkTMHtcu1m5J3pIBV723AaNY3GIwKibJjsps4vD2TTV/uYOblkzosJkEQOrfXX3+9zc/Z4jud+++/n8WLF/PUU081evy+++4TyY7QpobPGMQXLy3HUeIkNLrhpttAQKa2ys05N8yi+Fgp6VuOIPsDqDRqAr4ARouBudfPYPKicUGKvvMSyZ8QTFqdhmFT+jNsSsdslNeb9DgravB6vFjsPxUG0GjVBAIylcVOLDYD1jALL9/1FplpOYRE2oiLsiPLCs7SKpa9vpqq8mqu/ePFJ03Kzr5qMkfTcsnafxyTxYjBrMfn8VNVWUNolI2Lbz+73X7/dHotN/zxIt7969ekbT6CI6sEAINJx9DJ/bnivnMx2zpuIGznqjRqq1zEpTRehqzTa1FrVGz8crtIdgRBaFctTnbS09P58MMPGz1+3XXX8fzzz7dFTIJQLyI+nJlXTOarV76jNC9ASKQNtVZNrdNFRVEl8b1jmHvtDEKibOxbm87u1WnUOGuJSoxg9Nzh9BzcQyzPEoQz3MFtmWgMetTVbgL+QINkQ6WSCPj8yEBlWRXZB3KJSYqsr+6oVkuERtvR6rVs/24PUy8cS8rQ5GavFRJp49anL2fl0s1sWb4XV7UHjVbNhHOGMfPicSQPiG/X12oNtXDjXy4h72gRWfuPoygKiX1jSeof1+F/C51l1UDzvTH0Jj3lhZVNVokUhG5JFCj4VT179jzp34PMzMwWn7PFyU5kZCS7d++mT58+DR7fvXs3UVHdo2qQ0Lmce9NsDCY9K99dR8nxMgJ+GaNFz9BpA7n4nvPq9+OMmDWEEbNEnydBEBoqzCnFFGZDrZZwFjvwS37UWjWyLBPwBdAZddhjwtn67S40Wk2jMvYAZrsRR4mD3T8cOGmyA3UJz6KbZzPvmqlUVdZgMOuxdnDvlPiUaOKbmFHpSGa7CaDZZMbr9hEWbReJjiAI9e68884G/+/z+di1axfLli3jnnvuadU5W5zs3HDDDfzud78jMzOTCRMmAHV7dp5++mnuuuuuVgUhCCejVquZe90Mpl48niM7s/C6fUQnRZDQt+NHKgVBaKiyxMGulWlUFFZitBoYMjWV+N6dq8KUVqdBUkkkDUmmPK+csuOl+Nw+VGo1YXHh6K0mDBYD1RU1zfb5kSQJJInqipP3Cfo5g1mPwaxvq5fR5Qydmsp3b66hurK2UV8hvy+Az+Nj3LkjgxSdIASBmNn5VXfccUeTjy9ZsoTt27e36pwtTnYeeeQRrFYrf/vb33jggQcAiIuL4/HHH+f2229vVRBC5+fz+tm/8RAluWXoDFoGjOtDVGJEh8ZgtBgZMiW1Q6/Znbhq3DhKnBjMekIiGzcdPBPk55Sxdd1hMg4VoFGrSB3ag9GT+xIafmaWvz0diqKw5sONfPbPb3GWVoEEigxf/WsFExaM4uJ7z+s0TVD7jeiJ3qjDU+slKjmKyKRIZH8ASaVCUknkZ5YwbFQvKvJKydyb0+Q5fqwc11XL+AdD8sAExs0fwZqlm/B5fdjDT1Rjc9TiKK0iKTWBiQtG1T9fURRyD+bjLKvCHGImeWCCGNASBAGAs88+mwceeKBVBQxanOxIksTixYtZvHgxVVV11a6s1jO3OdiZ4ODWDN598lMKMouQZQUUBZPNyPhzR3Lh4vknrU4kBJ+j1Ml3b61h85fbcVW5UGvU9B/bh9nXTKPPiF7BDq/DbFqdzgevraPa6UKjVaMoCmm7clj1zV6uv3M2fVLjgh1il7JjxV7ef/ozgPo+WM7yaiqLHXy2ZBklx8u5+R/XomtmpqQjJQ2IY/CEvmxbsQ9JJWG0GFBrNQT8MiXHyzHZDExbNIbCzCIydmXjdXsb/V1zlldjshoZPrPlzUDPVJIkcdn952MJNbP+060U5ZSiyAomq4FRZw3h4j+cW1/S+9C2o3z+0jKy03LxenxodVp6pMaz4PezGTihX7vFmJmWy6ZvdnNwRxaSBANGpzD+7GEkp/60t0qWZQ5uz8JZUUNC72gSgrw8UBDORB999BFhYWG//sQmtDjZcblcKIqCyWTCarVy7NgxXn31VVJTU5k9e3arghA6r5z0PP5z39tUllYRER+GzqBFlhWqyqtY+c56An6Zqx65MNhhCs1wlDp58db/cnR3NiarEZPNhM/rZ/t3uzm0/Si/ffKKM2K2LDujiPdfXYvP6yeuR1j9aLEsyxTmVfL6Cyt44JmLsXZgpaquTJZlVrz1Az6Pj7iUGFw1bnIPFeCucaMoEPAH+P6ddZTklfP7Z68msV9wE0lJkrjq/nNRZJl9m45QXuysfw+ERtq46I659DtR/nr7ir3s33gYs82IJcRUX43N7wsw5zdTSezbuZbodXZanYaFt53NWVdOJmP3MQI+P3EpMQ0qtB3ekcnLf3gTZ2k1oTF2Qox2vC4vGTuz+Ne9/+N3T13JoEltX7lv3ec7WPriMmqcLown2has/GATm5ft4bK75zFu7lC+fmMtn/x7FaWFjrpy/Ro1vVLj+d0TC+k7LLnNYxKEM93w4cMbzOgqikJhYSElJSW89NJLrTpni5Od8847j4ULF/L73/+eyspKxowZg06no7S0lOeee46bbrqpVYEIndOq99dTXlRJfO9YpBN9blQqCXuEDUmS2PL1TmZePom4lNZ3HRfaz3dv/sDR3dnEJEfVb7o2AtZQMwVZxXzwzOf0H9unU4y+t6eNq9KpqXI3SHQAVCoV0XEhFOZVsnNTBlPniFH7U1GUXULuwXxCIu34fX5y0vNx13jQGbSo1CoURcFd6yFz7zH+dc//uPf1m0+pKWd7MttM/P7JSzm6L5cDW4/idXmJSghj+LTU+v0kBrOB3z9zJV/++3u2LdtNeaEDlUoiPD6UaReNZ/qlE8WyqlayhloY3kRDU0VR+PylZThLq4nrHV3/8zVajRgsBgoyi/j8pWUMGN8XdTPNpVsj93ABH724nIAvQHyvqPrrKopCSV4FH/z9G/ZvPcqXb6zD75fR6dWoVSp8PpmDu7J5/Op/8cT/fk+foUltFpMgCHD++ec3+H+VSkVkZCTTpk2jf//WDXq0ONnZuXMnf//734G6KaWYmBh27drFxx9/zKOPPiqSnW7EXethzw8HsISY6xOdn7OGWcg/WkTahkMi2emEXDVuNn+1A5PV2Ki6lCRJRMSHUZRdTNr6g4zo5ktzDu47jsGobfJG9ccbqMxDhSLZOUVejw85IKPWqHCUVOGu9aA36ur/TkiShCRJhETayM8sYtvyPZ2il4okSfQe0oPeQ3o0+xyz3cSl9yxg3m9nUphVjFqrJqFvbNAGBHLS89jyzU5yDuWhN+oZPKk/o2YPra901tUdP1xA1r4cQpuoyiZJEmExIeQeKiBr7zF6D+/ZZtfdvGwPNc5a4n6W6Px4zcj4UHKPFPLlG+sIBGTMVh2SVPd3Qq0FORDAWVnDa3/6jCeXNr2ZWhCaIil1Xx15va7msccea/NztjjZqa2trd+j891337Fw4UJUKhXjxo3j2LFjbR6gEDxelxe/z99kGVao+1BQSRKeWk8HRyacCkeJE1eVC5Ot6ZsinV6LIiuUF1R0cGQdT1G64F/8TiwiPgyz3USN04Wz/EQvlZ8NiAQCASSpbm+Mzxdg75oDnSLZaQlrqBlraNvdXLeUoiis+N9avnj5O2octWj1GuSAzK6V+1j13npu/OtV3WKQyVlWhc/tJySq6b2feqOeck8lVRXVbXrdo/ty0eqbHgCRJAlXrRev14/ZYqhPdH6kUqtRa9Qc3pNDcV45UfGt20cgCELHaPGccO/evfnss8/Izc1l+fLl9ft0iouLsdlElZruxGw3YQu34qp2N3nc7wugoBAeJ/7Qd0Z6kx61Ro3P62/yuByQURSlydK4iqJQkFlE5t5jVBRVtnOk7a//4ATcLl+TSU8gIAPQs2/Xv3HsKGabiTHzRlDrrMXv8zdaX+1z+zDZjJjtJtRqFV63N4jRdk371h/k0xe/RVEU4vvEEJ0USWyvaKKSIsk5lM+rD73X7O92V2INtaDRa/C4mn6PeNxetHoNZnvb9ilSa1QocvODIH6fXP+8pmg0Kvy+AIXHSts0LkE4U6lUKtRq9Um/NJoWz9EArZjZefTRR7n88stZvHgxM2fOZPz48UDdLM/w4cNbFYTQOak1aiadP4alz33ZqDqRoiiU5ZUTHhvK0Gndf4N7VxQaZaf/2D5s/2431lBzoxFMR6kTa5iFgRMbroFNW5/Ot6+uImtfDn5/AL1Rx7DpA5l/42yikyI78iW0mQkzUtmy7jClxVWERViorqjBWVaN3+/H61eI7RHOyPEpwQ6zSznntzPJTsth27Ld+Lx+VGoJFOrfM/G9Y1AAn8dHj/7xv3o+oaF1H2/G6/IS17thEq7RqolKDCcnPY/9Gw8xbFrjfTBdSWL/OJIHJnJo+1GMFkOjxLm8oJLk1ARS2rgYwMCxfTi4IwtZllGpGiY0ckBGkuoaocoBGVUTe4XkgIxKJRESIarRCi0g+uw069NPP2322KZNm3jhhReQZblV527xzM6FF15ITk4O27dvZ9myZfWPz5w5s34vj9B9TL14PKnj+1KSW0ZpXjmuKhdV5dUUHC1Cb9Jx0d3nYm5mmZQQfGddPRVrqJWCrCJ8Hh9Q9yFdUVSJq9rDtEsmEBr1U8+dnd/v5ZW73yJ9yxEMFj2hUXXr6Nd9vIUXbvkvxTklwXopp6Vnn2guuW4yapXEge1ZZOw/TnFBJeWl1dSWV+FMz2bN+xvEcrcWsIZauPWF61hw81x0Bi1+XwCVRkVUYgS9hiRhtBqpLHZgtBoZO29EsMPtUrweH0d2ZmEOaWYJqkGHHJDJ2tv1l45LksSCm2bXFU05WoSr2o0sy7hr3BRkFmOyGjjvljltWpwAYMzswUTEhlB4rIyA/6cbqIA/QMGxUhJTotDr1Hg8jWfPFEXG5wsQ3zOSHqI6nyC0ifPOO6/RV//+/XnjjTd49tlnueiiizh06FCrzt2qvx4xMTEMHz68wWjImDFjWl0lQei8TFYjNz13DeffMhf7iSVtAX+AYdMHcfNzv2H0nGHBDlE4ib4jU/jtU1cQkxxNaV45+UcLKcgqRq1RM//GWSy4eW79c71uLx///SvctW7iUqIx20zoDFrsEVbieseQd6SAb19bFcRXc3omTB9AgkWFqqoai0FNiFVHQriR/olWjGr44qVlbP1mZ7DDPCU+r59Du7LZt/EIBdnBS0DNdjNXP3ZR/f4Re4QNs92Eu8ZD/tFCAr4A8383i56Dmy8IIDThFJJu5dSe1iUMGNuHG5+5ipRhyVRX1lCYVUxVeTU9ByVyw1PtUx4/Ii6U6x5dVJfw5JSSl1lMXmYxRTllRCeGc8tfr2DMjFSUgIyrxlO/7Nfv81NT5UGn13DJ7XPaPC6he/uxQEFHfnVF+fn53HDDDQwePBi/38/u3bt58803SUpqXfXDU17GtnDhwlN63ieffNKqQITOy2wzseDmOcy9bjqVJU50Bh0hkWJ/VlcxZEoq/cf0Jm3DIcryyzGYDQya1L/BjA7AgU2HKTpWQkR8WKMlb2q1CmuYhZ3f7+WC28/BFtb1lm7kHMzj2K5MEiMMWH4xYq6PtpOfWciq9zcw5pwRnba8sKIobPhqFyve20hxXgUBfwCDUUe/UT1Z+PtZxCYHZ5nh3GunE98nlnUfb+bIziwAhk8fxJQLxzF48oBO+/PsrHQGHT0H92Dv2gPYIxr/rfW6fajVKpIGJgQhuvaROr4v/cf2JjstF2d5NdYQM8mDe7T5jM7P9RvZkwdfu5Htq9LI2n8cSZJIGZTIiBkDsdhN3PXP36C64y22rDyAq9aLooBKAnuIiavuncfkBSPbLTZBOBM5HA7+8pe/8OKLLzJs2DBWrlzJ5MmTT/u8p5zs2O32X3+S0K3pDDqiEiOCHYbQCjqD7lfLS1cWO5BlBW0zJXYNZj1V5dU4y6q7ZLKTsTMLd42bsNiQJo/bwqwcP5RPeWEl4bGhHRvcKVq1dAsfL1mBoiiERNrQaNXUVrvZ9UM6hdml3PbsFUQldHzBEEmSGDJ5AEMmD6jfNK9tpoqjcGqmLBpL+uYjVBY7sEfa6hPGgD9ASW4pPQYkMHjygCBH2bZUKhW9hnRs3xprqJnpi8YyfdHYRsd0ei33vnI9BVnFrP54K9VOF/G9oph5yTgMxsaFXQRBaL1nnnmGp59+mpiYGN577z3OO++8Njv3KX8avf766212UUEQOp8fS1QH/AHUGnWj4z63D41Og8lq6OjQ2oQsyyDR7CyDSlXXDFMOtG4DZHurqqjh2/+tR6VWEf6zhM1iN2GyGCjIKmHVR1u49M6zgxckIslpK8OmD2Le72ay7LXV5GcUojPoCPgDBPwB4lKiue5Pl3b7ZsCdRWzPKC7/w/xghyEI3dr999+P0Wikd+/evPnmm7z55ptNPq81K8jEp5IgCAAMnNCX0Gg7FYWVRCSENzimKAqOUiej5w4nLKZzznr8msR+cWh1WlzVboyWxglbVUU1sb2iCYsJ6fjgTsHejYdxlFUR3cTsqkqtwmQzsn3lfs6/YUaT5cSFrkWSJOb/7iwGjOnD5q93kHMwH71Rx9CpqYyeO6zJ5W2CIAhd1dVXX91uS55FsiMIAlC32XzudTNY+uwXlBwvIzTKjkanwV3roSy/nJAoO3OunR7sMFut76gUkgf34PD2o8T2jGowe1XjrCXgl5m0cGyTs1qnS1EUio6V4q71EBZtxxbe8mWA1RW1SEjN9v3QG7V4XD5qqlwdmuwE/AH2bzrM9u/2Ul5QQUiUjZGzhjBoUn8xy3OaJEmi9/Ce9B4evOamgiC0IVF6ullvvPFGu51bfBIJglBv1pVTUKlULHt9FcW5ZSiyjEavpeegHlz0hwWkDE0OdoitplKp+M0Tl/DS4tc5frgArU5Tn8yp1SomnDeK6ZdObPPrpm04xLI3fiB7fy4BXwCDWc+IWYM55/oZLdobZAk1oaAQ8MtNJjwelw+dQYvZamzL8E/K6/byxuNL2f7dXgJePxqdBr8vwJZvdjN0airX/ekSTB0YjyAIgiD8kkh2BEGoJ0kSM6+YzITzR3NwyxFc1W7CYkLoM7IXanXbz3h0tNhe0fzh1ZvZ/NUOti/fTY3TRVxKNOPmj2L4jEFtPquz7bs9vPXER7iq3dgjrWi0GlzVbla/v5Gje45x2wvXnnLCM2RCX+xhVipLnA327EBd76Rap4vx5wzt0Fmdb/67is1f7SQ02t4gqXHXeNj5/V7CYuxc/sAFHRaPIAiCIPySSHYEQWjEaDYwfMbJq7d1VfYIG3N+M505v2nfJXnuGjefvPAtHpeX2F5R9WuR9UYd1lAzOel5rHh7HZfes+CUzmcNNXP21ZP4eMkKio+XExJhra/G5iipIiY5gpkXjWvPl9RAbZWL9Z9vw2g2NJq9MZj1mEPMbP12N2dfP6NRmXNBEARB6CjtV8BeEAThDJa28TClx8uJiAtt3LdIo8ZsN7F9+R5c1e5TPueMi8Zy+R/mERkfSmWJk6LcMnxuH8OnD+CWpy/r0LLTuYfycZZWYw0zN3ncGmahqrKGYweOd1hMgiAIgvBLYmZHEAShHVQUOQDQNLNJ32DWU1vlwllW1WR1uKZIksSkc0cwds4QMvcfx+vyEREXErRmoqBAM9VzpBOHlS60QVYQBKFdiQIFQSGSHUEQhHZgshrq+/aomugC7/P40Gg1GFuxgV+r09BveHIbRNl6CX1isYZZqSqvbrJcd1V5NZYQM0kD4js+OEEQBEE4QSxjEwShWwv4A9RUuQj4Ax163UET+2MNM1NZ4mx0TFEUnOXVDJ7UD1uYpUPjaitmu4kJC0biqnY3WorncXmpqqxh1OwhnbZvkSAIQkeTgvAliJkdQRC6qfJiB2s+38HWFWm4ajyYLAbGzh7M1PNGEhLR8j43LWWPsDLrisl8/tJ3lBVUEBJpQ61R4671UF5QSWiUnVlXTG73ONrTvBtmUnSshF2r9lNR5ECr1+Dz+pEkiaFTUll4+9nBDlFoRzWOWnZ8v49jB3JBkug1uAfDZwwS5cYFQehURLIjCEK3U3y8nJce+pDjGUUYzHp0Bi3O8mq+fH0Ne9Yf4ua/XELEL8o3t4e5105HpVax8t0NFOWUggIarZrk1AQuuns+yQMT2z2G9mQw6fnd01ewd206W5ftpuxEEjdq9hCGTUtFZ9AFO0ShnRzekcnrj31ISW4ZiqKgKAprlm5m2Rs/cP2fLu2U721F8YLiBcmEJAVvYUve0SJ2rEqjrKASs9XIoIl96TeyF+omlrsK3YzYsxMUItkRuiVFUTh+uIDstFwURaHn4B4k9I2tr4rlLK8ma98xAn6ZhD6xRPWICHLEQlv65JWVHM8oIiYp/KfeOSEmAv4AOYcL+ew/q/nto+3f/0WtVnH2tdOZsnAs6Vsz8NR6CI8Npc+Inm3e0ydYNFoNI2YOZsTM7lmqXGisrKCCVx96n7LCCqKTIurfy36fn/yjRfznwfe47/WbO80STcWfjeL6CrwbAR+oIsFwFujnIKlMHReHovDVq6tZ8c56apwuVCoJWVZYvXQzQyb155pHLhCzYoLQDkSyI3Q7lSVO3vnTx+zfeBh3Td1eAoNZz8AJ/bjoD+ey9uMtbPx8G47SKlAUTDYjQ6akcuFd80U/kG6g4FgpB7ZnYo+wNEoo1Bo1tjAz+zYfoSS/gsi4U2voebrMdhOjzhrSIdcShPa25etdlOaVE5sShUr102yERqshJjmSwqxitn+3hxmXTgxilHUU3z4U59MgF4NkBUkLgVyU6n+BdydYH+iwhGfjVzv5+tUf0Bu1xKdE1w++1Va72b5yHyabgWseXtghsQjCmUQkO0K34q718K8/vEX6lgxCo2yExdQlLzWOWrYt383uH/bj9/kx2UxEJ0UgqSRqKmvZ+MU2SnLLuOOl32K2d9xIn9D2io+X4671YI+wEPAH8Hv9qNQqtHotUFclrSSvgpK8jkt2TkVxbinbvt1FQVYxBrOe1PH9GDy5P1qdNtihdXmKopC+I5stK/dTcKwUk1nPsEl9GTVtABbx+95iaRsPotFpGiQ6P1Jr1KhUEgc2Hwl6sqMoXpTqJSCXgjoJ6peu2UFxg3cruL8A06XtHkvAH2D10s0oikxIpK3BMZPFgD/Mwo5V+zn7mqlEJYa3ezxCkIhlbEEhkh2hW9m1Mo3DOzKJ7hGBzvDTTaIlxIzPFyBzTzaxKdENKkRZwywYLAYy9mSz+eudzLx8UhAiF9qKVqdBCSjkHcqnqsRZV4VNAmuYlcikSLQGXV3y00z/m2BY8+FGPn7+a6rKq5FUEoos88P7G+gzshe/e+YqQqNDgh1ilyXLMh+9soo1X+zE6/Gj02vx+wLs357F2i93c+Nj5xMtbi5bxOf1o1I3X+dJUqnwe/0dGFEzvDvBnwvqmJ8lOidIBpAMKO4VYFyIJLXv/rLi3DIKs0uxhTVdHMUaYiY/q5iMPcdEsiMIbUzshhO6lZ3f70VRaJDo/MhV5UJRwFPrbXRMq9Og0ajZ8vWOjghTaEcRMXaqiisozirC7/ej0qiQJInKokqydmdRmFVEZGwoSf1jgx0qAGnr0/ngmc/xub3E944hvncMCX3jCIsNJX3LEV576D1kWQ52mF3Wpu/SWPXJdvRGPXHJkUTEhhDTI5yohDByMgp589lvCATEz7clUoYk43X5UJroGKsoCn6fn56DOkGBgkA+IIOkb/q4ZAG5AuTy9g8lIKMoSvNJ4omHA37xXuzOROnp4Og8Q5uC0AaqKmvQapve+O33+UGCgK/pfis6o5bKkqr2DE/oAGs/3QqyjFqrQVKpUKvVoKlbXuOqclGRX84V9y5Ap+8cy8N++HAj7ho38X0aJl96o46IuDAO7zjKkZ1Z9BuVEqQIuy5Zlln35S4UwBrScLmaRqMmPNpO9sECjuzNoX+Qm7R2VllpOWz5eifZB46jN+gYMmUAgyb2ZcPn2ygvrCQ89qeloIqiUJpXji3Uwpi5w4MY9QmSDlBAkRvP7ADgr3u8nWd1ACLjw7CHW3GUVWEwNU6+XNVu9EYd8b2j2z0WQTjTiGRH6FaikyI5vC2jyWNanRZkBZ2x6ZtcT62XxH5x7RneGc9V42bP6v3kpB9HpVbRa2hym+5Lcdd42PLNbsLjQvF7A5QWVOJ2/TSTp9FrMRh1hEd2jipRrmoXh7dnYgltOh6DWU95QQUZOzNFstMKzvIaCnLKmt2XYzDpKS92cuxwoUh2fkFRFL57cw1fvLycWqcLnV5LICCzd106cSnRTF40hrUfbSEvoxCjxYCiKLhrPJhtJi6+51xie0UF+yWAdghIZlCcIIU0PKYoIDtANw6k9t+7pzfqmDB/BJ+9sgJ3jQeD+aeEJ+APUFHkJHVcb3oOTGj3WAThTCOSHaFbGTN3GJu/3EF1ZQ2WEHODY1q9BpVGhd7YeFTN6/YiyzLj5o3sqFC7BEVRyMssJudIEZIEvVLjW7S/oeR4GccP56NS1y0l++CZzynMLEI+sfxFrVbRIzWBG566kthepz+iWVnqpLbahclqxGgxEBplw1lejd8XQKNVYwuzUJZfQXlh5Wlfqy3IJ5a2NNdfQ5IkkCSxtKW1TlS7oonlVnUPKyeeJhZ7/NL+DYf47MVvUalVxPeOqf8ZBfwB8jMK0WjU3PS3q9i2bA8Htx1FkiTGzRvBxPNG02twjyBHX0fS9EDRTwH3N4AEkq3uPaEEQC6q67djXNBh//6zLp9AzuF8dq9JhxIwmHT4PH58Xj9xvaOYcv4oMvceIzIxotOU7RbamChQEBQi2RG6lQHj+jBp4Rh++GAjtU4X1hMfGFXl1fj9AQaO70dZYQWlx8uwRVhRqVRUV9ZQXVnLwAl9GXNOJ1h60UmUFzt57x/LObgzG3etB6irGjR0Qh8uvvWsk1axcpQ6+ejvX7F79X5qnS7kgExliQONVk2vQT3QGeuWjXjdPrL2HuOVu9/kvrduO+0eEwajHrVGXbdkkbq9WxE/q7j2Y3LRVMIbDCabidieUWTuPYY1zIIckKmurCHgD6DRadHptahUEvF9YoIdapdkDzOTkBJFxr7cJt+v7lovOr2Gnv3FjO4vrf14Mx5X3T6yn1Nr1ET3iOB4RgG1Dhe/eeLiIEV4aiTL71DwgWcDyMeo38WgikAyX4+kG9FhsRhMen77fxez4/s0Nn69k5Lj5ZjijYSGWyjMKuLVh95DlhXMNiOjZg9l/u9miaRHENqASHaEbkWlUnH5AxcQ2zOaNUs3UppXt/E0KimCKReOZ+pF41j13gZ++HATFYUVKIqC2W7mrKsmc97NczGaDUF+BR3P6/aSk55HwC8TnRxJSKSN2mo3/378EzLSjhMSYSE0ygoKVDtdbFy+j2qHi5v+dGGTFc1qq1y8fPdbHNp2FFu4hZheURRnl+B1+fD7AhQeKyWxX12DV51BS0xyFLmH8tm1ch8Tzx9zWq8lJMpGv5G92LEyDUuIudGIraOsCkuImYHj+pzWddqKJElMuWg8mftyyD9aiKO0Cq/LWzfjIIGERK8hSQyekhrsULskSZKYMn84mfvzcJRVYwv76T3h8/opL3IwcHRPeg8WS4d+LuAPcHhHJmbbT4MPfl8AR0UttdVuZAU81R7Stx5h9NxhwQv0FEiSESx3g/F88O6oKzmtjgbdeCRVx/dV0+m1jJ83nPHz6gbWvvrP93z5ygqQJOwRVtRqFTWOWr5/Zx25h/K59fnfiHYI3YkCkpjZ6XAi2RG6HbVGzawrJzP14vGU5JYCEJkYUX9jPvfa6Uy/dCLHDhxHDsjEpURjC2+6HGhHUBSFo3uyyU7LRZIkkgcl0mtIUrsvrZBlmVXvbWD1+xsozStHkRWMVgOjZg8lunccmQfyiEoI/Smhkeo2eev0GvZvzyRt61GGT+rX6LxbvtnFkR2ZRCdF1Pe2qa6sQaPToNaqcZQ6CYsJwXJiw7hGpwFFIW3DwdNOdgDOumISR3ZlUZhdQkRcGFq9Bjkg4yyrxlXtZt510wmN7jzNY8efO4o1Szex8bOtyLKCTq9BklQE/AEUCWqqXGTszCR1fOOftfDrxsxMpeh4OSs+3EJ+dgkarQbZHwBJovegBK7+wzyxjO1X1FZ7yM0qxevxnXhEwuf1serj7QybOYQhEzv3e1OSJND0rvvqRIqOlfDdW2vRGXQN/iaFRNkx200c3pHJxi+2c9ZVU4IYpSB0fSLZEbotrU5DXErTy3/0Rh19R/bq4IgaK80r483HPuTIzsy6Ef0TsfUbncLVj1/SoNJRW/vsn8v49tVVqDVq7JE21GoV1Y5aVr23AUWlQhsW0uTMjd6oQw7I7F5/uMlkZ+u3u1Bp1PWJDoAsK0hS3R4dv8d3Yoblp9FKlVqFr/5G6vT0HdGTax+/iA///g3FuaV1xZgUBUuIiXnXTWfBjbPa5DptJRCQqamsITQmFFBwVbtRq1XYI22ERtspzSvnq3+tYMC4vuKmvBUkSeLcayYxeGwKW1ftpzCnDKNZz5DxfRg2sU+TlbHOdGqNmr6jUti+bDeWUAu5WaV4PD70Bi2SVNcHSpEDBGSZN//0Kfe8cj0xSZHBDvtXOUqr2LZiL/vWH8Ln8dFjQDzj5g4jOUhFAXat2k+No5a4JvYravVatDoNG77YzqwrJ4vf/e5C7NkJCpHsCEKQ1Fa5eOXuNzm6O5uw2FAi4sMAcFW52bPmAK/c9QZ3/femdllal3ekgFXvrcdoMWD/WTfvkEgbZpuR9K1Hsak1QNMVldSaur1OTakscTbqc2S0GHBVueo33P+4pwZAkRX8vkCbVsIbOmUAA8aksG/jYcoLKzEY9Qyc0IewTtic8/D2o5TklhHfO6bJ/lAhUXay03LIyygkoU/n6A3U1UiSRM8BcfQcIPbmnKopC8eyb+0B8rJLGiY6ioLH5cVoMZDUP46C7FI2f7uH83/fuQYRfulYeh7/fvB9CrNLUGtUqNQqDu3IZMPn21lw4yzOuqLjm0k7yupaHUiqphMZvUmPo8SJ3xfoVE2QBaGrEU1FBSFIdny3h8y9OUQnR2GyGnFVuynILKIwuxiv20fahoNs/nJ7u1x758p91Dpd2CIaL9/T6rVo9Rqqiiqa/N66poFyg43/PxceG4LX1bBxa2hMCCq1Cq/Hh6JQ/8GtKApl+eXYwiyMObttNwrrDDpGzhjEWZdPYvIFoztlogNQ46itu5nRN30zozPo8Hn91DprOzgy4Uw2cGI/LrjtHDxuP36vH5/bh6fWg6fWg8Gkp0f/eNRqNTq9lgNbmi7331l4XF5ee2wphdnFxCRHEJMcSVRiOHEp0SgofPbSd+zfdLjD4zLZjPUzz03xenyYbEY0zfSOEwTh1IhkRxCCZNeqfUgSaLRqinNKObo7m+KcUqoqqqkqq6Ky2MnrD79P0bGSNr+2s7waaL7krj3cSsDnp6bK1ehYtcOFwahl1LQBTX7v2HNGIMt1o78/stjNRPWIwO8PIPsDqNQqKooc5GcUolKrWHTXuW1SerorComyozVoG/y8fs5d40Fn0BHysxk4QWhvkiQx+5qpDJ85GEuoGZPNiDXMQkKfWFKG98RoqZtxllQSgUDnLo2+Z206+UeLiOoRgVrzU+IgSRJh0SF4XF7Wf94+A0snM3RqKkaLnuqKxrPkAX8Ab62HcfNHiiVsgnCaRLIjCEFSXVmLRqfBWVZFYXYxUNdEUm/UYzAb0Oo0VJY6efXBdwn4A216beuJHkTNjShqtGrCY0NxltXUNeas9eKu9VCcV0GNo5bJ84fTe3Bik987eu4wBo7vS2luGRVFDvxeP16PD7VGQ0iElZ5DEjFZDWh0GsafO4rblvyWqReNb9PX15X0Hp5MQp9YyvMrGv17yHJdye7U8X2J6tH590QI3c/QKf2xhpjpNaQHvQb3ICI+DO2JmQZFUfC6vPQelhTkKE8u+8BxZFludimYyWbk0I5MZLljk7bEvrGMP3cUVRU1lBdV1hUlURRqHLUUZBWT0DeOSeeN7tCYBKE7EotABSFIYntFcWRnJtUVNciygsGkqz+mKAqKohASZiNrXw7pmw8zaFLTMymtMWRqKsve+IHqipr6XkQ/8vv8+Dw+Ft1+DlqrmXVf76aytAoJiI4PZcqCEUw9r/nRRoNJz43PXsUXL33H1m93UZZfDidGUBfcNJvZ10yte6IEarVYnqFWq1m0eD7/vuct8o4UEBodgs6gxV3jobLESWRiOOfeNCfYYQpnqNGzBrPy/U0UH68gOjGs/vdeURTKCisx2YyM7/Tlp39lZkQJTmNZSZK4+A/nYrIZWP/pNoqOlaIoCgaznmFTB3LxH87tVJUjhTYgChQEhUh2BCFIxs4byaYvtlOWV95oTXbAV7fUKyIhDEepk8y9OW2a7CSlJjDhvFGsfn8DPo8PW8RP1dgcJU56Dkpk6oXjsIVbmbFwNMV5dQlLdELYKW2UNdtMXHb/+cy7YSb5R4tQqVUk9o87I/sYnYqBE/px8/PX8vW/V5CxO5vqyhp0Bi1jzh7O/N/Ppkf/+GCHKJyhIuJCueK+BfzvL5+Rl1mM3qBDkur2wZhsRi68bS7JqZ37/ZmcGn+i4qO/yb1xNc5axs4dhkrV8YtdtDoNF9x6NjMvn0zGrmz8Pj8xPaNI7Bsrlq8JHe7JJ5/kk08+4eDBgxiNRiZMmMDTTz9Nv34/VV51u93cfffdvP/++3g8HubMmcNLL71EdPRPS9FzcnK46aabWL16NRaLhWuuuYYnn3wSjSY4aYdIdgQhSAaM7cPEC8bw4V+/IBCQkZBQgIDfDwpEJoRjtptwlDibXW7WWpIkcck952ENtbD2o82U5JbW9dmxGBhz9jAuvvvc+t5DOoOWhJTW7aexhVuD2sOoK+k3ujd9R6VQmFVMjaMWe6SNyITwYIclCAyfOoDoxDA2fbOb/VsyUGSFvsOTGXf2MHoGqWxzSwyZPIC4XtEcP1JATHJk/b4dRVGoKHJgMOmZeN6ooMZoC7MwYuagoMYgCGvWrOGWW25h9OjR+P1+HnzwQWbPns2BAwcwm+uWvy9evJivv/6apUuXYrfbufXWW1m4cCEbNmwAIBAIMG/ePGJiYti4cSMFBQVcffXVaLVa/vKXvwTldUlKW99FdTNOpxO73Y7D4cBmExuEhbbl9we4f/b/cXjH0fpRRb1JT3hcKGExIfjcPsoLK7nlhesYNr3ug7A4p4Ts/ceRJEge1OO0b4hrHLVk7M7C7wsQ1yv6jC0UIAhC95VzMJ//PPQe+VnFqFR1pae9Li8mm4kLbpnNrMsmBjtE4TR15vu1H2O78Zl30BtNv/4NbcTjquVf917R6p9JSUkJUVFRrFmzhilTpuBwOIiMjOTdd9/lwgsvBODgwYMMGDCATZs2MW7cOL799lvmz59Pfn5+/WzPK6+8wn333UdJSQk6ne5kl2wXYmZHEIJIo1Fzyb3n8Z/7/odaq8EWakF7op9FwB+g+HgZPQclMnBiP5zlVXz4zOfsXr2fGmctKGAJMTHirCFc/IcFmO3mVsVgtpsYOnVgG78yQRCEzqNH/zju+c+NbP5mFyvf20De0aK6ss9ygOz9uRzdc4yUoZ270EKw1Fa7SduSgaO0CpPVyKCxvbGHW379G4VOw+l0Nvh/vV6PXv/rDZUdDgcAYWF1fQB37NiBz+dj1qyf+mr179+fHj161Cc7mzZtYvDgwQ2Wtc2ZM4ebbrqJ/fv3M3z48LZ4SS0ikh1BCLJRc4aRezif7974geLjZeiNOgK+AAF/gPjeMVz358uRAzL/+sNbHNh4CFu4lfiUGBSgqryaNUs3UVns4NYXr0era9yUUhAEQQCDScfRPccoK6jAbDNithkJ+GU2fbWTfRsO8ZtHL2T4dDHw83Obl+/l8//+QFlR3U0vioI11Mysi8cy5/IJQdnn1JVJJ7468noAiYkNq6c+9thjPP744yf9XlmWufPOO5k4cSKDBtWtLCksLESn0xESEtLgudHR0RQWFtY/5+eJzo/HfzwWDCLZEYQgkySJC247h9Rxfdn81Q5yD+XXVeOZPoix54zAFm5l05fbObglg6jECHTGuilgCbBHWNGbdOzfcIi9aw4w8qyhwX0xHcxZXsWO7/aSte8YSBK9hyUz8qwhrZ7lEgSh+9rwxQ52rkojLDoEg/mnUW1buIWinFLe/+uX9B3RE7O945YZdWa71h3knee+we8LEBkfikarRg7IVJZW8fl/f0Cj03DWxeOCHaZwCnJzcxssYzuVWZ1bbrmFtLQ01q9f356hdQiR7AhCJyBJEv3H9KH/mD5NHt++fDeg1Cc6P2cw6ZFlmR0r9pxRyc6hbRm8+uC7lB4vq6+uuf6TLXz72ip+++QVpAxNDmZ43U7AH2DfunS2fLOL4pxSrGFmRs4ayqg5Q+sbTApCZ6UoCus/34akkhokOlD39zciLozi3FJ2rznAxAXBLVbQGciyzHfvbcLj8hGbHFH/uEqtIizaTmlBJSs/3MLEc4ZhEr//py5IpadtNluL9uzceuutfPXVV6xdu5aEhJ+KkMTExOD1eqmsrGwwu1NUVERMTEz9c7Zu3drgfEVFRfXHgkHMPwpCF+AsqzrpEjWNVoOjtKoDIwqu0vxy/nv/O5TllxPTM4qEPrEk9IklJjmSouxi/nPf2zhKnb9+IuGU+Lx+3njsQ5bc+QZbvt5J3pEC9q07yOuPvs/ff/9vKooqgx2iIJyUu8ZDWX7d8rWmaLRqFAWKcko7OLLOKT+rhNyMIuwRTe/NCYmwUl7s5PDuYx0cmdCeFEXh1ltv5dNPP2XVqlX07NmzwfGRI0ei1WpZuXJl/WOHDh0iJyeH8ePrmoOPHz+effv2UVxcXP+cFStWYLPZSE1N7ZgX8gtdItnJzs7m+uuvp2fPnhiNRlJSUnjsscfwer0n/b5p06YhSVKDr9///vcdFLUgtJ2IhHC87ubf7z6vn4j4sA6MKLi2fLWD0ry6ROfHMrIAao2amJ7RFB0rYeu3u4IYYfey8u11bPxsG9ZQM/G9Y4hMCCeuVzRRCeEc3n6Ud/78SZuXRxeEtqTRaVBr1Ph9gSaP//j+1Rk6vlJUZ+RxeQn4A2i1TS8AUmtUKLKCx3Xy+zCha7nlllt4++23effdd7FarRQWFlJYWIjL5QLAbrdz/fXXc9ddd7F69Wp27NjBtddey/jx4xk3rm5J4+zZs0lNTeWqq65iz549LF++nIcffphbbrnllJbPtYcukewcPHgQWZb517/+xf79+/n73//OK6+8woMPPvir33vDDTdQUFBQ//XMM890QMSC0LbGnD0ctVZNbZWr0bEaRy1avZYxZ48IQmTBkbb+IBqdpsnNsWq1CrVaRfqmw0GIrPvxur2s/WQzWr0Gs63hXgatXktolJ0Dm45w/HBBkCIUhF+n1WkYOmUANQ5Xk4l5bZULvVFH6tjeQYiu8wmPCcFg1OGqcTd53F3rRWfQEB4T0rGBdXESICkd+NXC+F5++WUcDgfTpk0jNja2/uuDDz6of87f//535s+fz6JFi5gyZQoxMTF88skn9cfVajVfffUVarWa8ePHc+WVV3L11Vfzxz/+sW1+iK3QJfbszJ07l7lz59b/f69evTh06BAvv/wyzz777Em/12QyBW2NoCC0lSFTUhk9dxibv9xBrdOFNaxuaUFVWRUet4/JC8fS/wz6kA4EZFSq5v+MSyoJv7/pEVyhZYpzSikvqMQa2nTRB7PdhKO0iGMHjpPYL66DoxOEUzdl0Vh2rzlAYXYJkfFhaHQaFEWh1umiosTJmNlD6Tko8ddPdAYIibAydFI/1n+1C7PN2GAGXZYVKoqc9B6SSK+B8UGMUmhrpzJDbzAYWLJkCUuWLGn2OUlJSXzzzTdtGdpp6RIzO01xOBz1db9P5p133iEiIoJBgwbxwAMPUFtbe9LnezwenE5ngy9BCDa1Rs1v/ngpF9x+DtYwC5UlThwlTmyRNi6861yufPRC1Gr1r5+om0gZmoTX7W3yD7OiKPi9fnoNET0z2oRUl1SKVWpCV5ecmsB1f7yYyPgwSo6Xk3+0iPzMYtw1HsbOGcpVDy9EkjqyMHDnNv83U0joHU3hsVIqip24qt04yqopyCohLNrGRbecJUpPC11Cl5jZ+aWMjAxefPHFX53Vufzyy0lKSiIuLo69e/dy3333cejQoQbTbb/05JNP8sQTT7R1yEIHUBSF2mo3iqxgthm73YeWzqDj3JvmMOvqqRQcratsEtc7BoMpOGtgg4NreFYAAF+VSURBVGncuaNY98kWyvIrCI8Lrf+3VhSFktwyrGFWxs47c5b1tafopEgiE8IoPlbaZNW16soajFaDaMgodAmDJvTj0ffuYPfaAxTnlKHVaxgwujdJqfHd7jPjdEXEhnDb05fy/dKtbF+1H1eNB61Ww6T5w5l10VgSekc3+X0+r49DWzOoKHZishpIHd8Xo6XpwhCC0BEkJYi7Su+//36efvrpkz4nPT2d/v371/9/Xl4eU6dOZdq0afz3v/9t0fVWrVrFzJkzycjIICUlpcnneDwePB5P/f87nU4SExNxOBwtKtsndBxFUdi78QhrP99B5v7jKEBcz0gmzx/O2NmDxchTN7Vm6SY+fPZzah21GC0GFMBd7cYSYubyhxYx/lxRPratfP/2Ot57+jOsdhOWUHP9TaHH5aXkeBnj5o/kxr9eFeQoBUFoL64aN9WVLowWPZaT9CHas2Y/Hz33JYWZxQQCMpIEYbGhnH39TKZfOrFdE0qn04ndbu+U92s/xnbT0+/8f3t3HldlmfYB/PecfQEOOwcQWRXFBVxx33czK9udtKZsr7e0afJ9K7NppmWqqWmcnGYqs8kWW7SyLPddUBG3UAFBkH0/cA6c9Xn/QE+eABUFDhx+38/n+RTPdl+HI/Bc577v64ZS1XHrOJkbTHj3j/M75fekI7m1Z2fJkiW4++67L3lOTEyM8/8LCwsxceJEjBo1Cu+9916r20tOTgaASyY7SqXSbdUi6OpsWZuKdf/eCnODFV6+GkgEAdnH8nHm+DnknS7CLY9O6/YJj81qwy/7TiP/ZCEEiYC4QdHoNTi6S3+SOf6WkQjvpceedak4lZoFCAL63dAbo24Yjuj+Pd0dnkeZePsolOSVYdeXKaipqIVMIYPdaodEKkG/0fG4Y+mN7g6RiNqRWquCWnvp9XQyUjLxn2c+gclgQmCYPxRqBWxWG6pKavDZK99AEARMvH10B0XcSblpnZ3uzq3JTlBQEIKCgq7o3IKCAkycOBFDhgzBhx9+eFUPr+np6QCA0NDQVl9LnVPBmVJ8t2oHBImAsOhf/y15+2pQW23CjnWHkDAsFgNGNr9YZ3eQd7IAq57/HPmnCmG32QERUKjk6DUkBvf86Xb4d+FqOnFJ0YhLir78iXRNpDIp7lx6I4ZOHYjUjekozSuHj78Xkib1R+KEflAoW14Diog8nyiK+OHfm2CsNiIsTu/8IE0mlyGoRwDK8ivw4/tbMGLOkMsmTURtrUvM2SkoKMCECRMQGRmJ119/HWVlZc5jFyqtFRQUYPLkyVi9ejWGDx+O7OxsrFmzBrNmzUJAQACOHj2KJ598EuPGjcPAgQPd9VKojR3cegJGQ71LonOBt68GtVVG7P/5WLdNdqpKa7ByyWoUnSlBUI8AKNUKiKKIhroGHNt1Ev/6w8dY8u8HuLYEXZYgCIgfFof4Yd2n6h8RXZmSs2XIPnIWvsG6ZkcM+IXoUJpfgYz9mRg8eYAbIuwk2LPjFl0i2dm0aROysrKQlZWFHj16uBy7MOXIarXi1KlTzmprCoUCmzdvxltvvQWj0YiIiAjMmzcPzz77bIfHT+2n6Gw5pFJJi8OxlGoFzp2fzN8d7fv2IIrOlCA0JgRSaWNvqCAIUHurESKXIjs9F0d3ZmDotEQ3R0qeSBRF2Kx2SCSCS+laIvIs9bX1sFvtkCubf6xsLPPtQH0za8URtbcukezcfffdl53bExUV5VKGNiIiAjt27GjnyMjdlGoFHPaWP7qw2+zdslrZBWlbjkGulDsTnYspVArYbXYc28VkpyOcyyxC6o9pyD9ZCKVagf5j+mDwlIHQeHtelSKjwYQv//Y9Dvx0BIaKWmh8tBg2MwkT5o1g1TYiD+QbrINCrUB9nbnZkQLmegukMhn8uvCw6bZwYbHPjmyPukiyQ9SS/slx2LfxKCxma5N5A3a7AzaLHYPH9Wnhas9XX9cAmbzlT9SlUgnqjeYWj1Pb2Prpbnzz9gbUVRshk8tgt9uR+uNhbP54Bx54fSFCY5ov4doVZaScxqsL/oHS/HJAbFzgtVKoRNGZYhzcdBS/X34bhk3jUGIiT+IX4ovE8QnY/U0qvP20kFz0AZsoiqgorEREn3DED22+OBRRe+reJaqoy0sc3Rux/Xug7FyVy0O7pcGKkrPl0EcGIHma540PdjgcOHP0LNK2HMPJ1CxYLbZmz+vROxQNLSQzoijCbncgLCa4PUPt9k7sPYUv3/gONpsd4b1CoY8ORnhcKEJ6BuLsL+fwn6WfwGqxujvMNlGUU4K/PfAeSvPLoVQr4eXnBa1OC6VGCYfVhuLMIqx5bT2qS7lYsycTRREl5ypx7kwpTHUN7g6HOsh1D05DaGwICrKKUVNugLnegrpqIwoyi+Dlq8XNi+dwOCu5BXt2qEtTqORYtOwmrHr5W2Qdy0fV+YcoqVSCyD5hWPD0HPgGekMUReQcy8PZX84BAKIH9ERkQo8uWXr59MFsfPX2DzibcQ7WBiukcilCo4Ix+/4pGD5zkMu5I68bgsNbjqOu2ggvX63LsaqSGmh1Ggyb4XoNta2dX+5Dg7EB4b1cq0DKFDIERzQmPMd3n8SgSV0/Kd+zLhWleeWQymWQX9TTKpVJoVQrYWmwoDS3DAc3H8OUO7t5CVoPlbbrNLZ8cxB5WSVwOERovVVInpSAabcOh/cl1mehrk8fFYz/+ecibHhvE45sP4GacgNkchmSJvbHzPsmo/cQ9uqQezDZoS7PP0SHJ96cj8wjecg+fg4OhwM9e+mRMCwWMrkUFUVVWP3C5zh9MBtmkwUAoNQo0Se5FxYsuwV+Ib7ufQGtkJ2ei5VPrUZ1eS389b5QaZWwNFhReKYEq5Z9AbvdgZHXDXGeP3B8AsbfMgLbP9+L2qrGhEcURdRVGSFXynHT/8xCeJzeja/Is9msNpxKzYK2hYc8hbpx3lTO0bw2TXasFiuO7z6JY7szYDZaEBIZhGEzktp9uFza5mOw2xzNDp2USCUQRRFmYz2Kz5Y1czV1dbt+OILP390KS4MVOn8tpDIJjHUN+PHT/ThzsggPL7sBWh/Pm6NGv9JHBePev8xHVWkNDOUGqL3VCOoR0CU/WCTPwWSHPIJEIkH8oCjED4py2W+qrce7T65CVnoO/PW+CAjzb9xvqEf61mMwGUx48r0Hu0QRA1EU8f2/N6O6zOCyjoFSrYA+OhgluWX4/l+bMGTKAOcEUYlEgtufuRE9+/bAzi/3ozinFIIA9B/bB+NvGYlBk/q78yV5PFEUIUKEILn0H3qHw9FmbdaUG/De0x/jVGoW7LbGhT8ddgc2rd6O6x+egSl3jWu3Bw9LvQUSqQDxEvVOHQ4RcoVn/ukRRRHnskpgqq2HX7APgnsEuDukDlNTacT6VbshOkSERv76upVqBaw6G04fycOuH49ixm3JboySOopfsA5+wTp3h9HpsECBe3jmXxyi8w5tOoqco2ehjwp2ecDS6jSQq+TIOpyLw1uOYeScoW6M8sqU5pUj89AZ6IJ8mn1Y9Q/1RWleOU4eyMbAsX2d+6VSCcbelIwxNw5HbWUdJFIJtDoNP2nrAHKFHDEDInFk5y/QBfo0OW41WyGRCIhM6NHM1a0niiJWPfcZTuw5heCIACjPJ/GiKKKyuBpfvfU9AsL9222di8h+PXD2l3NoqLdAVIgu/8ZEUYQoio29qsM8bzjL8f2Z+GHVTpw9WQi71QaFSoG+w2Jw3b0TEdHL83tP0/dmoqayDvoI/ybH5AoZ5EoZ9v50DFNvHtZsdUgiovbC3zjk0Q5vOQoIaPaT5MbqbSIObz3W8YFdhbpqE6wWW4sLgMqVctjtDhirjc0eFwQBPgHe8PLVMtHpQGNvHgm5XIbqMtdJ+Q67A6V55QiL1SNxQr82aevM0bPISMmEf6ivM9EBGt/7gFA/WM1WbPt0t0uZ/rY06vph8PLVQiIRYK63wHG+HVEU0WBsgCgCCSPj0c/DFvlN35mBfz/7BU4fzoXGS4UAvS/kChkObjmBFU+vwbmsYneH2O6qy2shCIJLFa6LqTQK1FabWiyYQkTUXpjskEerqzZBdokhM1KZFHUtJAedjU+AF+RKOcz1zT8sWBoskMmk8Anw7uDI6FIGTeqPWfdPgc1iw7nMIpSfq0DJ2TIUZpcgODIIv//LnS0msK2VdTgHlnpLi2v3ePt5Ifd4Hmor69qkvd8aNHkAptw1Dj4B3hAdjQsIGg0m1FUZITpE9BvdFw+/sQAyuecMKrBabPhm5WbUGy0Iiw6CxlsFmUIGL18NwmKCUHauEj+u3uXuMNudSqN09t41x2ZpXHBSoZI3e5yoWxDdsBGHsZFn00cHIzPtTIvHrRYbQqO7RunloB4BSBjRCwd+SodW1/jp+QWiKKKyqBphMSHofY3rGNRU1OLorlOoKa+FVqfGwDHxCAj1u9bwuy1BEHD9Q9PRZ1gc9n13EHkZ5yBXKTBoYn8kzx7cpgUyHHYHIAgt9twJEsFZcrw9SCQS3LH0RsQmRmHbZ7uRmXYGlgYbQuNCMPmOsZh61ziPKz17Ki0HxWfLEaDXNfm+SyQS6AK8cHxvJiqKqxHgwQsqDkiOwYZP9qK2uh4+fq4FORwOEaa6BoyZOdBj52sRUefF3zrUIarLalCaVw65Uo6efcI77IEnedZgpHx/CLVVRnj7uZZerq2sg1KtwPCZgzsklrZw3f1TkXM8H0XZxfAN1kGpUcJqtqKqpBoabzVueGzGVT9MiKKI7V+m4Pv3t8FQUQcIgOgQsX6lBpNuG4nZ907kWPurJAgC4ofFIX5YXLu206N3GKQyCcz1FijVTXuL6qqNiIgPh0+AV7vFIJFIMOK6IUiePbhxTpJU4lE9Ob9lqKiDw+ZoscdCqVagurwWhso6j052wiIDMXJqf2xdfwgOuwM+fhpIpBI0mCyoLDUgKNQX42YnujtMIuqGPPcvEHUKVaU1+PafG5G26ShMtfWQSqXQRwdhyl3jMfqG4e0+d6TviF4Yd/MIbPtsD0wGE7z9Gh/yDJW1EEURU3437pp7QjpSz77heOStu7H+nz/h9MEzqK2sg0whQ2xiFK57YKpLYYLWStl4BGvf/hGCICAkMhBSqQQOhwM15XX4/v1tUKjkmLFgXBu+GmprCSN7I6JPOHKO5SE0JsQlOTXWmCA6RIydNwJSaft/2CAIQpsNz+vMtD5qCBIBVout2Q8aLGYr5AoZvHw8f42Zm++fAIVShj0/HUPJuSoAgEwuRWy/cNz+8GToI7pPdToi6jyY7FC7MVTWYsXjHyDrcA68/b0QEOoHu82BgqxirF6+FiZDPaYtnNCuMVwovRwWF4odX+xFaV45IAAR8WEYf8sojJmX3OUm60f1i8Dj/7gXRWdKUF1qgMZHjZ59wyGRXH2vi91mx+Y1e2C32qGPCnLul0gk8Av2QUVRFbat3Y9xNw5rcT4IuZ9UJsXdL96OlYtXoSi7BAqVHDK5FPUmM6RSKcbclIxxN49wd5gepc/QGASG+aGqpAbBv3mYF0URNeW1SBzbB4Hhnj8UVK6QYd6iCZh84xCcPJIHq9mG4HA/9BrQ45p+PxF5DFFs3DqyPWKyQ+1nxxf7kJ2eg9DoYGeRALkS0GuDUVFYhQ3vbcLQ6Ynw17fvQ4BUJsXE20dj3M0jUF5QCUEAAsL8u/TcAUEQEBarR1hs25S0zT9dhMKcUvgGNS2PDAC6QB+UnatAZvpZJCTH4ejeTKRuOYHyomr4+GkxdGIChkzo0y7rFdVVG3F0ZwaM1UZ4+3thwLi+0HahT8krSmqwf/MJpO/NgrnBip6xwRgxpR/6DYtul0S7Z59wPPXBw9j37UEc/PkI6usa0GdEL4y6fhiSJvbv0v/uOyOlWoHZ94zHmr9+j5L8CvgH+0CmkMFssqCytAY+/l6YubD91jbqjHwDvTFicttUGCQiulZMdqhd2O127F1/AEqNstlqaH4hOhSdKcHhLccxef7YDolJKpMiJDLo8id2Q1azDQ67A1J58w/CUpmkcZJxbT0++Mu3SNt5EqJDhFwlw7nsUpw4cAZ7fzqK+5fdCJ1/28wHEUURW9fsxg//2YLqUgNEAIIA+IX44vqHpmHsNfTK2aw2CILQ7g/+ORmF+PdfvkNpUTUUChmkMgmKzpYjbc9pTLphCObdN75dHoL99X6Yff9UzL5/apvfm5oaNXsQJBIJfli1A6UFlbBb7ZAr5YhO6IGbHp6KuIE93R0iEVG3xWSH2oXZZIGxxtjiJ/0SqQQQgJrfrD1C7hEY7geVRglTbT10zZSurq9rgFKjwKmj+Ti47Rf4BftArf31vbWYrTh1OBdr/7kZ9z17Q5vEtOurFHz+128hlUoa5xDJpLBZ7agsrsaal7+BQiXHiOuGXPH9RFHE4a3HsevrFOQcy4MgCEgY2Rvj5o1AfDsscmkxW7HqjR9RVlSD0J7+LsN4aqtN2PL1QfSMC8HwiVc/z4o6B0EQMHJWEoZM7oes9LMw1TZAF+SN2AERHL5FRE6C2Lh1ZHvEdXaonSjVCig1SlgarM0eFx0iRBHQ6LrOcCRP5hesQ9KEBNRWGmGz2l2OOewOVJXUILJvOE6mnYVSo3BJdIDGBVp9/L1wbF8WSvIrrjkeS4MFG1dtAwAEhv865FAmlyI4IgA2iw0bP9wGu81+qds4iaKI9Ss24l9/+BhHd/4Ch90Bm9WG/d8fxDuPvY+dX+2/5ph/6+j+bBTnVSAoTNfkgdfbVwOH3YE9G4+22wKf1PEUSjkSkuMwdEp/9EqMZKJDRNQJ8DcxtQupTIrk2YNhqq1vdk2PmopaaH3USJrIcd2dxZxFkxCVEI7i3DJUFFXDWGNCVWkNCnNKEdwzEGNvHA5DlRHeLSSoXj5qmOoacPb0ta8Wn5Wei7L8CvgF65o93jgMshQ5x/Ov6H4Z+zPx06rtUGoUCIvVQxfkA99gHUJj9bDZ7PjqbxtQnFt6zXFf7NyZMjgcYoulwDXeKuRnl8LcwgcCREREdO2Y7FC7mXDrKIT30qMou7ix7K0owm6zo6KwCiZDPcbfOgr6qK6xoGd3EKD3xWN/W4Dr7psIL18NLBYblGoFps4fg8ffWojQ81XaxBaWZL6w/+LFTq9Wg9EMu9Xe7HwvoLHqk91mh9lkvqL77fv+IMwNVugCXQswCIKAwDB/1FbV4cDG9GsN2/Xel/k+NPboCG3y/SIiIqLmcc4OtZvA8AA88vbv8dmr65CZdgZVJTWQSAX4Busw877JmHXfZHeHSL/hG+SDkbOSIJcKqCyugl+wL4ZOT4Q+MhCWBiv8gn1QXV4LZWhzC1aaoPVRI7pv+DXHERDmB6VGifq6+mYrr5lqG6DUKBEQdmWV/M6eOAeVpvk1XwSJAIlUgnOni64p5t+KTQiHTCZtdoFPURRhrDVj6Lh4KJTNL0ZJnUPuiXzsWX8AGfszITpE9EmOw+i5wxAzMNLdoRER0RVgskPtKixWjyf/9QDyThag9GwZ5Eo5eg2OhlandXdo9BsOhwPf/vMnbP54J4wGEwQ0lujfuGorJtw6Cjf9z2yMmzMIX63ciroaE7wuGs7WYDKjttqE8XOHIEDf/NCz1ujZJxy9Bkfj6M4MqL1ULnMfHHYHqssMGDYj8Yp7BuUqOey2psMpnfd0OKBQt+0CmH0H9UR031CcPpKP4B5+zuFsokNERakBKrWcK8p3cvu+O4Q1f/kaddVGqM7PU9u6ZjdSNqTh1qeu55pFRNQqgqNx68j2iMkOdQBBEBDZtwci+/Zwdyh0CVvX7Mb3K3+GykuF8Fg9BIngXBRx44fb4OWrxdQFE1BWUI19Px2FocIIqVwCu80BqUyKpDHxmPfApDaJRRAEzHtyNopzS1GQVQxvPy8oVXI01FtQV21EaEwIbnp81hXfb9DE/sg5lgeHw9Fk0rjVYoNEkCBhZO82if0CqUyKe56ejf/85TvkniqGw+GAIBHgsIvw1qlx473j0HdwVJu2SW2n6EwJPn3lG1gaLAiP0ztLhIuiiPKCSqx94ztED+iJiPgwN0dKRESXwmSHiGBpsGDLJ7sgk8tcigIIggDfIB/YLDZs+2wPJtw+GvMXz8CwyQk4tD0DFcXV8PHzQtKY3ug3PBayFtbpuRqRfXvgiXcX4efVO3B463GY6hqgUCkwef5YTFswvlVrJo24bgh2fZ2C4jOlCOoZ6OxlsTRYUJZfgah+Ee1SLCMo1BeL/3o7juzLwi+HcmExWxEWGYhhE/ogpId/m7dHbSflhzTUVta5JDrA+Xle4f4oyCrG/u8PMdkhoisnnt86sj1iskNEQM7xfJQXVMJf79vscV2QD8oLKpGdnov+o/sgPikS8UntP2chLFaPu5ffhlsWz0FdtRFevlpor6JceWC4P+5/9Xf44LnPUJJbBofDAQiAVCpFbGIU7v3LHVBrVe3wCgClSo7hE/tyPZ0uJvvIWcgUsmYXfRUEAQqlHJmHc9wQGRERtQaTHaIuym6zI/9MGawWG4JCfeEb4HXV97JZbBAdDkhlzRdolEoljWvTWGxX3ca10Oo0V5XkXCw2KQrPfvYEjmw/gfxThZBIJIhNikK/UfEtloem7ksql0J0tPyxqEMU27Qnk4iI2gf/whN1MaIoYu+m49jy9SGUFFTBYXdArVUiaVQcrl8w5qqSnpCoIKi9VKirNkEX6N3kuLHGBLW3Cvrorl0qXK1VYcTsIRgxe4i7Q6FOLiG5N45ub1yAViJ1/RDA4WhM/PuP6uOm6IioKxLObx3ZHnGdHaIuZ/PXB/HftzehMK8cXjo1/IK84XA4sGPDEax44RsYqoytvmdgmD+SJvaHoaK2Se+NzWpHTbkB/Uf34bpI1G0Mm5mEoIgAFOWUwm6zO/fbbXYU55QhMNwfw2cPcmOERER0JdizQ9SFVJYZ8ONnKZDJJPAP9nXu1/l7QeutRs7JIuz84Qiumz+q1fe+6YnZKMguRs7Rs1CqlVCoFbA0WGA2mRHZLwK3LJnThq+EqHPzC9Zh0Svz8Z//XYPi3LJfDwiNc8B+/9IdCAxjkQkiagVRbNw6sj1iskPUlaTvzUJtjQn6iKYPWTK5FEqVHPs2ncDM25IhlbVuPoFfiC+eWHk/dn+Vgj3rU1FXZYSf3hejrh+GsfOS4Rt07evnEHUlcYOi8eynT+DQz0eRdSQXoigiZkAkhk5PhI//1c+RIyKijsNkh+gqVZfV4MCP6TiZmgmbzY64pGgkzx6M4IjAdmvTUGWEIAhN1oq5QKmWw1TXgIZ6K7TerZ887ePvjVmLpmDmfZNhNVshV8qbrUZF1F14+Wox/taRGH/rSHeHQkRdHUtPuwWTHaKrcOpgNt5f+gnKz1VAIpVAEAQc3f4LtnyyC3c9fzOGTE1sl3a13iqIogjRIUKQNE1CrGYbtN4qqNTya2pHEAQoVIprugcRERGRu7FAAVEr1ZQb8P7ST1BRWInQmBCExoRAHx2M8Dg9jDVGrF7+Bc5lFrVL2wNHxEHjpYKhumkRArvdgXqjGcMn9W31EDYiIiIiT8Rkh6iVDv50BGXnKhASFexSklaQCAiJDIKhvBb7vjvYLm2HhPth/HWJqDdaUFFqgM1mhyiKMNY2oDi/AmFRgRg3K6ld2iYiIiLqapjsELXSqYNZkEgESKVNf3wEQYBSrcQve0+1W/tzF4zBDXePgdZLhbLCahSerYC53oIBw2Px4HNzEahnIQEiIiIigHN2iFpPBC65VJfQuPBne5HKpJh5+wiMm52ErOPnYLXYEBzuh4jYYBYTICIi6qQEsXHryPaIyQ5Rq8UmReHAxvRmV1YXRRENJjPih8W1exxabxUSR7Z/O0RERERdFYexEbXS8JmDEBDmi+KzZRAdv35sIooiys9VwttXi1HXD3VjhEREREQEsGeHOjFRFFFTboAoArpA7xbXlunIeM7lVeDk8QLETx2MA2v34FxmERSqxrVojAYTFEo5xtyUDD+9n1tjJSIiok6G6+y4BZMd6nREUUTqj4ex7bM9OHeqECJEhEYFY9wtIzH6xuGQSi9fVrnkbBn2b0jDqQNZAID4YXFInjUI+qjgq4rJZDRjzQe7cPhADurrLZAIAmzhesiNJnhJHKjIK4Pd5oBVYse2L/YibetxjLlxOOY8OA1yBX/MiIiIiNyBT2HUqYiiiO/e/Rnf/+tn2O0O+Ph5AQJwNuMcPl6+FvmnCnHH0hsv2ctzeOtxrF6+FtWlNc5EI2N/JrZ/vhcLlt2CQZP6tzqmj/+9Aym7T0Pnp4VfgBaCIMBqsaGkqAZ5JdVQyRUIDQ+AxkcNh92BmvJabHhvM4w1Jvzu2XktFg6oKK7C2te/xf5vD6Ku2gQvPy1GzR2GW/9wPXyDWFWNiIjIUwi4ZHmjdmmPOGeHOpncE/nY+OFWKNUKhMWEwMtPCy9fLfRRwdD6arFz7b5LlnUuzSvH6uVrUVtlRHisHiGRQQiJDEJ4rB51VUasXr4WpXnlrYopJ6sU6Qdz4euvhZe3ypm4yBUyyEQHTPVWyIL8oNVpIAgCpDIp/PW+8Pb3wv7vDyH/ZGGz980/XYgnxzyH9f/YiNK8cjQYG1Bytgzf/P0HPDHmORRmF7cqTiIiIiJyxZ4d6lRSfzyM+tp6hPcKbXLM208LQ4UB+747hP5j+jZ7fcqGNFSX1iA8Vg9B8utnGoJEQEjPQBRkFyNlQxrmPDTtimP65Wg+zGYrAoK8mhyrKTNAIgFqbSIcogjJRT04Xn5aFGYVI33bcfTsGw5DRS0ObzmGyuJqqLRKfPvPn1CWXw6Vlwoy+a8/ijaLDSW5pXj93nfxxrYXWE76MhpMZhz86QhSfkhDZVEV/EJ8MXzmIAybmQS1VuU8z2a1IfdEPqxmG4J6+CMwPMCNURMRUbfDOTtuwWSHOpXiMyWQKWQtPuArVYpL9nicPJDVeL2k6fWCRIBMIcPJA1mtSnYsFhsEAU1iEsXGB2iJIMAhNn59cZ+x0HgRjAYTdn2dgq/f3oCashoIgoD6OjPKCyogkUogk7nOQZIpZJBZZMhOz0FWeg56DYq54li7G2ONCSufWo1f9p0GACjVCpScLUfG/kykbEjDA28sgLefFnvWpeLnj7ajJLcMdrsDaq0SA8f3w42Pz2TSQ0RE5MGY7FCnovFWw26zt3jcZrVD7aVq8TiupBeklT0lgcE+gAjY7Q5IL1pXRxAAuVIOs9ECtVTAb/Mr8XwGVFNuwK4v98Nut0MfFQypTIrC7GKIogiHzY4GkwUqrdLlWrlKhgajBb/sO81k5xLWrdiIY7tPIrhHAJRqhXO/pcGKX/afxtdvb0B4rB5r3/wOosMB32AdZHIZTAYT9qxLRf6pAjyx8n74s3oeERGRR+KcHepUBo5PgCBIYGmwNjlms9phs9kxZGpii9f3GRYHm8Xmsv7NBaJDhM1iR5+hsVcUiyiKqCqtQUSoD3S+GpSXGiCKrvf19veGCEAnE5v0/NSUG6DxUaP0bDnMJjOCIwIhPd+LI0iExvMlAqxmKxwOx2/abvzvb3t96Fc15Qak/ngY3jqNS6IDAAqVHN5+WqT+kIZ1K36EVCaBPioYKo0SMrkUPgHeCIsNQX5GAbZ9tsdNr4CIiLoV0Q0bsWeHOpekSf0RNygKpw9mwz/UD2qvxoIADcbGYV89+/bAsJlJLV6fPHsQtn22B8Vny6CPDHIOZxMdIorPlsEvxAfJ1w2+bBxHdpzAlk924cyRs42JiEyKekGOcw1W6Py1kEolMNaZ4ZBKEBKggSW/GNUNGmh1GtjtDhjKa+FwODDx1lHYsy4VPoHeLvfXBfhAIimEwyFChAi71Q6J8tfPHiwNVqg0CiRNbl3luO6kILMYxmoTgnr4N3vcy88LZ46ehUQCRPfv2eS4VCaF2luN/d8dwvUPT4dcIW/vkImIiKiDMdmhTkWpVuKB1xfgo2Wf49SBbFQVVwMAZEo5eg+Nxd1/uh0+/t4tXh8cEYiFL9yCj15Yi4LsYufEf5vVBr8QXyx84RYERwQ6zzfXm3FgYzpSfzyMisIq+IXo4O3nhcNbj8HaYIV3gDekMgmMNSaI1TVQCA44vFWw20UE63UYO6kvBg2JxKZV23Bg4xFUFldDIpEgpGcgJt05BnGDorHrq/2QyV17aDQ+anj7e6GmzACHKF7UsyPCXG+Fw+5A4sT+CI9tWqiBGgkSAYJEaLYXD2hMcEWHA4JMBom0+U5spUaB+roGmAz10AUy2SEionYkXpjg24HtEZMd6nz89X54YuUDyD6Se75nRURkQg/0HhpzRQuKJk7oh2c+DkHqD4dx6mA2AKD3kFgkzx7kkugYa4yNk9vPl7JWqpUozCpCaX4FFCoF+gyPdSZLGu/G5KSysAqzJvbCiLnD4eOjhlTW+BB959KbcN0D01CSWwaZQoYevUMhV8hQb2yAl68Gxpp6qLSuc41iE6OQkZIJU209LPUWWM02QBQhkUoQPywOS/7zUJt8Pz1VZEIP+Ab5wFBRh4CwpnNuDBW10Ppq4bDZ4XA4ml2byVJvgcpLdel5YERERNRlMdmhTkkQBMQlRSMuKfqqrg+OCMR1D0zFdQ9MbfGcdf/YiGO7MhAcEeic81F+zgFBAKxmC4rOlCIiPsx5vkqjhEQmwcEf0zDj7glN5uj4+HvBx9+1PLVaq8LI64fhu3d/gqXBCwrVr70HUrkUfiE6hPfSw9vPCzUVtfAN1mHyHWMw8Y4xLuWoqSmNtxpj5yVj3TsbUVdtdK5zBDRWaauva8D420bi0E/pqC41wF/v63K9w+6A0VCPcbeMhEKlaKYFIiIi6ur4NEXdUuPk9jR4+2qbVPESBAEyuQw1ZQaERAa5JChqLzXKCythtdigUF7ZsKfpd09AdnouMvafhlwph9pbBavZBqPBhKCIQDz4xkLEJka19UvsFmbeOxkVRdVI+f4QqssMkEolsDtEKJRyjLx+KO744w3wD9Zh/T9/Qtm5isZqbDIpjAYTqktrEBYbgol3jHH3yyAiou6CI8s6HJMd6pbOnS5qnNx+0bA2AJCcH5YmkTVWhKs3NrgkOzaLDVqdpskcnEvR6rR4+O17sHPtPuxZlwpDeS2UGgVG3zgcE28bjdCYkGavyz2Rjz3rUnEyNRMQgT7JvTBq7rBmJ9t3V3KFDHcvvxWj5w7Doc1HUVVcA99gbwyePBC9h8ZAIpFg9gNTofJSYfPHO1FeUAmHzQ6VVoWkif1xy1PXuwxtJCIiIs/CZIe6JYlUAkEQmikl7YXSvHI4bA4IcF2Sx+FwoL6uHhPvGN3s/I9L0fpoMPPeyZh29wQ0GM1QqOSXrP61d/0BfPry16irNjnX4Nn88U7s/+4g7lh6E0bNHdaq9j2ZIAjoPSQGvYc0vx6RRCLB1LvGY8xNycg+nANLgxVBEQHo0TusxcVriYiI2pogNm4d2R4x2aFuKjKhB3RBPjCU17pMbtd4q6EL9EF5QSVkCplz4rq53oLycxUI7BGAsfNGXHW7UqkUWh/NJc8pyCrCZ69+A4vZivBeeucDuSiKKDtXgc9e/QY9E3qgR6/2q9RWU26A2WSBT6A3VBrl5S/oAtRaFfqP6evuMIiIiKgDMdmhbqHBZEZVcTXkShkCwvwbJ7ffPALr3/kRddVGePlqATT2EvjpfVFXbYRKq0Tp2XIIEgESqQQ9E3pgwbJboY8KbtdYUzakobayDuG9Ql16HgRBQFCPABRkFiFlwyH0eOK6Nm/7dNoZbP7vLpxMzYLd5oDGW40R1w3G1LvGwdtPi/zcchxPz0NDvQVBwT5IGh4Dbx91m8dBRETkeTp6pU927QBMdsjDGQ0m/PzRduxdfwB11UZIpBJE9++JqQvGY9Z9k1FZWIWUDWmoLq2BVCaF3e6AQinHzPsmny8scBY2iw2hMcHoO6I3pLIrn6tztbLScyBXypsdYiUIAuRKObIO57Z5u0d3ZeD9//sMtRV18A7wgtpLAaPBhO/f24yM1GwEJMXi+JF8NNRbnLF9u/YA5v1uJEaMjW/zeIiIiIiuFZMd8lim2nr884kP8cveU1B7qaD10cBus+OXfadx5shZ3Pl/N2Hhi7dh1NxhSNt8FJXF1fAN0WHw5IGIHxYLiUSCnn16dHjcMpm0xYUygcbFMltTIOFKWBos+Py1b2GsNiEsLsSZzKi9VLBabDh8vADSIiN6RAfBP9ALgiDAbnegotSAT/69A94+avRLZOEEIiIi6lyY7JDH2vnlfmTsz0Rwz0CXdVS0Og3K8iuw5uVvUF1mgFwhR7/RfZAwsnenWNsmYWQ8ju8+CYfdAYnUtRCCw+6A3WZHwsjebdrmsd2nUJJXjsBwvyY9SnaJBFa5Ag5jAzRapfO4VCpBkF6HwvxKbP3xKBIGRnDCPxERUQtYoMA93P9kR9QOHA4H9nyTArlC1mTBSLvNAVNtAyqKqvDfP30FrY8aEpkU4b30WPD8LYgZGOmmqBsNnzUIW9fsQnFuKUIig5xD5+w2O0rOliEg3B/DZw1u0zYrCqsAUYS8mbWDjBYHIJFAtDtgtdhc1iUSBAE+Og0yM4pgqDFBd37uExEREVFn0Lr6uURdRIPRjJpyg7Oa2gWiKCL/dCGqywwQBAFanQZhsXr4BeuQ90sB/vXUxyg5W+amqBv56/1w78vzERDmj+LcUhRkFaEgqwjFuaUICPPHfS/PR0Co3+Vv1AoqrRKi2Jgk/pZDFCGKIiTnCzX8llQmgcMhwmqxt2lMREREHkV0w0bs2SHPJFfKIJPLYK63uOw31tSjtqIOcqUMVrPN2WuiVCsQGhOMwuwS7P4mFfOemO2OsJ3ih8Xh2c+fxMGfjiD7SC4AIHZgJIbOSIKPv3ebt9dvVG9odRoYKurgG+TjckwhFeCwO6D294Jc0fRXhrHODP8ALXR+ly6pTURERNTR2LNDHkmukGPItESYDCY4LprsX1tVB4dDhMMhQiqVwCfAy3lMIpFApVUi9YfDTRYbdQcff29MumMMFr3yOyx65XeYdOfYdkl0ACAg1A/jbh6B+tp6VJfWOHt4rGYrjEWVUMokkKkUTb4v5gYrrGYrRk/sC3knmO9EREREdDE+nZDHmnj7aKRvPY6iMyUIDPODUqOE3WaH3d74IB8Q5geV1nWYm1whg7nBcj4Z6l6T7W94ZBogitj1dQqKc0obiw0IAvSRgbjptjHYtuM0CvIqofVSQiaXot5ohs3mQP/BkZg0c6C7wyciIurkuM6OOzDZIY8VFqvHA28swJo/f438UwWNhQkM9YAIBIb7ISxWj9+mM6baBsQmRkLazNwUi9mKyqIqyORSBIT5e1zlMZlchpufnI3Rc4fixL7TcNgdCAz3R//R8VCoFEgcE4+dm07g0P5s2GwO6MP9MHpiX4ydnACVWnH5BoiIiIg6GJMd8mhxSdH4v0+fwMnULJScLUODyYwN/9oMu80OicQ1oak3NkAEMPqG4S77LQ0WbP7vLuz6ej9qSmsgSCSI6BOOyXeOwdDpSR6T9BzfnYEda/fh9MFsiCIQER+GcTePgOz8PJ0ekYG4877xuGXhaFgtdqjU8ibfQyIiImqB4/zWke0Rkx3yfFKZFP1GxaPfqHgAgNZHg89fW4/C7BJ4+3tBIhVgrDHBarFhyNSBGDFniPNai9mKf//xvzj08xEo1Ap46TRwOERkpp1B7rE8VJXUYNrCCW56ZW1n22d7sPb1b9FgaoCXrxaCIODkgSycPnQGub/k49an5jqTOrlcxvk5RERE1CXwiYW6nfG3jIRvkA+2froH2UdyIZpFBEUEYsyNwzHpjtFQXLTWTOoPaUjbfAz+oX4uZay1Og0qiqrw3cqfkTSxH4J7BrnjpbSJopwSfPP2BoiiiPC4UOd+nwBvGCrrsPWT3UgYEY8BY/u6MUoiIqKujYuKukeXGYMSFRUFQRBctldeeeWS1zQ0NOCRRx5BQEAAvLy8MG/ePJSUlHRQxNSZJU7ohydWLsKfv38Gy9f9AS98tQQz7pnYZAHSPetSIQhosl4PAPiH+KKuyoiDPx/tqLDbxYEf01FbVYeAsKZr9/j4e8FqtmLvtwfcEBkRERHRtelSPTsvvvgiFi1a5Pza2/vSZXiffPJJbNiwAWvXroVOp8Ojjz6Km266CXv27GnvUKkLEAQBukCfFo+Looji3DKomkl0AECQNA7rqiisbJf4OkpBVhGkMmmLc49UWhXyTxZ0cFRERERE165LJTve3t7Q6/VXdG5NTQ3ef/99rFmzBpMmTQIAfPjhh+jbty/279+PESNGtGeo5AEEQYDWR43ygvpLnCU2KV/d1SjVCjjsLc9itNvsULLaGhEREXVBXWYYGwC88sorCAgIwKBBg/DXv/4VNputxXMPHToEq9WKKVOmOPf16dMHPXv2xL59+1q8zmw2w2AwuGzUfQ2fORhmk9m5Ns/FTLX1UKgUGDiua89l6Te6DwSJAIvZ2uSYw+6ApcGKwVM6xzo6drsdpfnlKM0vh91md3c4RERE1Ml1mZ6dxx9/HIMHD4a/vz/27t2LpUuXoqioCG+++Waz5xcXF0OhUMDX19dlf0hICIqLi1ts5+WXX8by5cvbMnTqwkbfOBz7vz+IojPFCAzzh0qrgiiKqKsyoqbcgKHTk9BrSIy7w7wmSRP7IWZgJLIO5yAwPAAqrRJAYyW6srxyBEcGYsScoW6N0eFwYPfXKdj++V6U5JZCBBASGYhxN4/CuJtHQCqTujU+IiKiyxLFxq0j2yP39uw888wzTYoO/HY7efIkAGDx4sWYMGECBg4ciAcffBBvvPEG3nnnHZjN5jaNaenSpaipqXFu+fn5bXp/6loCQv3w0N/uRq/BMTBU1KEgswiFWcWwWmwYc2My7nnpji6/1oxSrcQDry9An+ReqCk3oCCrCAVZRagoqESP3mF48PUFCAhtWrygo4iiiC9e/xYfL1+L/FMFUGqVUGtVOHe6GJ+89CU+e3UdRP5CJyIioma4tWdnyZIluPvuuy95TkxM85+aJycnw2azITc3F/Hx8U2O6/V6WCwWVFdXu/TulJSUXHLej1KphFKpvKL4qXuIiA/HMx8/jlMHslGYVQyZXIreQ2MRGhNyTfc9l1mEU6lZsFltCI0JQcLI3pC5af2awPAAPPX+wziZmoWswzlw2B2I6BOOgeP6NqlQ19FOHzqD7Z/tgcZHDZ+AX4uSaHzUqK0yYufafUia2N+5jhIRERHRBW5NdoKCghAUdHXrk6Snp0MikSA4OLjZ40OGDIFcLseWLVswb948AMCpU6eQl5eHkSNHXnXM1D1JJBL0Te6Fvsm9rvleptp6fPLSl0jfehz1dQ0QBAESqQThvUKx4IVbETMwsg0ibr3fLr7aWaT+kAZzvRmB4f5Njnn7aWGoMCDlh7ROFzcREdHFuM6Oe3SJ8Tf79u3DW2+9hSNHjuDMmTP45JNP8OSTT+J3v/sd/Pwah9cUFBSgT58+SE1NBQDodDrce++9WLx4MbZt24ZDhw7hnnvuwciRI1mJjdxGFEWseu4z7F1/AHKVHGFxeoTF6eGn90Vexjm8u3gVinNL3R1mp1KcUwq5Qt5iaWyFUoHiHH7PiIiIqKkuUaBAqVTis88+wwsvvACz2Yzo6Gg8+eSTWLx4sfMcq9WKU6dOwWQyOff97W9/g0Qiwbx582A2mzF9+nT885//dMdLIAIAZKadwdEdv8BP7wutj8a5X6lWIDQ2BIWZxdj1dQpuWTzHjVF2LlpfzSUrr1mtVmh91B0YERER0dUQz28d2R51iWRn8ODB2L9//yXPiYqKajJJWaVSYcWKFVixYkV7hkddUHFuKY7tykBDXQP89L5ImtgfXr7adm/3xJ5TMNdbENij6ZAsiUQCtbcKB348jJufvK7FnozuZtCkATj081FYzFYolHKXY1aLDaIDnaY0NhEREXUuXSLZIWorNqsNX775PXZ/nQKTwQRBIkAUAb8QHW76n9kYfcPwdm3fbDIDAlpMZGQKGSz1FjjsDpZTPm/Q5AGITYrC6UPZ8A/xheZ8L059bQMqi6sQmxSNIdMS3RwlERHRpQmOxq0j2yMmO9TJiaKIjP2nsWfdAWSl50Aqk2LA2L4Yc+NwRMSHt/p+61dsxKaPtkOr0yAsVg9BIsBus6OisAqfvPQVtDoNkib2b4dX0ijg/CR7h90BibTplDlTbT2iB0Qy0bmISqPEQ28uxOoXvsDJ1CxUl9YAABRqBQaMS8CCF26FxpvD2IiIiKgpJjvUaYmiiB//swXfrfwZZpMZai8VHKKIn1dtw/7vDmLh8ttaNXypuqwGO7/cB7W3CrogH+d+qUyKoIgAFGYXY9PqHUic0K/dhpANnZaIDf/ahIqiKgT1CHA5Vl/XANEBjLkxuV3a7sr8Qnzx+D8XIfdEPnKO5QGiiKj+PRE9oGebvVflhZU4uDG9sSCCSo6+I3pjwNg+kCvkl7+YiIiIOiUmO9RpnUzNwncrf4ZUJkV4r1DnflEUUXK2DP/905eIHtATfiG+V3S/jP2ZqK00IjS6ablyQRDgG6RD7vE8lOWXI7hn60uii6KIc6cLcTI1C3arHfroYPQbHe/ysOwX4oubnpiNz15Zh4KsIvj4e0Mik8BYbYLVYsOQqQMxcs6QVrfdHQiCgOj+PRHdv2eb33vv+gP44q/rUVNeC0FofC+3fbobcYOisei1u9y6qCoRERFdPSY71Gnt/fYAzCazS6IDND70BkcEovBMCQ5sTMe0hROu6H6WBisANDt8DACkcinsdgfM9ZZWx2o0mM6vnXMC9cYGSAQBglSCsNgQLHjhVsQlRTvPHXfzSPgG67Dlk504c+QsrBYbgiICMObGZEy6c4zbF/Hsbk4dyMInf/kKNrMNYXEhkEga/32Y6y04eSALH/zvGiz+z4OQSjm0kIiIqKvpEuvsUPeUfTgHKq2q2WMSqQSCIODsL+eu+H7BPQMhk0vRYDI3e9xkqIfWRwP/Vn6Kf2HtnH3fHoRSrUD4+bVzAkJ9ce50Ef61ZDWKckpcrhk4LgFPrHwAL32/FMvXPY1lXz2FGb+fxETHDXas3QuToR5BEQHORAdoLAceFB6AzLQzOJWa5cYIiYjII4hu2Fpp586dmDNnDsLCwiAIAtatW+f6EkQRzz//PEJDQ6FWqzFlyhRkZma6nFNZWYn58+fDx8cHvr6+uPfee1FXV9f6YNoIkx3qtKRyGRyOlkuJiKIImeLKP23vPTQGEfFhqCiohMPh+hvAarbCWGPC8FmDXNa/uRKZaWdwbGcG/PV+8PLTOueQKFQKhMYEo7ygAru/TmlynSAI0AX6IDDMn/NC3MRqseKXvafhpdM0O/dHpVXCZrHh9KEzboiOiIioYxmNRiQmJra4bMtrr72Gv//971i5ciVSUlKg1Woxffp0NDQ0OM+ZP38+Tpw4gU2bNuH777/Hzp07cf/993fUS2iCw9io0xo4PgE//GsTRFFs8iBqs9ggkQiIHxp3xfeTSqW4439vwsrFH6EgswhevlrIlTI01DWgwWRG76GxmHnfZNQbG5C+9Tiy0nMg2h3o2bcHhkxLhLefV7P3vezaOV5qpP54GDcvnsO1czoZu80Bhyi2OLQRACAADhvrdxIRkeebOXMmZs6c2ewxURTx1ltv4dlnn8XcuXMBAKtXr0ZISAjWrVuH22+/HRkZGdi4cSMOHDiAoUOHAgDeeecdzJo1C6+//jrCwsI67LVcwGSHOq3Rc4dh77pUFOeUIiQyyPlAarPYUJxbioj4cAya3Loy0XFJ0XjiXw9g26e7kbbpKKxmG3RBOsy6YRgm3D4aVSU1+M8f/4uCrGI47PbGNXEg4If/bME9L92Bvsm9mtzTXG+BcMm1c6SwNli5dk4npFQr0KNXKE4dzIZPgHeT41aLDYIgILyX3g3RERGRRxHFxq0j2wNgMBhcdiuVSiiVylbfLicnB8XFxZgyZYpzn06nQ3JyMvbt24fbb78d+/btg6+vrzPRAYApU6ZAIpEgJSUFN95441W+mKvHZIc6rbBYPe556Q6sfuELFJ0paRx6KjbO14noE477/7oAaq/Wr6/So1co7nr+Ftz6h+vRYDRDq9NAJpfBWGPEv5/+GOdOF0IfFQyZovHHw26zo+RsGd5f+l88/dFjCI4IdLlfINfO6bIEQcDYeSOQmXYGtVVGePtpncccDhFleeUIiQpCYjuuvURERNSeIiIiXL5etmwZXnjhhVbfp7i4GAAQEhLisj8kJMR5rLi4GMHBrlVvZTIZ/P39ned0NCY71KkNHJeA575YjIM/HUH+yQJIZBL0GhyDpEn9oW6heMGVUqqVUKp//WTj0KajKMwqhj46BDL5r4mJVCaFPjoEhVlF2P/dIVz/8HSX+wyZlojv/7UJ5YWVCOoR4NLDc2HtnLE3db+1cywNFhzafAwHfzqCiuJqBOh9MXR6IoZMGdCpCjEMnzUIZ46exY4v9sJQUdu4npPNjgaTGQFh/lj44u1QaVr/CRgREZELN/Xs5Ofnw8fn1/UFr6ZXpytjskOdni7QB5Pnj233djJSMiFCdEl0LpBIBChUChzdcaJJsuMXrMPNi6/Dmr98jcLsYnj7e0MqlcBYY4LNYsOQaYkYMWdok3t6MqPBhH//cQ2O7z0FiCLkSjnOnSrEkR0ZSP3xMBa9Mh8a79b3yrUHqVSKO5beiL7JvbBnfSryMgqgUMkxZGoiRs0dBn1U03WZiIiIugofHx+XZOdq6fWNQ7pLSkoQGvrrsiAlJSVISkpynlNaWupync1mQ2VlpfP6jsZkh+g8m9nmUnr4tyQSAVaLrdljY25Mhm+QD7as2Y2swzmwWW0I7hmIsfNGYMJto6BQdq9qa+v+8ROO7sxAYA9/KNW/9uKYTWYc2Z6B9f/8GXf8ca4bI3QlkUgweMpADJ4y0N2hEBGRp7rKctDX1F4bio6Ohl6vx5YtW5zJjcFgQEpKCh566CEAwMiRI1FdXY1Dhw5hyJDGRdK3bt0Kh8OB5GT3jHJhskN0XlT/CBz8OR2iQ4QgcS02IIoiGuotiE2KavH6/mP6ot/oPqitqoPNYoMu0KdbztOpKq3BgY3p0PpqXBIdAFBqlNDq1Ej5IQ2z7p0IXeC1f9JEREREbaOurg5ZWb+uLZeTk4P09HT4+/ujZ8+eeOKJJ/DSSy+hV69eiI6OxnPPPYewsDDccMMNAIC+fftixowZWLRoEVauXAmr1YpHH30Ut99+u1sqsQFcZ4fIadjMQdAF+qA0vxzib8bUVpXUQO2lwsjLDEcTBAE+/t7w1/t1y0QHAAoyi1BXY3KZ7H8xLz8v1FWbcO50UQdHRkRERJdy8OBBDBo0CIMGDQIALF68GIMGDcLzzz8PAHj66afx2GOP4f7778ewYcNQV1eHjRs3QqX6dR71J598gj59+mDy5MmYNWsWxowZg/fee88trwdgzw6RU3BEIO5YeiP++9JXKMgqglqrhiARUF9XD5VGibmPzkSvwTHuDrPTEwQBAi4xB1MUIQgAuOYQERF1I4LYuHVke601YcKEJh/4utxTEPDiiy/ixRdfbPEcf39/rFmzpvWNtxMmO0QXSZ49BMGRQdj9dQqO7zkJ0e5A0sT+GHNTcrNr7FBTPfuGwzvAC4bKWviH+DY5bqisg0+AD6ISenR8cERERNStMNkh+o3o/j0R3b+nu8O4JFEUUW+xQSoRoJR3rh9jbz8vjJ47DBv+vQUmTb1L1TWToR71dQ2YMn8MtDqNG6MkIiLqaF28QkEX1bmekojokuwOB3b+koNNR04jr7wagiCgf089ZiTFIzEq9PI36CBzHpiCiqIqHPr5KKpKaiCVSWG32SFXyDByzhDMXjTZ3SESERFRN8Bkh6iLcDhEvL/lADYePgWHKMJbrYTDIWLvyVwcPlOIeycPw9TEzjHUTqFS4N4/34HR1w/Foc3HUFVSA78QHYZMHYg+w+MglbI2ChEREbU/JjtEXURqVj5+Sj8NL7USPupfVz/21apQWlOH1dsPYUCkHnpfbzdG+SupVIJ+o+LRb1S8u0MhIiJyP1G8RPWedmqPWHqaOofyggpkHc5BQVbRJauAdGfbjmfDZre7JDpAY2WUIJ0XakwN2HMy1z3BEREREXVC7NkhtzqXWYTv3v0JJ/acgqXBAplciugBkZi1aAp7BH4jp7QSaqW82WMSQYAgAOcqajo4KiIiIroirE/gFuzZIbcpyCrCO4/8Bykb0iCVS+Gv94XKS4WM/aexcslHOLL9hLtD7FRUchnsdkeLxx1i4zlERERE1IjJDrnND+9tRsnZMoTH6eHj7wW5Ug6tjwZhcXqYDCZ89db3sFlt7g6z0xjRuycarDY4mhnmZ7baIJMISIwKc0NkRERERJ0TPwYmt6gsrsLRnb9AF+gNyW8qcwmCgMAwfxSdKcHJ1Cz0H93HTVF2LpP6x2Hr8WwUVNQgxNcbCpkUAFBvtqLUUIf+PfUYEhPu5ih/ZbXYkLb1BPb/cBglZ8uh1akxbNpAJM9Mgi6gcxRRICIi6igCAKED5yULHdZS58Zkh9yipswAS4MVvkE+zR5XqBWwW+2oLuUclAv0ft546vpx+MePe3GuosZZyEEulSIpKgyPzx4N+fkEyN0sDVZ8uPxLpG05DlEUodQoUVVag5wT57D3+8N48NU7oY8MdHeYRERE5OGY7JBbaHUayBQyWMxWKNSKJsdtFhskUgm8fLVuiK7z6hMejDcWXocDWedwtqwKUqkECT2C0S8iBFJJ5xmVuuXzvTi46Rj8gn2g9lI599ttduSfLsR/X16HJe/eC0Hg505ERNRNsECBWzDZIbcIighE7yExSN92HFqdpslDb2VxNQLC/dEnuXMsktmZKOUyjOkbhTF9o9wdSrMsZiv2rD8EuVLmkugAgFTWWIjizLF8nDmWj9iBPd0UJREREXUHneejYOpWBEHAzPsmwyfQG4XZJWgwmQEAVrMVJWfLIAgCZi+aApVGeZk7UWdTUViFqjIDvHSaZo+rtUpYzRacyyzq4MiIiIjc6MKioh25EZMdcp/eQ2LxwF8XIKpfBGrKDDiXWYTygkoEhPlh/rPzMHbeCHeHSFdBIpVAEHDJxWFFEU0KUxARERG1NQ5jI7dKGBmP//s0DlmHc1BdWgO1txp9hsdBoWo6j4e6hsBwf4RGByPvZCE03uomx+uqTdB4qxCXGOmG6IiIiKg74Uer5HZSmRTxw+KQPHsIBo5LYKLTxUmlEky6dQQEAaguM7j08NQbzaipqEXiuL4IjQ52Y5REREQdTXTDRuzZIaI2N2LWIJQXVmPTJ7tQkF0CiVQCh12EXCFD0vgE3L7kOneHSERERN0Akx0ianOCIGDOoklImtAXaVtOoLywEhpvNQaMiUffYbGQdpL1gIiIiDqM4/zWke0Rkx0iaj8RvUIR0SvU3WEQERFRN8Vkh4haVJpfjsxDObDb7AiL0yM2MZILgRIREVGXwWSHiJqoNzZg7RvfIfWHwzAZ6gEACpUcMYmR+N2z8xAWq3dzhERERESXx2psRORCFEWsfmEttn26FxKJBKExIQiLDYGXToOM/Zn455Mfoaqk2t1hEhEREV0Wkx0icnH60Bkc3nIMfiE+0AV6QyIRIAgC1N5qhEYHoyCzCHvWHXB3mERERF2LKHb8Rkx2iMjVsV0ZMNdbml0QVCqTQqlWIOWHNDdERkRERNQ6nLNDRC7qaxsAoMVCBDKFDHXVJoiiyGIFREREV6qje1vYswOAPTtE9Bv+el8AgOho/pdkg9GMkMhAJjpERETU6THZISIXQ6YNhJevFlWlNU2ONZjMEEURo64f5obIiIiIiFqHyQ4RudBHBWPmvZNgtdhQlFMKU209GkxmlBdWorywConjEzDiusHuDpOIiKhrEd2wEefsEFFTM++dBL8QX2z5ZBcKs4vhcIjQBXhjxu+HYdrC8VCoFO4OkYiIiOiymOwQUROCIGDknCEYPmsQSs+WwW6zI7BHAFQapbtDIyIi6ppYoMAtmOwQUYuk0sZFRYmIiIi6Is7ZISIiIiIij8SeHSIiIiKi9sZhbG7Bnh0iIiIiIvJI7NkhIiIiImpv7NlxC/bsEFG3YrbYYLXa3R0GERERdQD27BCRxxNFEQfTcrFj9ynk5JZBEAT06a3HhHF90D+hh7vDIyKi7oA9O27BZIeIPJooivhq3SH88PNR2O0OaDVKOEQHUg/m4Ojxc7jt5uGYPCHB3WESERFRO+AwNiLyaL9kFGLjpmNQKeUIC/WFTqeGr06D8HA/iAC+/OYgCgqr3B0mERERtQMmO0Tk0fbsz4LZYoNOp25yLMBfi7q6BqQcOOOGyIiIqHsR3bARkx0i8mhn88qhUjY/YlcQBEhlEuQXVHZwVERERNQROGeHiDyaQimD3dHyp1sOuwilUt6BERERUbfkOL91ZHvEnh0i8mxDkiJhtdrhcDT9rW+12iEIAgYkhLshMiIiImpvTHaIyKONTI5DSLAPiopqXNbXMZttKC6pQWRkAAYPinRjhERERNReOIyNiDxagL8XHl40Cf/5aCcKCqsgOkSIAGRSCXrHheD+30+AWqVwd5hEROTxOrpoAAsUAEx2iKgbiIkOwrL/nYv0o3nIy6uAIBEQFxOM/gnhkMmk7g6PiIiI2gmTHSLqFpQKGZKHxiB5aIy7QyEiou5IFBu3jmyPusacne3bt0MQhGa3AwcOtHjdhAkTmpz/4IMPdmDkRERERETkLl2iZ2fUqFEoKipy2ffcc89hy5YtGDp06CWvXbRoEV588UXn1xqNpl1iJCIiIiJqEafsuEWXSHYUCgX0er3za6vVivXr1+Oxxx6DIAiXvFaj0bhcS0RERERE3UOXGMb2W99++y0qKipwzz33XPbcTz75BIGBgejfvz+WLl0Kk8l0yfPNZjMMBoPLRkREREREXU+X6Nn5rffffx/Tp09Hjx49LnnenXfeicjISISFheHo0aP44x//iFOnTuHrr79u8ZqXX34Zy5cvb+uQiYiIiKg7Ex2NW0e2R+7t2XnmmWdaLDxwYTt58qTLNefOncNPP/2Ee++997L3v//++zF9+nQMGDAA8+fPx+rVq/HNN98gOzu7xWuWLl2Kmpoa55afn3/Nr5OIiIiIiDqeW3t2lixZgrvvvvuS58TEuJaJ/fDDDxEQEIDrr7++1e0lJycDALKyshAbG9vsOUqlEkqlstX3JiIiIiJqEUtPu4Vbk52goCAEBQVd8fmiKOLDDz/EggULIJfLW91eeno6ACA0NLTV1xIRERERUdfSpQoUbN26FTk5ObjvvvuaHCsoKECfPn2QmpoKAMjOzsaf/vQnHDp0CLm5ufj222+xYMECjBs3DgMHDuzo0ImIiIiIqIN1qQIF77//PkaNGoU+ffo0OWa1WnHq1ClntTWFQoHNmzfjrbfegtFoREREBObNm4dnn322o8MmIiIiIuLaN27QpZKdNWvWtHgsKioK4kVjEyMiIrBjx46OCIuIiIiIiDqhLpXsENGVsTRYYDTUQ6VVQq1VuTscIiIiYoECt2CyQ+RBqkprsHXNLuz/7hBMdfWQK+QYMnUgJs8fi7BYvbvDIyIiIupQTHaIPERlcRXeefR95BzLg8ZbDZVWCUuDFVvW7MKxnb/g4bd/j6h+Ee4Ok4iIqHtiz45bdKlqbETUsu9W/oycY3kIjQlBQJgftDoN/EJ0CI/To6ygEp+9us5lXhsRERGRp2OyQ+QBasoNSNt0FN7+XpDJpS7HJBIJAvS+yD2Wh+wjue4JkIiIiMgNmOwQeYDygkrU1zVA461u9rjKSwVLgwVl+RUdHBkREREB+HUYW0duxGSHyBMoVHJIZVLYrbZmjzvsDkAQoFQrOjgyIiIiIvdhskPkAcJ7haJH71BUldU0e7y6tAZ+ITrED4vt4MiIiIgIQOOCoh3as+PuF9w5MNkh8gASiQTT75kEhVKB0vxy2G12AIDD4UBVSTUsDVZMvnMstDqtmyMlIiIi6jgsPU3kIYZOS4TJYML6FRtRklsGABBFEV5+Wsx5aBqm/36imyMkIiIi6lhMdog8yLibR2LwlIFI33YcNWUGaHw0GDg+AQGhfu4OjYiIqHvjOjtuwWSHyMN4+Wox5sZkd4dBRERE5HZMdoiIiIiI2ht7dtyCBQqIiIiIiMgjsWeHiIiIiKidiaIIsQN7Wzqyrc6MPTtEREREROSRmOwQEREREZFH4jA2IiIiIqL2xgIFbsGeHSIiIiIi8kjs2SEiIiIiam/s2XEL9uwQEREREZFHYrJDREREREQeicPYiIiIiIjaG4exuQV7doiIiIiIyCOxZ4eIiIiIqJ2JDhGio+N6Wzqyrc6MPTtEREREROSRmOwQEREREZFH4jA2IiIiIqJ2J57fOrI9Ys8OERERERF5JPbsEBERERG1N4fYuHVke8SeHSIiIiIiarRixQpERUVBpVIhOTkZqamp7g7pmjDZISIiIiJqd6Ibttb5/PPPsXjxYixbtgxpaWlITEzE9OnTUVpaepWv2f2Y7BAREREREd58800sWrQI99xzDxISErBy5UpoNBp88MEH7g7tqnHOzmWIYmNWbDAY3BwJERERETXnwnPahee2zshsM7ulvd8+wyqVSiiVyibnWywWHDp0CEuXLnXuk0gkmDJlCvbt29e+wbYjJjuXUVtbCwCIiIhwcyREREREdCm1tbXQ6XTuDsOFQqGAXq/H3ze/0uFte3l5NXmGXbZsGV544YUm55aXl8NutyMkJMRlf0hICE6ePNmeYbYrJjuXERYWhvz8fHh7e0MQhDa5p8FgQEREBPLz8+Hj49Mm9yT34nvqefieeia+r56H76nnuZr3VBRF1NbWIiwsrJ2jaz2VSoWcnBxYLJYOb1sUxSbPr8316ngyJjuXIZFI0KNHj3a5t4+PD38xexi+p56H76ln4vvqefieep7WvqedrUfnYiqVCiqVyt1hXFJgYCCkUilKSkpc9peUlECv17spqmvHAgVERERERN2cQqHAkCFDsGXLFuc+h8OBLVu2YOTIkW6M7NqwZ4eIiIiIiLB48WIsXLgQQ4cOxfDhw/HWW2/BaDTinnvucXdoV43JjhsolUosW7as242Z9GR8Tz0P31PPxPfV8/A99Tx8T93ntttuQ1lZGZ5//nkUFxcjKSkJGzdubFK0oCsRxM5co4+IiIiIiOgqcc4OERERERF5JCY7RERERETkkZjsEBERERGRR2KyQ0REREREHonJTgf785//jFGjRkGj0cDX17fZc/Ly8jB79mxoNBoEBwfjD3/4A2w2W8cGStckKioKgiC4bK+88oq7w6JWWLFiBaKioqBSqZCcnIzU1FR3h0RX6YUXXmjy89inTx93h0WttHPnTsyZMwdhYWEQBAHr1q1zOS6KIp5//nmEhoZCrVZjypQpyMzMdE+wdEUu957efffdTX52Z8yY4Z5gqctistPBLBYLbrnlFjz00EPNHrfb7Zg9ezYsFgv27t2Ljz76CKtWrcLzzz/fwZHStXrxxRdRVFTk3B577DF3h0RX6PPPP8fixYuxbNkypKWlITExEdOnT0dpaam7Q6Or1K9fP5efx927d7s7JGolo9GIxMRErFixotnjr732Gv7+979j5cqVSElJgVarxfTp09HQ0NDBkdKVutx7CgAzZsxw+dn99NNPOzBC8gRcZ6eDLV++HACwatWqZo///PPP+OWXX7B582aEhIQgKSkJf/rTn/DHP/4RL7zwAhQKRQdGS9fC29sber3e3WHQVXjzzTexaNEi5yJqK1euxIYNG/DBBx/gmWeecXN0dDVkMhl/Hru4mTNnYubMmc0eE0URb731Fp599lnMnTsXALB69WqEhIRg3bp1uP322zsyVLpCl3pPL1AqlfzZpWvCnp1OZt++fRgwYIDL4k3Tp0+HwWDAiRMn3BgZtdYrr7yCgIAADBo0CH/96185FLGLsFgsOHToEKZMmeLcJ5FIMGXKFOzbt8+NkdG1yMzMRFhYGGJiYjB//nzk5eW5OyRqQzk5OSguLnb5udXpdEhOTubPbRe3fft2BAcHIz4+Hg899BAqKircHRJ1MezZ6WSKi4ubrFJ74evi4mJ3hERX4fHHH8fgwYPh7++PvXv3YunSpSgqKsKbb77p7tDoMsrLy2G325v9OTx58qSboqJrkZycjFWrViE+Ph5FRUVYvnw5xo4di+PHj8Pb29vd4VEbuPD3sbmfW/7t7LpmzJiBm266CdHR0cjOzsb//u//YubMmdi3bx+kUqm7w6MugslOG3jmmWfw6quvXvKcjIwMTojt4lrzPi9evNi5b+DAgVAoFHjggQfw8ssvQ6lUtneoRHSRi4fJDBw4EMnJyYiMjMQXX3yBe++9142REdGlXDz8cMCAARg4cCBiY2Oxfft2TJ482Y2RUVfCZKcNLFmyBHffffclz4mJibmie+n1+iZVn0pKSpzHyH2u5X1OTk6GzWZDbm4u4uPj2yE6aiuBgYGQSqXOn7sLSkpK+DPoIXx9fdG7d29kZWW5OxRqIxd+NktKShAaGurcX1JSgqSkJDdFRW0tJiYGgYGByMrKYrJDV4zJThsICgpCUFBQm9xr5MiR+POf/4zS0lIEBwcDADZt2gQfHx8kJCS0SRt0da7lfU5PT4dEInG+p9R5KRQKDBkyBFu2bMENN9wAAHA4HNiyZQseffRR9wZHbaKurg7Z2dm466673B0KtZHo6Gjo9Xps2bLFmdwYDAakpKS0WP2Uup5z586hoqLCJaEluhwmOx0sLy8PlZWVyMvLg91uR3p6OgAgLi4OXl5emDZtGhISEnDXXXfhtddeQ3FxMZ599lk88sgjHP7URezbtw8pKSmYOHEivL29sW/fPjz55JP43e9+Bz8/P3eHR1dg8eLFWLhwIYYOHYrhw4fjrbfegtFodFZno67lqaeewpw5cxAZGYnCwkIsW7YMUqkUd9xxh7tDo1aoq6tz6Y3LyclBeno6/P390bNnTzzxxBN46aWX0KtXL0RHR+O5555DWFiY80ML6nwu9Z76+/tj+fLlmDdvHvR6PbKzs/H0008jLi4O06dPd2PU1OWI1KEWLlwoAmiybdu2zXlObm6uOHPmTFGtVouBgYHikiVLRKvV6r6gqVUOHTokJicnizqdTlSpVGLfvn3Fv/zlL2JDQ4O7Q6NWeOedd8SePXuKCoVCHD58uLh//353h0RX6bbbbhNDQ0NFhUIhhoeHi7fddpuYlZXl7rColbZt29bs38+FCxeKoiiKDodDfO6558SQkBBRqVSKkydPFk+dOuXeoOmSLvWemkwmcdq0aWJQUJAol8vFyMhIcdGiRWJxcbG7w6YuRhBFUXRDjkVERERERNSuuM4OERERERF5JCY7RERERETkkZjsEBERERGRR2KyQ0REREREHonJDhEREREReSQmO0RERERE5JGY7BARERERkUdiskNERERERB6JyQ4REREREXkkJjtE5FHuvvtu3HDDDe4Oo90UFxfjscceQ0xMDJRKJSIiIjBnzhxs2bLF3aF1Klf672Dnzp2YM2cOwsLCIAgC1q1b1+6xERFRx2GyQ0TUReTm5mLIkCHYunUr/vrXv+LYsWPYuHEjJk6ciEceecTd4XVJRqMRiYmJWLFihbtDISKidsBkh4g82pdffokBAwZArVYjICAAU6ZMgdFoBAA4HA68+OKL6NGjB5RKJZKSkrBx40bntbm5uRAEAV988QXGjh0LtVqNYcOG4fTp0zhw4ACGDh0KLy8vzJw5E2VlZc7rDhw4gKlTpyIwMBA6nQ7jx49HWlqaS1yCIODdd9/FzJkzoVarERMTgy+//PKSr+Xhhx+GIAhITU3FvHnz0Lt3b/Tr1w+LFy/G/v37nefl5eVh7ty58PLygo+PD2699VaUlJQ4j7/wwgtISkrCBx98gJ49e8LLywsPP/ww7HY7XnvtNej1egQHB+PPf/5zq2M+duwYJk2a5Px+33///airq3Mev9Dj8vrrryM0NBQBAQF45JFHYLVaneeYzWY89dRTCA8Ph1arRXJyMrZv3+48vmrVKvj6+uKnn35C37594eXlhRkzZqCoqMj5+j766COsX78egiBAEASX6y82c+ZMvPTSS7jxxhsv+b0nIqKuickOEXmsoqIi3HHHHfj973+PjIwMbN++HTfddBNEUQQAvP3223jjjTfw+uuv4+jRo5g+fTquv/56ZGZmutxn2bJlePbZZ5GWlgaZTIY777wTTz/9NN5++23s2rULWVlZeP75553n19bWYuHChdi9ezf279+PXr16YdasWaitrXW573PPPYd58+bhyJEjmD9/Pm6//XZkZGQ0+1oqKyuxceNGPPLII9BqtU2O+/r6AmhM4ObOnYvKykrs2LEDmzZtwpkzZ3Dbbbe5nJ+dnY0ff/wRGzduxKeffor3338fs2fPxrlz57Bjxw68+uqrePbZZ5GSknLFMRuNRkyfPh1+fn44cOAA1q5di82bN+PRRx91uce2bduQnZ2Nbdu24aOPPsKqVauwatUq5/FHH30U+/btw2effYajR4/illtuwYwZM1zeF5PJhNdffx0ff/wxdu7ciby8PDz11FMAgKeeegq33nqrMwEqKirCqFGjmv2+EhGRhxOJiDzIwoULxblz54qiKIqHDh0SAYi5ubnNnhsWFib++c9/dtk3bNgw8eGHHxZFURRzcnJEAOJ//vMf5/FPP/1UBCBu2bLFue/ll18W4+PjW4zJbreL3t7e4nfffefcB0B88MEHXc5LTk4WH3rooWbvkZKSIgIQv/766xbbEUVR/Pnnn0WpVCrm5eU59504cUIEIKampoqiKIrLli0TNRqNaDAYnOdMnz5djIqKEu12u3NffHy8+PLLL19xzO+9957o5+cn1tXVOY9v2LBBlEgkYnFxsSiKje9PZGSkaLPZnOfccsst4m233SaKoiiePXtWlEqlYkFBgUs7kydPFpcuXSqKoih++OGHIgAxKyvLeXzFihViSEiI8+uL/x1cKQDiN99806priIioc2PPDhF5rMTEREyePBkDBgzALbfcgn//+9+oqqoCABgMBhQWFmL06NEu14wePbpJ78rAgQOd/x8SEgIAGDBggMu+0tJS59clJSVYtGgRevXqBZ1OBx8fH9TV1SEvL8/lviNHjmzydUs9O+L53qjLycjIQEREBCIiIpz7EhIS4Ovr63LvqKgoeHt7u7yGhIQESCQSl30Xv67LxZyRkYHExESXnqfRo0fD4XDg1KlTzn39+vWDVCp1fh0aGups59ixY7Db7ejduze8vLyc244dO5Cdne28RqPRIDY2ttl7EBERXSBzdwBERO1FKpVi06ZN2Lt3L37++We88847+L//+z+kpKQgICDgiu8jl8ud/y8IQrP7HA6H8+uFCxeioqICb7/9NiIjI6FUKjFy5EhYLJarfi29evWCIAg4efLkVd/jYhfHDzS+hub2Xfy62sql2qmrq4NUKsWhQ4dcEiIA8PLyuuQ9rjQhJCKi7oM9O0Tk0QRBwOjRo7F8+XIcPnwYCoUC33zzDXx8fBAWFoY9e/a4nL9nzx4kJCRcU5t79uzB448/jlmzZqFfv35QKpUoLy9vct7FRQUufN23b99m7+nv74/p06djxYoVzgILF6uurgYA9O3bF/n5+cjPz3ce++WXX1BdXX3Nr+tyMfft2xdHjhxxiW/Pnj2QSCSIj4+/ovsPGjQIdrsdpaWliIuLc9n0ev0Vx6lQKGC326/4fCIi8kxMdojIY6WkpOAvf/kLDh48iLy8PHz99dcoKytzPpz/4Q9/wKuvvorPP/8cp06dwjPPPIP09HT8z//8zzW126tXL3z88cfIyMhASkoK5s+fD7Va3eS8tWvX4oMPPsDp06exbNkypKamNpnMf7EVK1bAbrdj+PDh+Oqrr5CZmYmMjAz8/e9/dw4vmzJlCgYMGID58+cjLS0NqampWLBgAcaPH4+hQ4de0+u6XMzz58+HSqXCwoULcfz4cWzbtg2PPfYY7rrrLufwv8vp3bs35s+fjwULFuDrr79GTk4OUlNT8fLLL2PDhg1XHGdUVBSOHj2KU6dOoby83KXa28Xq6uqQnp6O9PR0AEBOTg7S09ObDDkkIqKuickOEXksHx8f7Ny5E7NmzULv3r3x7LPP4o033sDMmTMBAI8//jgWL16MJUuWYMCAAdi4cSO+/fZb9OrV65raff/991FVVYXBgwfjrrvuwuOPP47g4OAm5y1fvhyfffYZBg4ciNWrV+PTTz+9ZO9LTEwM0tLSMHHiRCxZsgT9+/fH1KlTsWXLFrz77rsAGnuy1q9fDz8/P4wbNw5TpkxBTEwMPv/882t6TVcSs0ajwU8//YTKykoMGzYMN998MyZPnox//OMfrWrjww8/xIIFC7BkyRLEx8fjhhtuwIEDB9CzZ88rvseiRYsQHx+PoUOHIigoqEkP3gUHDx7EoEGDMGjQIADA4sWLMWjQIJfqekRE1HUJIgc5ExF1OEEQ8M033+CGG25wdyhXrCvGTERE3Rt7doiIiIiIyCMx2SEiIiIiIo/EYWxEREREROSR2LNDREREREQeickOERERERF5JCY7RERERETkkZjsEBERERGRR2KyQ0REREREHonJDhEREREReSQmO0RERERE5JGY7BARERERkUf6f+Urx4/KGHPLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500, Loss: 4980.8428\n",
            "Epoch 20/500, Loss: 4512.6084\n",
            "Epoch 30/500, Loss: 4282.9365\n",
            "Epoch 40/500, Loss: 4212.6460\n",
            "Epoch 50/500, Loss: 4210.6592\n",
            "Epoch 60/500, Loss: 4202.1519\n",
            "Epoch 70/500, Loss: 4195.4253\n",
            "Epoch 80/500, Loss: 4192.1396\n",
            "Epoch 90/500, Loss: 4189.5830\n",
            "Epoch 100/500, Loss: 4187.1152\n",
            "Epoch 110/500, Loss: 4184.5586\n",
            "Epoch 120/500, Loss: 4180.0859\n",
            "Epoch 130/500, Loss: 4169.6865\n",
            "Epoch 140/500, Loss: 4144.2588\n",
            "Epoch 150/500, Loss: 4110.0986\n",
            "Epoch 160/500, Loss: 4095.1868\n",
            "Epoch 170/500, Loss: 4065.6216\n",
            "Epoch 180/500, Loss: 4208.9448\n",
            "Epoch 190/500, Loss: 4091.4023\n",
            "Epoch 200/500, Loss: 4063.0442\n",
            "Epoch 210/500, Loss: 4007.5137\n",
            "Epoch 220/500, Loss: 3969.9546\n",
            "Epoch 230/500, Loss: 4203.3682\n",
            "Epoch 240/500, Loss: 4157.7314\n",
            "Epoch 250/500, Loss: 4054.2036\n",
            "Epoch 260/500, Loss: 4094.2234\n",
            "Epoch 270/500, Loss: 4026.5298\n",
            "Epoch 280/500, Loss: 3954.3628\n",
            "Epoch 290/500, Loss: 3891.8008\n",
            "Epoch 300/500, Loss: 3869.9829\n",
            "Epoch 310/500, Loss: 3691.5054\n",
            "Epoch 320/500, Loss: 3795.7715\n",
            "Epoch 330/500, Loss: 4012.4543\n",
            "Epoch 340/500, Loss: 3882.2800\n",
            "Epoch 350/500, Loss: 3734.6304\n",
            "Epoch 360/500, Loss: 3593.6321\n",
            "Epoch 370/500, Loss: 3450.4751\n",
            "Epoch 380/500, Loss: 3350.2520\n",
            "Epoch 390/500, Loss: 3335.9011\n",
            "Epoch 400/500, Loss: 3035.4497\n",
            "Epoch 410/500, Loss: 3402.4419\n",
            "Epoch 420/500, Loss: 2912.1216\n",
            "Epoch 430/500, Loss: 2447.0283\n",
            "Epoch 440/500, Loss: 3885.5659\n",
            "Epoch 450/500, Loss: 3477.1187\n",
            "Epoch 460/500, Loss: 3222.4685\n",
            "Epoch 470/500, Loss: 2988.7278\n",
            "Epoch 480/500, Loss: 2894.0049\n",
            "Epoch 490/500, Loss: 2640.7048\n",
            "Epoch 500/500, Loss: 2335.7400\n",
            "Training complete.\n",
            "Test Loss: 12028.3340\n",
            "Test MAE: 103.7868\n"
          ]
        }
      ]
    }
  ]
}